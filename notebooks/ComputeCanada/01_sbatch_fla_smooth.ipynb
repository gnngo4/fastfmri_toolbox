{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d08a1d31-5b87-4115-a9a7-91f8c71a0f11",
   "metadata": {},
   "source": [
    "### Running run-level frequency-based modelling from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da47a35-ddb6-451c-9c8e-eb743a14a863",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "experiment_id = \"1_frequency_tagging\"\n",
    "mri_id = \"3T\"\n",
    "oscprep_dir = f\"/data/{experiment_id}/{mri_id}/bids/derivatives/oscprep_grayords_fmapless\"\n",
    "out_dir = f\"/scratch/{experiment_id}/{mri_id}/derivatives/run_level\"\n",
    "sub_id = '002'\n",
    "ses_id = '01'\n",
    "task_id = 'controlQ1'\n",
    "run_id = '01'\n",
    "search_frequencies = [.125, .2]\n",
    "time_window = (1, 219) # second\n",
    "smooth_mm = 4\n",
    "\n",
    "!python3 /opt/app/scripts/fla.py \\\n",
    "    {experiment_id} \\\n",
    "    {mri_id} \\\n",
    "    {oscprep_dir} \\\n",
    "    {out_dir}_s{smooth_mm} \\\n",
    "    {sub_id} \\\n",
    "    {ses_id} \\\n",
    "    {task_id} \\\n",
    "    {run_id} \\\n",
    "    {' '.join([str(i) for i in search_frequencies])} \\\n",
    "    {' '.join([str(i) for i in time_window])} \\\n",
    "    --smooth-mm {smooth_mm}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6912a803-e6cb-4ac3-bea4-08ad81d4fb69",
   "metadata": {},
   "source": [
    "### Running run-level frequency-based modelling on ComputeCanada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a499f8c-c359-4869-bcca-3a5520f61ede",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def search(base_dir, wildcard, error=True):\n",
    "    search_path = Path(base_dir) / wildcard\n",
    "    files = glob.glob(str(search_path))\n",
    "\n",
    "    if not files:\n",
    "        if error:\n",
    "            raise FileNotFoundError(f\"No files were found in: {search_path}\")\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    return files\n",
    "\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import glob\n",
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "scripts_dir = \"/data/scripts/03a_run_level\"\n",
    "scripts_dir = Path(scripts_dir)\n",
    "if not scripts_dir.exists():\n",
    "    scripts_dir.mkdir(parents=True)\n",
    "\n",
    "experiment_ids = ['1_frequency_tagging']\n",
    "mri_ids = ['7T']\n",
    "smooth_mm = 4\n",
    "oscprep_dir = 'oscprep_grayords_fmapless'\n",
    "\n",
    "for experiment_id, mri_id in itertools.product(experiment_ids, mri_ids):\n",
    "    base_bids_dir = f'/data/{experiment_id}/{mri_id}/bids'\n",
    "    sub_ids = [Path(i).stem for i in search(base_bids_dir, 'sub-*')]\n",
    "    sub_ids.sort()\n",
    "\n",
    "    oscprep_deriv_dir = f\"{base_bids_dir}/derivatives/oscprep_grayords_fmapless\"\n",
    "    assert Path(oscprep_deriv_dir).exists()\n",
    "    \n",
    "    for sub_ix, sub_id in enumerate(sub_ids):\n",
    "        sub_dir = f'{base_bids_dir}/{sub_id}'\n",
    "        ses_ids = [Path(i).stem for i in search(sub_dir, 'ses-*')]\n",
    "        ses_ids.sort()\n",
    "\n",
    "        if sub_ix > 2:\n",
    "            continue\n",
    "        \n",
    "        for ses_ix, ses_id in enumerate(ses_ids):\n",
    "            ses_func_dir = f'{sub_dir}/{ses_id}/func'\n",
    "            funcs = [Path(i).stem for i in search(ses_func_dir, '*part-mag_bold.nii.gz')]\n",
    "            funcs.sort()\n",
    "\n",
    "            vols_per_task_list = defaultdict(list)\n",
    "            for func in funcs:\n",
    "                nifti = Path(f\"{ses_func_dir}/{func}.gz\")\n",
    "                task_id = func.split('task-')[1].split('_')[0]\n",
    "                if task_id == 'wholebrain': continue\n",
    "                n_vols = nib.load(nifti).shape[-1]\n",
    "                vols_per_task_list[task_id].append(n_vols)\n",
    "\n",
    "            vols_per_task = defaultdict(int)\n",
    "            for k, v in vols_per_task_list.items():\n",
    "                counter = Counter(v)\n",
    "                vols_per_task[k] = counter.most_common(1)[0][0]\n",
    "\n",
    "            for func in funcs:\n",
    "                nifti = Path(f\"{ses_func_dir}/{func}.gz\")\n",
    "                task_id = func.split('task-')[1].split('_')[0]\n",
    "                if task_id == 'wholebrain': continue\n",
    "                run_id = func.split('run-')[1].split('_')[0]\n",
    "                n_vols = nib.load(nifti).shape[-1]\n",
    "                inconsistent_vols = n_vols != vols_per_task[task_id]\n",
    "\n",
    "                # Check if oscprep ran correctly\n",
    "                oscprep_check_wildcards = [\n",
    "                    f\"{sub_id}_{ses_id}_task-{task_id}*run-{run_id}*space-T1w_boldref.nii.gz\",\n",
    "                    f\"{sub_id}_{ses_id}_task-{task_id}*run-{run_id}*space-T1w_desc-boldref_brainmask.nii.gz\",\n",
    "                    f\"{sub_id}_{ses_id}_task-{task_id}*run-{run_id}*space-T1w_desc-preproc_bold.nii.gz\",\n",
    "                    f\"{sub_id}_{ses_id}_task-{task_id}*run-{run_id}*desc-preproc_bold.dtseries.nii\",\n",
    "                    f\"{sub_id}_{ses_id}_task-{task_id}*run-{run_id}*desc-preproc_bold.json\",\n",
    "                    f\"{sub_id}_{ses_id}_task-{task_id}*run-{run_id}*desc-confounds_timeseries.tsv\",\n",
    "                    f\"{sub_id}_{ses_id}_task-{task_id}*run-{run_id}*desc-confounds_timeseries.json\",\n",
    "                ]\n",
    "\n",
    "                preproc_flag = True\n",
    "                preproc_paths = []\n",
    "                for wildcard in oscprep_check_wildcards:\n",
    "                    _path = search(f\"{oscprep_deriv_dir}/bold_preproc/{sub_id}/{ses_id}/func\", wildcard, error=False)\n",
    "                    assert len(_path) in [0,1]\n",
    "                    if len(_path) == 0:\n",
    "                        preproc_flag = False\n",
    "                    else:\n",
    "                        preproc_paths += _path\n",
    "\n",
    "                if preproc_flag and not inconsistent_vols:\n",
    "\n",
    "                    if task_id.startswith((\"localizer\", \"entrain\", \"control\")):\n",
    "\n",
    "                        experiment_search_frequencies = {\n",
    "                            \"localizer_7T\": [.2],\n",
    "                            \"entrain_7T\": [.2, .5],\n",
    "                            \"control_7T\": [.2, .5],\n",
    "                            \"localizer_3T\": [.125],\n",
    "                            \"entrain_3T\": [.125, .2],\n",
    "                            \"control_3T\": [.125, .2],\n",
    "                        }\n",
    "\n",
    "                        stim_start_time = 14\n",
    "                        experiment_stim_end = {\n",
    "                            \"localizer_7T\": stim_start_time+185,\n",
    "                            \"entrain_7T\": stim_start_time+185,\n",
    "                            \"control_7T\": stim_start_time+185,\n",
    "                            \"localizer_3T\": stim_start_time+205,\n",
    "                            \"entrain_3T\": stim_start_time+205,\n",
    "                            \"control_3T\": stim_start_time+205,\n",
    "                        }\n",
    "\n",
    "                        k = f\"{task_id.split('Q')[0]}_{mri_id}\"\n",
    "                        assert k in experiment_search_frequencies.keys()\n",
    "                        search_frequencies = experiment_search_frequencies[k]\n",
    "                        stim_end_time = experiment_stim_end[k]\n",
    "\n",
    "                        for stim_delay_time in [-(stim_start_time-1), 0, 10, 20, 30]:\n",
    "                            \n",
    "                            time_window = (stim_start_time+stim_delay_time, stim_end_time)\n",
    "\n",
    "                            oscprep_dir = f\"/data/{experiment_id}/{mri_id}/bids/derivatives/oscprep_grayords_fmapless\"\n",
    "                            out_dir = f\"/scratch/{experiment_id}/{mri_id}/derivatives/run_level_s{smooth_mm}/truncate-{time_window[0]}-{time_window[1]}\"\n",
    "                            CONTAINER_DIR= '/project/def-mmur/gngo4/containers'\n",
    "\n",
    "                            # Check to see if fla was run to completion by counting number of expected outputs\n",
    "                            n_out = len(search(out_dir,f\"*_experiment-*/{sub_id}/{ses_id}/task-{task_id}/run-{run_id}/GLM/*\", error=False))\n",
    "                            run_flag = (n_out==144) or (n_out==272) # These are expected output amount - manually change this depending on experiment\n",
    "                            # Skip if ran already\n",
    "                            if run_flag:\n",
    "                                continue\n",
    "\n",
    "\n",
    "                            all_run_dirs = f\"/scratch/{experiment_id}/{mri_id}/derivatives/run_level_s{smooth_mm}/truncate-{time_window[0]}-{time_window[1]}/*_experiment-*/{sub_id}/{ses_id}/task-{task_id}/run-{run_id}\"\n",
    "                            #!rm -rf {all_run_dirs}\n",
    "                            print(n_out)\n",
    "                            \n",
    "                        \n",
    "                            print(\n",
    "                                experiment_id, \n",
    "                                mri_id, \n",
    "                                sub_id.split('-')[-1],\n",
    "                                ses_id.split('-')[-1], \n",
    "                                task_id, \n",
    "                                run_id, \n",
    "                                search_frequencies, \n",
    "                                time_window,\n",
    "                            )\n",
    "\n",
    "                            txt = f\"\"\"#!/bin/bash\n",
    "module load apptainer/1.1\n",
    "\n",
    "singularity run \\\\\n",
    "    --bind /project/def-mmur/gngo4/data/fastfmri:/data \\\\\n",
    "    --bind /scratch/gngo4:/scratch \\\\\n",
    "    --bind /project/def-mmur/gngo4/projects/fastfmri_toolbox:/opt/app \\\\\n",
    "    {CONTAINER_DIR}/neuroimaging-notebook-v2.simg \\\\\n",
    "    python3 /opt/app/scripts/fla.py \\\\\n",
    "    {experiment_id} \\\\\n",
    "    {mri_id} \\\\\n",
    "    {oscprep_dir} \\\\\n",
    "    {out_dir} \\\\\n",
    "    {sub_id.split('-')[-1]} \\\\\n",
    "    {ses_id.split('-')[-1]} \\\\\n",
    "    {task_id} \\\\\n",
    "    {run_id} \\\\\n",
    "    {' '.join([str(i) for i in search_frequencies])} \\\\\n",
    "    {' '.join([str(i) for i in time_window])} \\\\\n",
    "    --smooth-mm {smooth_mm}\n",
    "                            \"\"\"\n",
    "                            cmd_path = f\"{scripts_dir}/{experiment_id}_{mri_id}.s{smooth_mm}.trunc-{time_window[0]}-{time_window[1]}.{sub_id}_{ses_id}_task-{task_id}_run-{run_id}_fla.sh\"\n",
    "                            with open(cmd_path, 'w') as f:\n",
    "                                f.write(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794a0d9b-b0b9-4444-8c84-b58615232672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sbatch --time=00:45:00 --mem=32GB --account=def-mmur {cmd_path}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
