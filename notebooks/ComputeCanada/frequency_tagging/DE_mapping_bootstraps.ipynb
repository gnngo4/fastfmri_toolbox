{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/opt/wbplot\")\n",
    "\n",
    "from wbplot import dscalar\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get HCP labels\n",
    "\"\"\"\n",
    "dlabel_dir = Path(\"/opt/app/notebooks/data/dlabels\")\n",
    "hcp_label = dlabel_dir / \"Q1-Q6_RelatedValidation210.CorticalAreas_dil_Final_Final_Areas_Group_Colors.32k_fs_LR.dlabel.nii\"\n",
    "\n",
    "_HCP_INFO = !wb_command -file-information {hcp_label}\n",
    "HCP_LABELS = []\n",
    "HCP_COUNTER = 0\n",
    "for i in _HCP_INFO:\n",
    "    if len(i) == 60 and any([\"L_\" in i, \"R_\" in i]):\n",
    "        hcp_colors = tuple([float(f\"0.{k}\") for k in [j.split(' ') [0] for j in i.split('0.')][-3:]] + [1])\n",
    "        if ' R_' in i:\n",
    "            roi = i.split(\"_ROI\")[0].split(' R_')[1]\n",
    "            HCP_LABELS.append(f\"R_{roi}_ROI\")\n",
    "        if ' L_' in i:\n",
    "            roi = i.split(\"_ROI\")[0].split(' L_')[1]\n",
    "            HCP_LABELS.append(f\"L_{roi}_ROI\")\n",
    "        HCP_COUNTER += 1\n",
    "\n",
    "\"\"\"Get HCP label coordinates\n",
    "\"\"\"\n",
    "dscalar_dir = Path(\"/opt/app/notebooks/data/dscalars\")\n",
    "tmpdir = Path(\"/tmp\")\n",
    "template_dscalar = dscalar_dir / \"S1200.MyelinMap_BC_MSMAll.32k_fs_LR.dscalar.nii\"\n",
    "\n",
    "hcp_mapping = {}\n",
    "for roi_label in HCP_LABELS:\n",
    "    out_dscalar = tmpdir / f\"{roi_label}.dscalar.nii\"\n",
    "    if out_dscalar.exists():\n",
    "        hcp_mapping[roi_label] = out_dscalar\n",
    "        continue\n",
    "    !wb_command -cifti-label-to-roi {hcp_label} {out_dscalar} -name {roi_label}\n",
    "    assert out_dscalar.exists(), f\"{out_dscalar.stem} does not exist.\"\n",
    "    hcp_mapping[roi_label] = out_dscalar\n",
    "hcp_rois = list(set([k.split('_')[1] for k in hcp_mapping.keys()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_fractional_overlap(data):\n",
    "\n",
    "    return data.sum(0) / data.shape[0]\n",
    "\n",
    "def map_data_to_value(data_list):\n",
    "\n",
    "    for ix, (k,v) in enumerate(data_list):\n",
    "\n",
    "        if ix == 0:\n",
    "            new_data = k.copy() * v\n",
    "        else:\n",
    "            new_data += k * v\n",
    "\n",
    "    return new_data\n",
    "\n",
    "def get_quadrant_id(mask_path):\n",
    "    rel_mask_path = mask_path.split(\"/\")[-1]\n",
    "    idx_start = rel_mask_path.find(\"Q\")\n",
    "    quadrant_id = rel_mask_path[idx_start:idx_start+2]\n",
    "    assert quadrant_id in ['Q1', 'Q2'], f\"{quadrant_id} not Q1 or Q2\"\n",
    "\n",
    "    return quadrant_id\n",
    "\n",
    "@lru_cache(maxsize=360)\n",
    "def read_roi_path(roi_path):\n",
    "    return nib.load(roi_path).get_fdata()[0,:]\n",
    "\n",
    "def roi_vertex_counter(\n",
    "    roi_vertex_count,\n",
    "    hcp_mapping,\n",
    "    data,\n",
    "    q_id,\n",
    "):\n",
    "\n",
    "    for roi_label, roi_path in hcp_mapping.items():\n",
    "        if q_id == \"Q1\":\n",
    "            contra = \"L_\"\n",
    "        elif q_id == \"Q2\":\n",
    "            contra = \"R_\"\n",
    "        else:\n",
    "            raise ValueError(f\"{q_id} not supported.\")\n",
    "\n",
    "        if roi_label.startswith(contra):\n",
    "            roi_label = f\"CONTRA_{roi_label[2:-4]}\"\n",
    "        else:\n",
    "            roi_label = f\"IPSI_{roi_label[2:-4]}\"\n",
    "\n",
    "        roi_mask = read_roi_path(roi_path)\n",
    "        assert roi_mask.shape == data.shape\n",
    "        \n",
    "        roi_vertex_count[roi_label].append((roi_mask * data).sum())\n",
    "\n",
    "    return roi_vertex_count\n",
    "\n",
    "\"\"\"Reimplement when mapping code is done\n",
    "def condense_roi_info_across_cohort(sub_ids, roi_vertex_count, sub_threshold=.5):\n",
    "    \n",
    "    n_sub_per_roi = []\n",
    "\n",
    "    n_sub_total = len(sub_ids)\n",
    "    for roi, vertex_count_across_subs in roi_vertex_count.items():\n",
    "        n_sub_per_roi.append(\n",
    "            (\n",
    "                roi, # ROI label\n",
    "                sum([i>0 for i in vertex_count_across_subs])/n_sub_total, # Number of subjects with vertex in a ROI\n",
    "                np.median(vertex_count_across_subs), # Median vertex count\n",
    "            )\n",
    "        )\n",
    "\n",
    "    my_list = [i[2] for i in n_sub_per_roi]\n",
    "    sorted_indices = sorted(range(len(my_list)), key=lambda x: my_list[x], reverse=True)\n",
    "    \n",
    "    condensed_roi_info = []\n",
    "    for i in sorted_indices:\n",
    "        if n_sub_per_roi[i][1]<sub_threshold:\n",
    "            continue\n",
    "        condensed_roi_info.append(n_sub_per_roi[i])\n",
    "\n",
    "    return condensed_roi_info\n",
    "\"\"\"\n",
    "\n",
    "def find_activations(experiment_id, mri_id, roi_task_id, roi_f_1, fo, sub_id, corr_type=\"uncp\", match_str=\"activations.dtseries.nii\"):\n",
    "    \n",
    "    import os\n",
    "\n",
    "    directory = f\"/scratch/fastfmri/experiment-{experiment_id}_mri-{mri_id}_smooth-0_truncate-39-219_n-200_batch-merged_desc-IMall_roi-{roi_task_id}-{roi_f_1}_pval-{corr_type}_fo-{fo}_bootstrap/sub-{sub_id}/bootstrap/\"\n",
    "    activations_files = [file for file in os.listdir(directory) if 'data-train' in file and match_str in file]\n",
    "\n",
    "    if roi_task_id == \"AttendInF1\":\n",
    "        return [f\"{directory}{i}\" for i in activations_files if \"AttendInF1F2\" not in i]\n",
    "    else:\n",
    "        return [f\"{directory}{i}\" for i in activations_files]\n",
    "\n",
    "def set_base_dir(basedir):\n",
    "    basedir = Path(basedir)\n",
    "    if not basedir.exists():\n",
    "        basedir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    return basedir\n",
    "\n",
    "\"\"\"Not used\n",
    "def load_mean_power_dtseries(dtseries):\n",
    "    mean_power = nib.load(dtseries).get_fdata().mean(0)\n",
    "    return mean_power\n",
    "\"\"\"\n",
    "\n",
    "def crop_and_save(input_file, output_file, left, top, right, bottom):\n",
    "    from PIL import Image\n",
    "    try:\n",
    "        # Open the input image\n",
    "        with Image.open(input_file) as img:\n",
    "            # Crop the image\n",
    "            cropped_img = img.crop((left, top, right, bottom))\n",
    "            # Save the cropped image\n",
    "            cropped_img.save(output_file)\n",
    "            print(\"Cropped image saved successfully as\", output_file)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "def get_im_frequencies(f1,f2):\n",
    "    assert f2 > f1, f\"{f2} <= {f1}\"\n",
    "    im_frequencies = {}\n",
    "    im_frequencies[\"first_order\"] = [f1, f2]\n",
    "    f2_sub_f1 = round(f2-f1, 10)\n",
    "    f1_plus_f2 = round(f1+f2, 10)\n",
    "    f1_mul_2 = round(f1*2, 10)\n",
    "    f2_mul_2 = round(f2*2, 10)\n",
    "    f1_mul_2_sub_f2 = round(2*f1-f2, 10)\n",
    "    f2_mul_2_sub_f1 = round(2*f2-f1, 10)\n",
    "    im_frequencies[\"f1f2_f2-f1\"] = [\n",
    "        f1, f2,\n",
    "        f2_sub_f1\n",
    "    ]\n",
    "    im_frequencies[\"f1f2_f1+f2\"] = [\n",
    "        f1, f2,\n",
    "        f1_plus_f2,\n",
    "    ]\n",
    "    im_frequencies[\"f1f2_2f1\"] = [\n",
    "        f1, f2,\n",
    "        f1_mul_2,\n",
    "    ]\n",
    "    im_frequencies[\"f1f2_2f2\"] = [\n",
    "        f1, f2,\n",
    "        f2_mul_2,\n",
    "    ]\n",
    "    im_frequencies[\"f1f2_2f1-f2\"] = [\n",
    "        f1, f2,\n",
    "        f1_mul_2_sub_f2,\n",
    "    ]\n",
    "    im_frequencies[\"f1f2_2f2-f1\"] = [\n",
    "        f1, f2,\n",
    "        f2_mul_2_sub_f1,\n",
    "    ]\n",
    "\n",
    "    return im_frequencies\n",
    "\n",
    "def combine_f1f2_with_im(im_order, im_paths, im_c, fo=1., mask=None, mask_c=.41):\n",
    "    \"\"\"Example inputs\n",
    "    all_paths = [f1, f2, im_product, mask]\n",
    "    im_paths = [f1[0], f2[0], im_product[0]]\n",
    "    im_cs = [-.1, .82] # red, blue, (overlap is yellow [.14])\n",
    "    \"\"\"\n",
    "    f1_data = convert_to_fractional_overlap(nib.load(im_paths[0]).get_fdata())\n",
    "    f1_data = (f1_data >= fo).astype(int)\n",
    "    f2_data = convert_to_fractional_overlap(nib.load(im_paths[1]).get_fdata())\n",
    "    f2_data = (f2_data >= fo).astype(int)\n",
    "    f1f2_data = ((f1_data + f2_data) == 2).astype(int)\n",
    "    im_data = convert_to_fractional_overlap(nib.load(im_paths[2]).get_fdata())\n",
    "    im_data = (im_data >= fo).astype(int)\n",
    "    f1f2im_data = ((f1f2_data + im_data) == 2).astype(int)\n",
    "    im_data -= f1f2im_data\n",
    "    f1f2_data -= f1f2im_data\n",
    "    if mask:\n",
    "        mask_data = convert_to_fractional_overlap(nib.load(mask).get_fdata())\n",
    "        mask_data = (mask_data >= 1.).astype(int)\n",
    "        mask_data -= f1f2im_data\n",
    "        mask_data -= f1f2_data\n",
    "        mask_data -= im_data\n",
    "    data_dict = [(f1f2_data, im_c[0]), (im_data, im_c[1]), (f1f2im_data, .14)]\n",
    "    if mask:\n",
    "        data_dict.append((mask_data,mask_c))\n",
    "    return map_data_to_value(data_dict)\n",
    "\n",
    "def combine_im(\n",
    "    im_order, im_paths, im_c,\n",
    "    fo=1.,\n",
    "    mask=None, \n",
    "    mask_c=.41,\n",
    "):\n",
    "    \n",
    "    if im_order.startswith(\"f1f2\"):\n",
    "        return combine_f1f2_with_im(im_order, im_paths, im_c, fo=fo, mask=mask, mask_c=mask_c)\n",
    "    \n",
    "    if im_order == \"first_order\":\n",
    "        f1_data = convert_to_fractional_overlap(nib.load(im_paths[0]).get_fdata())\n",
    "        f1_data = (f1_data >= fo).astype(int)\n",
    "        f2_data = convert_to_fractional_overlap(nib.load(im_paths[1]).get_fdata())\n",
    "        f2_data = (f2_data >= fo).astype(int)\n",
    "        f1f2_data = ((f1_data + f2_data) == 2).astype(int)\n",
    "        f1_data -= f1f2_data\n",
    "        f2_data -= f1f2_data\n",
    "        if mask:\n",
    "            mask_data = convert_to_fractional_overlap(nib.load(mask).get_fdata())\n",
    "            mask_data = (mask_data >= 1.).astype(int)\n",
    "            mask_data -= f1f2_data\n",
    "            mask_data -= f1_data\n",
    "            mask_data -= f2_data\n",
    "        data_dict = [(f1_data, im_c[0]), (f2_data, im_c[1]), (f1f2_data, .14)]\n",
    "        if mask:\n",
    "            data_dict.append((mask_data,mask_c))\n",
    "        return map_data_to_value(data_dict)\n",
    "\n",
    "def merge_and_binarize_mask(data, im_order, im_c, mask_c=.41):\n",
    "\n",
    "    if im_order == \"first_order\":\n",
    "        new_data = data.copy()\n",
    "        new_data[(new_data == im_c[0]) | (new_data == im_c[1]) | (new_data == .14)] = 1\n",
    "        new_data[new_data == mask_c] = 0\n",
    "\n",
    "        return new_data\n",
    "    \n",
    "    if im_order.startswith(\"f1f2\"):\n",
    "        new_data = data.copy()\n",
    "        new_data[(new_data == im_c[0]) | (new_data == im_c[1]) | (new_data == .14)] = 1\n",
    "        new_data[new_data == mask_c] = 0\n",
    "\n",
    "        return new_data\n",
    "\n",
    "def generate_single_subject_maps(\n",
    "    experiment_id, mri_id, sub_ids, \n",
    "    roi_task_ids, im_frequencies, \n",
    "    ROI_FO=.8, SUB_THRESHOLD=.5,\n",
    "    LEFT=600, TOP=120, RIGHT=1120, BOTTOM=420, VERTEX_TO = 59412,\n",
    "    mask_c = .41, PALETTE=\"power_surf\",\n",
    "    SKIP_IF_EXISTS=True, corr_type=\"uncp\"\n",
    "):\n",
    "    roi_vertex_count = defaultdict(list)\n",
    "\n",
    "    for ix, (sub_id, roi_task_id, im_frequencies) in enumerate(zip(\n",
    "        sub_ids,\n",
    "        roi_task_ids, \n",
    "        im_frequencies,\n",
    "    )):\n",
    "        for im_order, im_f in im_frequencies.items():\n",
    "            im_order_str = im_order.replace(\"f1f2_\", \"f1f2U\")\n",
    "            if im_order == \"first_order\":\n",
    "                im_order_str = \"f1Uf2\"\n",
    "            png_out = Path(set_base_dir(f\"./ComputeCanada/frequency_tagging/figures/data_exploration/bootstrapped_rois/{experiment_id}/mri-{mri_id}/sub-{sub_id}/figures\")) / f\"sub-{sub_id}_task-{roi_task_id}-{corr_type}_im-{im_order_str}_fo-{ROI_FO}.png\"\n",
    "            if png_out.exists() and SKIP_IF_EXISTS:\n",
    "                return None\n",
    "            mask = find_activations(experiment_id, mri_id, roi_task_id, im_frequencies['first_order'][0], .8, sub_id, corr_type=corr_type, match_str=\"mask.dtseries.nii\")\n",
    "            if im_order == \"first_order\":\n",
    "                try:\n",
    "                    f1 = find_activations(experiment_id, mri_id, roi_task_id, im_f[0], .8, sub_id, corr_type=corr_type, match_str=\"activations.dtseries.nii\")\n",
    "                    f2 = find_activations(experiment_id, mri_id, roi_task_id, im_f[1], .8, sub_id, corr_type=corr_type, match_str=\"activations.dtseries.nii\")\n",
    "                    all_paths = [f1, f2, mask]\n",
    "                    im_paths = [f1[0], f2[0]]\n",
    "                    im_cs = [-.1, .82] # red, blue, (overlap is white)\n",
    "                except:\n",
    "                    print(f\"\\n\\n\\nSkipping: {sub_id} {roi_task_id} {im_f}\\n\\n\\n\")\n",
    "                    continue\n",
    "            elif im_order.startswith(\"f1f2\"):\n",
    "                try:\n",
    "                    f1 = find_activations(experiment_id, mri_id, roi_task_id, im_f[0], .8, sub_id, corr_type=corr_type, match_str=\"activations.dtseries.nii\")\n",
    "                    f2 = find_activations(experiment_id, mri_id, roi_task_id, im_f[1], .8, sub_id, corr_type=corr_type, match_str=\"activations.dtseries.nii\")\n",
    "                    im_product = find_activations(experiment_id, mri_id, roi_task_id, im_f[2], .8, sub_id, corr_type=corr_type, match_str=\"activations.dtseries.nii\")\n",
    "                    all_paths = [f1, f2, im_product, mask]\n",
    "                    im_paths = [f1[0], f2[0], im_product[0]]\n",
    "                    im_cs = [-.1, .82] # red, blue, (overlap is white)\n",
    "                except:\n",
    "                    print(f\"\\n\\n\\nSkipping: {sub_id} {roi_task_id} {im_f}\\n\\n\\n\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "            for f in all_paths:\n",
    "                assert len(f) == 1, f\"{roi_task_id}, {f}\"\n",
    "\n",
    "            data = combine_im(im_order, im_paths, im_cs, fo=ROI_FO, mask=mask[0], mask_c=mask_c)\n",
    "            data = data[:VERTEX_TO]\n",
    "            map_data = merge_and_binarize_mask(data, im_order, im_cs)\n",
    "            q_id = get_quadrant_id(mask[0])\n",
    "            roi_vertex_count = roi_vertex_counter(roi_vertex_count, hcp_mapping, map_data, q_id)\n",
    "\n",
    "            palette_params = {\n",
    "                \"disp-zero\": False,\n",
    "                \"disp-neg\": True,\n",
    "                \"disp-pos\": True,\n",
    "                \"pos-user\": (0, 1.),\n",
    "                \"neg-user\": (-1,0),\n",
    "                \"interpolate\": True,\n",
    "            }\n",
    "            dscalar(\n",
    "                png_out, data, \n",
    "                orientation=\"portrait\", \n",
    "                hemisphere='right',\n",
    "                palette=PALETTE, \n",
    "                palette_params=palette_params,\n",
    "                transparent=False,\n",
    "                flatmap=True,\n",
    "                flatmap_style='plain',\n",
    "            )\n",
    "            #crop_and_save(png_out, str(png_out).replace(\"png\", \"cropped.png\"), LEFT, TOP, RIGHT, BOTTOM)\n",
    "\n",
    "    \"\"\"\n",
    "    roi_cohort_info = condense_roi_info_across_cohort(\n",
    "        sub_ids, \n",
    "        roi_vertex_count, \n",
    "        sub_threshold=SUB_THRESHOLD\n",
    "    )\n",
    "    \"\"\"\n",
    "    return None\n",
    "    return roi_cohort_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Set up for visualizing dual frequency tagging across each subject using fractional overlap\n",
    "\"\"\"\n",
    "cohort_roi_info_across_experiments = {}\n",
    "ROI_FOS = [.2, .8, 1.]\n",
    "SKIP_IF_EXISTS=True\n",
    "\n",
    "\"\"\"Save png\n",
    "\"\"\"\n",
    "for corr_type in [\"fdrp\", \"uncp\"]:\n",
    "    # 3T normal\n",
    "    f1, f2 = .125, .2\n",
    "    cohort_roi_info = defaultdict(list)\n",
    "    for ROI_FO in ROI_FOS:\n",
    "        experiment_id = \"1_frequency_tagging\" \n",
    "        mri_id = \"3T\"\n",
    "        sub_ids = [\"000\", \"002\", \"003\", \"004\", \"005\", \"006\", \"007\", \"008\", \"009\"] \n",
    "        roi_task_ids = [\"entrain\"] * len(sub_ids)\n",
    "        im_frequencies = [get_im_frequencies(f1, f2)] * len(sub_ids)\n",
    "        cohort_roi_info = generate_single_subject_maps(\n",
    "            experiment_id, mri_id, sub_ids, \n",
    "            roi_task_ids, im_frequencies, \n",
    "            ROI_FO=ROI_FO, SUB_THRESHOLD=.5, corr_type=corr_type,SKIP_IF_EXISTS=SKIP_IF_EXISTS\n",
    "        )\n",
    "    # 7T normal\n",
    "    f1, f2 = .125, .2\n",
    "    cohort_roi_info = defaultdict(list)\n",
    "    for ROI_FO in ROI_FOS:\n",
    "        experiment_id = \"1_attention\" \n",
    "        mri_id = \"7T\"\n",
    "        sub_ids = [\"Pilot001\", \"Pilot009\", \"Pilot010\", \"Pilot011\"]\n",
    "        roi_task_ids = [\"AttendAway\"] * len(sub_ids)\n",
    "        im_frequencies = [get_im_frequencies(f1, f2)] * len(sub_ids)\n",
    "        cohort_roi_info = generate_single_subject_maps(\n",
    "            experiment_id, mri_id, sub_ids, \n",
    "            roi_task_ids, im_frequencies, \n",
    "            ROI_FO=ROI_FO, SUB_THRESHOLD=.5, corr_type=corr_type,SKIP_IF_EXISTS=SKIP_IF_EXISTS\n",
    "        )\n",
    "    # 3T/7T vary\n",
    "    for label, mri_id in zip([\"3TVary\", \"7TVary\"], [\"3T\", \"7T\"]):\n",
    "        cohort_roi_info = defaultdict(list)\n",
    "        for ROI_FO in ROI_FOS:\n",
    "            experiment_id = \"1_frequency_tagging\"\n",
    "            sub_ids = [\"020\"] * 3 + [\"021\"] * 3\n",
    "            roi_task_ids = [f\"entrain{i}\" for i in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]]\n",
    "            im_frequencies = [\n",
    "                get_im_frequencies(.125, .2),\n",
    "                get_im_frequencies(.125, .175),\n",
    "                get_im_frequencies(.125, .15),\n",
    "                get_im_frequencies(.125, .2),\n",
    "                get_im_frequencies(.15, .2),\n",
    "                get_im_frequencies(.175, .2),\n",
    "            ]\n",
    "            cohort_roi_info = generate_single_subject_maps(\n",
    "                experiment_id, mri_id, sub_ids, \n",
    "                roi_task_ids, im_frequencies, \n",
    "                ROI_FO=ROI_FO, SUB_THRESHOLD=.5\n",
    "            )\n",
    "    # 7T attention\n",
    "    f1, f2 = .125, .2\n",
    "    cohort_roi_info = defaultdict(list)\n",
    "    for ROI_FO in ROI_FOS:\n",
    "        experiment_id = \"1_attention\" \n",
    "        mri_id = \"7T\"\n",
    "        sub_ids = [\"010\", \"011\", \"012\", \"013\", \"014\", \"015\", \"016\"] \n",
    "        roi_task_ids = [\"AttendAway\"] * len(sub_ids) + [\"AttendInF1\"] * len(sub_ids) + [\"AttendInF2\"] * len(sub_ids) + [\"AttendInF1F2\"] * len(sub_ids)\n",
    "        im_frequencies = [get_im_frequencies(f1, f2)] * len(sub_ids) * 4\n",
    "        sub_ids = [\"010\", \"011\", \"012\", \"013\", \"014\", \"015\", \"016\"] * 4\n",
    "        cohort_roi_info = generate_single_subject_maps(\n",
    "            experiment_id, mri_id, sub_ids, \n",
    "            roi_task_ids, im_frequencies, \n",
    "            ROI_FO=ROI_FO, SUB_THRESHOLD=.5, corr_type=corr_type,SKIP_IF_EXISTS=SKIP_IF_EXISTS\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
