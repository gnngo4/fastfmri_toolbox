{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a58a56a7-c6dd-4431-9705-7175fff661b7",
   "metadata": {},
   "source": [
    "### Running run-level frequency-based modelling on ComputeCanada\n",
    "##### Inputs\n",
    " - `scripts_dir`: location of outputted sbatch scripts. \n",
    " - `experiment_ids`: *experiment_id* directory found under\n",
    "     - **/project/def-mmur/gngo4/data/fastfmri**\n",
    " - `mri_ids`: *mri_id* directory found under,\n",
    "     - **/project/def-mmur/gngo4/data/fastfmri/{experiment_id}**\n",
    " - `oscprep_dir`: minimal preprocessed directory (using *https://github.com/gnngo4/oscprep*) found under,\n",
    "     -  **/project/def-mmur/gngo4/data/fastfmri/{experiment_id}/{mri_id}/bids/derivatives**\n",
    " - `smooth_mm`: surface smoothing parameter (*mm*) (only works if the `fla.py ... --image-type == CIFTI`)\n",
    " - `relevant_task_ids`: tuple containing all frequency-based task paradigms of interest\n",
    " - `experiment_search_frequencies`: search frequencies (*Hz*) associated to each `task_id` and `mri_id`\n",
    " - `stim_start_time`: stimulus start time (*s*)\n",
    " - `stim_rampup_times`: List of ramp-up times (*s*) used to determine truncation window of the BOLD data\n",
    " - `experiment_stim_end`: stimulus stop time (*s*) associated to each `task_id` and `mri_id`\n",
    " - `CONTAINER`: Set the container path used to run the sbatch script\n",
    " - `image_type`: Set processing of either CIFTI or NIFTI\n",
    "##### Outputs\n",
    " - Denoising outputs found under,\n",
    "     - **/scratch/{experiment_id}/{mri_id}/derivatives/run_level_s{smooth_mm}/truncate-{time_window[0]}-{time_window[1]}**\n",
    "     - `time_window` = (`stim_start_time`+`stim_rampup_time`, **stim_end_time**)\n",
    "         - **stim_end_time**: taken from `experiment_stim_end`\n",
    "##### sbatch example settings\n",
    "sbatch --time=00:10:00 --cpus-per-task=1 --mem-per-cpu=4GB --account=def-mmur {script.sh}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910a4451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import itertools\n",
    "import glob\n",
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from ComputeCanada.frequency_tagging.study_info import (\n",
    "    frequency_tagging_settings,\n",
    "    attention_settings,\n",
    "    setting_exceptions,\n",
    ")\n",
    "SMOOTH_OVERRIDE = 0\n",
    "SETTINGS = attention_settings\n",
    "scripts_dir = \"/data/scripts/03a_run_level\"\n",
    "experiment_ids, mri_ids, oscprep_dir, smooth_mm, relevant_task_ids, experiment_search_frequencies, TR, stim_start_time, stim_rampup_time, experiment_stim_end, CONTAINER, image_type = SETTINGS.values()\n",
    "if SMOOTH_OVERRIDE is not None:\n",
    "    smooth_mm = SMOOTH_OVERRIDE\n",
    "\n",
    "assert image_type in ['CIFTI', 'NIFTI']\n",
    "\n",
    "# Output sbatch scripts here\n",
    "scripts_dir = Path(scripts_dir)\n",
    "if not scripts_dir.exists():\n",
    "    scripts_dir.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e81ae98-96ea-4a4b-8937-34575b0e0130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions\n",
    "\"\"\"\n",
    "\n",
    "def search(base_dir, wildcard, error=True):\n",
    "    search_path = Path(base_dir) / wildcard\n",
    "    files = glob.glob(str(search_path))\n",
    "\n",
    "    if not files:\n",
    "        if error:\n",
    "            raise FileNotFoundError(f\"No files were found in: {search_path}\")\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    return files\n",
    "\n",
    "# Iterate over `experiment_ids` and `mri_ids`\n",
    "for experiment_id, mri_id in itertools.product(experiment_ids, mri_ids):\n",
    "    # Set base directory\n",
    "    base_bids_dir = f'/data/{experiment_id}/{mri_id}/bids'\n",
    "    # Set minimal preprocessed directory\n",
    "    oscprep_deriv_dir = f\"{base_bids_dir}/derivatives/{oscprep_dir}\"\n",
    "    assert Path(oscprep_deriv_dir).exists()\n",
    "    # Find all subjects\n",
    "    sub_ids = [Path(i).stem for i in search(base_bids_dir, 'sub-*')]\n",
    "    sub_ids.sort()\n",
    "\n",
    "    # Iterate over subjects\n",
    "    for sub_ix, sub_id in enumerate(sub_ids):\n",
    "        # change settings based on exceptions\n",
    "        settings = setting_exceptions(experiment_id, mri_id, sub_id, SETTINGS.copy())\n",
    "        experiment_ids, mri_ids, oscprep_dir, smooth_mm, relevant_task_ids, experiment_search_frequencies, TR, stim_start_time, stim_rampup_time, experiment_stim_end, CONTAINER, image_type = settings.values()\n",
    "        if SMOOTH_OVERRIDE is not None:\n",
    "            smooth_mm = SMOOTH_OVERRIDE\n",
    "        # Set subject directory\n",
    "        sub_dir = f'{base_bids_dir}/{sub_id}'\n",
    "        # Find all sessions\n",
    "        ses_ids = [Path(i).stem for i in search(sub_dir, 'ses-*')]\n",
    "        ses_ids.sort()\n",
    "\n",
    "        # Iterate over sessions\n",
    "        for ses_ix, ses_id in enumerate(ses_ids):\n",
    "\n",
    "            # Set subject and session bold directory\n",
    "            ses_func_dir = f'{sub_dir}/{ses_id}/func'\n",
    "            # Find all bold runs\n",
    "            funcs = [Path(i).stem for i in search(ses_func_dir, '*part-mag_bold.nii.gz')]\n",
    "            funcs.sort()\n",
    "            # Find the number of volumes for each task, and store in a dictionary\n",
    "            # `vols_per_task`: Dict[task_id, n_vols]\n",
    "            vols_per_task_list = defaultdict(list)\n",
    "            for func in funcs:\n",
    "                nifti = Path(f\"{ses_func_dir}/{func}.gz\")\n",
    "                task_id = func.split('task-')[1].split('_')[0]\n",
    "                if task_id == 'wholebrain': continue\n",
    "                n_vols = nib.load(nifti).shape[-1]\n",
    "                vols_per_task_list[task_id].append(n_vols)\n",
    "            vols_per_task = defaultdict(int)\n",
    "            for k, v in vols_per_task_list.items():\n",
    "                counter = Counter(v)\n",
    "                vols_per_task[k] = counter.most_common(1)[0][0]\n",
    "\n",
    "            # Iterate over all bold runs\n",
    "            for func in funcs:\n",
    "                # Set nifti path\n",
    "                nifti = Path(f\"{ses_func_dir}/{func}.gz\")\n",
    "                # Parse some nifti info\n",
    "                task_id = func.split('task-')[1].split('_')[0]\n",
    "                run_id = func.split('run-')[1].split('_')[0]\n",
    "                n_vols = nib.load(nifti).shape[-1]\n",
    "                \"\"\"\n",
    "                Skipping heuristics\n",
    "                \"\"\"\n",
    "                inconsistent_vols = n_vols != vols_per_task[task_id] # Skip if inconsistent volumes\n",
    "                task_is_wholebrain = task_id == 'wholebrain' # Skip if task_id == 'wholebrain'\n",
    "                # Skip if minimal preprocessing (via oscprep) did not run\n",
    "                oscprep_check_wildcards = [\n",
    "                    f\"{sub_id}_{ses_id}_task-{task_id}*run-{run_id}*space-T1w_boldref.nii.gz\",\n",
    "                    f\"{sub_id}_{ses_id}_task-{task_id}*run-{run_id}*space-T1w_desc-boldref_brainmask.nii.gz\",\n",
    "                    f\"{sub_id}_{ses_id}_task-{task_id}*run-{run_id}*space-T1w_desc-preproc_bold.nii.gz\",\n",
    "                    f\"{sub_id}_{ses_id}_task-{task_id}*run-{run_id}*desc-preproc_bold.dtseries.nii\",\n",
    "                    f\"{sub_id}_{ses_id}_task-{task_id}*run-{run_id}*desc-preproc_bold.json\",\n",
    "                    f\"{sub_id}_{ses_id}_task-{task_id}*run-{run_id}*desc-confounds_timeseries.tsv\",\n",
    "                    f\"{sub_id}_{ses_id}_task-{task_id}*run-{run_id}*desc-confounds_timeseries.json\",\n",
    "                ]\n",
    "                preproc_flag = True\n",
    "                preproc_paths = []\n",
    "                for wildcard in oscprep_check_wildcards:\n",
    "                    _path = search(f\"{oscprep_deriv_dir}/bold_preproc/{sub_id}/{ses_id}/func\", wildcard, error=False)\n",
    "                    assert len(_path) in [0,1], f\"{wildcard}\\n{_path}\"\n",
    "                    if len(_path) == 0:\n",
    "                        preproc_flag = False\n",
    "                    else:\n",
    "                        preproc_paths += _path\n",
    "                # Skip\n",
    "                if inconsistent_vols or task_is_wholebrain or not preproc_flag:\n",
    "                    continue\n",
    "                \n",
    "                # Run if task_id is found in `relevant_task_ids`\n",
    "                if task_id.startswith(relevant_task_ids):\n",
    "                    # Set key to parse input metadata\n",
    "                    k = f\"{task_id.split('Q')[0]}_{mri_id}\"\n",
    "                    assert k in experiment_search_frequencies.keys(), f\"{k} is not a key in `experiment_search_frequencies`\"\n",
    "                    assert k in experiment_stim_end.keys(), f\"{k} is not a key in `experiment_stim_end`\"\n",
    "                    # Parse experiment relevant info\n",
    "                    search_frequencies = experiment_search_frequencies[k]\n",
    "                    stim_end_time = experiment_stim_end[k]\n",
    "                    \n",
    "                    # Set truncation time window in seconds\n",
    "                    time_window = (stim_start_time+stim_rampup_time, stim_end_time)\n",
    "                    # TODO: add assertion statement here to ensure time_window is bounded by the bold data\n",
    "                    # Set output directory\n",
    "                    out_dir = f\"/scratch/fastfmri/experiment-{experiment_id}_mri-{mri_id}_smooth-{smooth_mm}_truncate-{time_window[0]}-{time_window[1]}_desc-denoised_bold\"\n",
    "                    # TODO: check whether bold denoising has already been performed, skip otherwise\n",
    "                    n_out = len(search(out_dir, f\"*_experiment-*/{sub_id}/{ses_id}/task-{task_id}/run-{run_id}/GLM/*\", error=False))\n",
    "                    if n_out == 2:\n",
    "                        continue\n",
    "                    # Verbose, print some stuff\n",
    "                    print(\n",
    "                        experiment_id, \n",
    "                        mri_id, \n",
    "                        sub_id.split('-')[-1],\n",
    "                        ses_id.split('-')[-1], \n",
    "                        task_id, \n",
    "                        run_id, \n",
    "                        search_frequencies, \n",
    "                        time_window,\n",
    "                    )\n",
    "                    # Print sbatch scripts to `scripts_dir`\n",
    "                    txt = f\"\"\"#!/bin/bash\n",
    "module load apptainer/1.2.4\n",
    "\n",
    "singularity run \\\\\n",
    "--bind /project/def-mmur/gngo4/data/fastfmri:/data \\\\\n",
    "--bind /scratch/gngo4:/scratch \\\\\n",
    "--bind /project/def-mmur/gngo4/projects/fastfmri_toolbox:/opt/app \\\\\n",
    "{CONTAINER} \\\\\n",
    "python3 /opt/app/scripts/fla.py \\\\\n",
    "{experiment_id} \\\\\n",
    "{mri_id} \\\\\n",
    "{oscprep_deriv_dir} \\\\\n",
    "{out_dir} \\\\\n",
    "{sub_id.split('-')[-1]} \\\\\n",
    "{ses_id.split('-')[-1]} \\\\\n",
    "{task_id} \\\\\n",
    "{run_id} \\\\\n",
    "{' '.join([str(i) for i in search_frequencies])} \\\\\n",
    "{' '.join([str(i) for i in time_window])} \\\\\n",
    "--smooth-mm {smooth_mm} \\\\\n",
    "--image-type {image_type} \\\\\n",
    "--denoise-only\n",
    "                    \"\"\"\n",
    "                    cmd_path = f\"{scripts_dir}/experiment-{experiment_id}_mri-{mri_id}_smooth-{smooth_mm}_truncate-{time_window[0]}-{time_window[1]}.{sub_id}_{ses_id}_task-{task_id}_run-{run_id}_fla.sh\"\n",
    "                    with open(cmd_path, 'w') as f:\n",
    "                        f.write(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1aca5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
