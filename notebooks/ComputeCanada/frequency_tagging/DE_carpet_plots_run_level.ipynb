{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_pickle(pkl_path):\n",
    "    with open(pkl_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = \"1_frequency_tagging\"\n",
    "mri_id = \"3T\"\n",
    "deriv_dir_base = \"oscprep_grayords_fmapless\"\n",
    "deriv_dir = f\"/data/{experiment_id}/{mri_id}/bids/derivatives/{deriv_dir_base}/bold_preproc\"\n",
    "sub_ids = !ls {deriv_dir}\n",
    "for sub_id in sub_ids:\n",
    "    ses_ids = !ls {deriv_dir}/{sub_id}\n",
    "    for ses_id in ses_ids:\n",
    "        dtseries = !ls {deriv_dir}/{sub_id}/{ses_id}/func/*dtseries.nii\n",
    "        for raw_bold in dtseries:\n",
    "            task_id = raw_bold.split(\"_task-\")[1].split(\"_\")[0]\n",
    "            if not any([task_id.startswith(\"Attend\"), task_id.startswith(\"entrain\"), task_id.startswith(\"control\")]):\n",
    "                continue\n",
    "            task_id = f\"task-{task_id}\"\n",
    "\n",
    "            run_id = raw_bold.split(\"_run-\")[1].split(\"_\")[0]\n",
    "            run_id = f\"run-{run_id}\"\n",
    "            \n",
    "            sub_base = f\"{sub_id}_{ses_id}_{task_id}_{run_id}\"\n",
    "            \n",
    "            raw_bold = !ls {deriv_dir}/{sub_id}/{ses_id}/func/{sub_id}_{ses_id}_{task_id}_*_{run_id}_desc-preproc_bold.dtseries.nii\n",
    "            confounds = !ls {deriv_dir}/{sub_id}/{ses_id}/func/{sub_id}_{ses_id}_{task_id}_*_{run_id}_desc-confounds_timeseries.tsv\n",
    "            for i in [raw_bold, confounds]:\n",
    "                assert len(i) == 1\n",
    "\n",
    "            denoised_bold = Path(\"/scratch/fastfmri\") / f\"experiment-{experiment_id}_mri-{mri_id}_smooth-0_truncate-39-219_desc-denoised_bold\" / \"00_experiment-min+motion24+wmcsfmean\" / sub_id / ses_id / task_id / run_id/ \"GLM\" / f\"{sub_base}_desc-denoised_bold.dtseries.nii\"\n",
    "            \n",
    "            if not denoised_bold.exists():\n",
    "                continue\n",
    "            \n",
    "            nvols = nib.load(raw_bold[0]).shape[0]\n",
    "\n",
    "            data = {\n",
    "                \"raw_bold\": Path(raw_bold[0]),\n",
    "                \"confounds\": Path(confounds[0]),\n",
    "                \"denoised_bold\": denoised_bold,\n",
    "                \"eyetracking\": Path(\"/data/behaviour\") / \"eyetracking\" / experiment_id / mri_id / f\"{sub_base}_eyetracking.pkl\", \n",
    "                \"fingertracking\": Path(\"/data/behaviour\") / \"fingertracking\" / experiment_id / mri_id / f\"{sub_base}_fingertracking.pkl\", \n",
    "            }\n",
    "\n",
    "            all_exists = True\n",
    "            for k, v in data.items():\n",
    "                if not v.exists():\n",
    "                    print(f\"[{sub_base} - {k} - n_vols: {nvols}] {v} not found.\")\n",
    "                    all_exists = False\n",
    "\n",
    "            if all_exists and \"task-entrain\" in str(data['raw_bold']):\n",
    "                import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carpet plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pkl(datadir, n_bootstraps, sub_id, roi_task_id, roi_frequency, task_id, experiment_id=\"1_frequency_tagging\", mri_id=\"7T\", fo=.8, corr_type='fdrp', roi_frequency_2=None, control_roi_size=False):\n",
    "\n",
    "    import pickle\n",
    "\n",
    "    if roi_frequency_2 is not None:\n",
    "        if control_roi_size:\n",
    "            bootstrap_pkl: Path = datadir / f\"experiment-{experiment_id}_mri-{mri_id}_smooth-0_truncate-39-219_n-{n_bootstraps}_batch-merged_desc-IMall_roi-{roi_task_id}-{roi_frequency}_controlroisizetomatch-{roi_frequency_2}_pval-{corr_type}_fo-{fo}_bootstrap/sub-{sub_id}/bootstrap/task-{task_id}_bootstrapped_data.pkl\"\n",
    "        else:\n",
    "            bootstrap_pkl: Path = datadir / f\"experiment-{experiment_id}_mri-{mri_id}_smooth-0_truncate-39-219_n-{n_bootstraps}_batch-merged_desc-IMall_roi-{roi_task_id}-{roi_frequency}-{roi_frequency_2}_pval-{corr_type}_fo-{fo}_bootstrap/sub-{sub_id}/bootstrap/task-{task_id}_bootstrapped_data.pkl\"\n",
    "    else:\n",
    "        bootstrap_pkl: Path = datadir / f\"experiment-{experiment_id}_mri-{mri_id}_smooth-0_truncate-39-219_n-{n_bootstraps}_batch-merged_desc-IMall_roi-{roi_task_id}-{roi_frequency}_pval-{corr_type}_fo-{fo}_bootstrap/sub-{sub_id}/bootstrap/task-{task_id}_bootstrapped_data.pkl\"\n",
    "    if not bootstrap_pkl.exists():\n",
    "        print(f\"Warning: {bootstrap_pkl} does not exist.\\nReturn None\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Reading: {bootstrap_pkl}\")\n",
    "    with open(bootstrap_pkl, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    return data\n",
    "\n",
    "def find_quadrant_id_from_keys(_dict):\n",
    "    for i in _dict.keys():\n",
    "        if task_id in i:\n",
    "            q_idx = i.find(\"Q\")\n",
    "            q_id = i[q_idx:q_idx+2]\n",
    "            assert q_id in ['Q1', 'Q2']\n",
    "            return q_id\n",
    "    raise ValueError(\"No quadrant id found.\")\n",
    "\n",
    "def pad_denoised_data(denoised_bold_data, n_tps_raw, timepoints_raw, timepoints_denoised):\n",
    "\n",
    "    n_tps_denoised = denoised_bold_data.shape[0]\n",
    "    n_vertices = denoised_bold_data.shape[1]\n",
    "\n",
    "    first_denoised_tp = timepoints_denoised[0]\n",
    "    start_ix = None\n",
    "    for ix, i in enumerate(timepoints_raw):\n",
    "        if i == first_denoised_tp:\n",
    "            start_ix = ix\n",
    "    assert start_ix is not None\n",
    "\n",
    "    start_paddings = np.ones((start_ix, n_vertices)) * -1\n",
    "    end_paddings = np.ones((n_tps_raw - start_ix - n_tps_denoised, n_vertices)) * -1\n",
    "\n",
    "    return np.vstack([start_paddings, denoised_bold_data, end_paddings])\n",
    "\n",
    "def custom_colormap():\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    # Create the base colormap (Blue-White-Red)\n",
    "    bwr = plt.cm.bwr\n",
    "    \n",
    "    # Extract colors from the Blue-White-Red colormap\n",
    "    bwr_colors = bwr(np.linspace(0, 1, 256))\n",
    "    \n",
    "    # Replace all values of -1 with grey\n",
    "    bwr_colors[0] = (0.5, 0.5, 0.5, .5)  # Grey color\n",
    "    \n",
    "    # Create a new colormap with the modified colors\n",
    "    custom_cmap = LinearSegmentedColormap.from_list('custom_bwr', bwr_colors)\n",
    "    \n",
    "    return custom_cmap\n",
    "\n",
    "def load_bold_data(\n",
    "    raw_bold_path, raw_ax,\n",
    "    denoised_bold_path, denoised_ax,\n",
    "    truncate_window, repetition_time,\n",
    "    experiment_id, mri_id, sub_id, task_id, frequencies, \n",
    "    roi_task_id,\n",
    "    corr_type=\"fdrp\", roi_frequency_2=None, control_roi_size=False, fo=.8,\n",
    "    datadir = Path(\"/scratch/fastfmri\"),\n",
    "    n_bootstraps = 200, period_offset = 2,\n",
    "    vmin=-.05, vmax=.05, # [-5,5] %BOLD\n",
    "):\n",
    "    assert corr_type in [\"fdrp\", \"uncp\"]\n",
    "\n",
    "    if not raw_bold_path.exists() or not denoised_bold_path.exists():\n",
    "        return None\n",
    "\n",
    "    # Load pre-generated pickles\n",
    "    f_data = {}\n",
    "    for roi_f in frequencies:\n",
    "        f_data[roi_f] = read_pkl(\n",
    "            datadir, \n",
    "            n_bootstraps, \n",
    "            sub_id.split('-')[-1], \n",
    "            roi_task_id, \n",
    "            roi_f, \n",
    "            task_id.split('-')[-1].split(\"Q\")[0],\n",
    "            experiment_id=experiment_id,\n",
    "            mri_id=mri_id,\n",
    "            fo=fo,\n",
    "            corr_type=corr_type,\n",
    "            roi_frequency_2=roi_frequency_2,\n",
    "            control_roi_size=control_roi_size,\n",
    "        )\n",
    "    # Get vertex coordinates of f1, f2, f1/f2\n",
    "    assert frequencies[1]>frequencies[0]\n",
    "    f1_dict = f_data[frequencies[0]].copy()\n",
    "    f2_dict = f_data[frequencies[1]].copy()\n",
    "    f1_coords = f1_dict['roi_coords']\n",
    "    f2_coords = f2_dict['roi_coords']\n",
    "    f1_only_coords = f1_coords.astype(int) + f2_coords.astype(int)\n",
    "    f1_only_coords = f1_only_coords[f1_coords]\n",
    "    f2_only_coords = f1_coords.astype(int) + f2_coords.astype(int)\n",
    "    f2_only_coords = f2_only_coords[f2_coords]\n",
    "    # Masks\n",
    "    inter_from_f1 = f1_only_coords == 2\n",
    "    f1_from_f1 = f1_only_coords == 1\n",
    "    f2_from_f2 = f2_only_coords == 1\n",
    "    n_f1, n_f1f2, n_f2 = f1_from_f1.sum(), inter_from_f1.sum(), f2_from_f2.sum()\n",
    "    #print(n_f1, n_f1f2, n_f2)\n",
    "    # Load bold data\n",
    "    bold_data = {}\n",
    "    for bold_type, bold_path in zip([\"raw\", \"denoised\"], [raw_bold_path, denoised_bold_path]):\n",
    "        bold_data[bold_type] = nib.load(bold_path).get_fdata()\n",
    "    # Get timepoints of data\n",
    "    n_tps_raw = bold_data['raw'].shape[0]\n",
    "    timepoints_raw = np.arange(repetition_time, repetition_time*n_tps_raw+repetition_time, repetition_time)\n",
    "    n_tps_denoised = bold_data['denoised'].shape[0]\n",
    "    timepoints_denoised = np.arange(repetition_time, truncate_window[1]+repetition_time, repetition_time)[-n_tps_denoised:]\n",
    "    assert n_tps_denoised < n_tps_raw\n",
    "    assert timepoints_denoised.shape[0] == n_tps_denoised\n",
    "    assert timepoints_raw.shape[0] == n_tps_raw\n",
    "    # Convert to percent BOLD change \n",
    "    baseline = bold_data['denoised'].mean(0)\n",
    "    bold_data['raw'] = ((bold_data['raw'] - baseline) / baseline).T\n",
    "    bold_data['denoised'] = ((bold_data['denoised'] - baseline) / baseline).T\n",
    "    # Extract vertices from bold_data\n",
    "    selected_bold_data = {}\n",
    "    selected_bold_data['raw'] = np.hstack([\n",
    "            bold_data['raw'][f1_coords,:][f1_from_f1,:].T,\n",
    "            bold_data['raw'][f1_coords,:][inter_from_f1,:].T,\n",
    "            bold_data['raw'][f2_coords,:][f2_from_f2,:].T,\n",
    "    ])\n",
    "    selected_bold_data['denoised'] = np.hstack([\n",
    "            bold_data['denoised'][f1_coords,:][f1_from_f1,:].T,\n",
    "            bold_data['denoised'][f1_coords,:][inter_from_f1,:].T,\n",
    "            bold_data['denoised'][f2_coords,:][f2_from_f2,:].T,\n",
    "    ])\n",
    "    # Pad the truncated data\n",
    "    selected_bold_data['padded_denoised'] = pad_denoised_data(selected_bold_data['denoised'], n_tps_raw, timepoints_raw, timepoints_denoised)\n",
    "\n",
    "    # Plot carpet plots\n",
    "    extent=[\n",
    "        timepoints_raw[0], timepoints_raw[-1], n_f1+n_f1f2+n_f2, 0\n",
    "    ]\n",
    "    raw_ax.imshow(selected_bold_data['raw'].T, cmap=custom_colormap(), vmin=vmin, vmax=vmax, aspect='auto', extent=extent)\n",
    "    denoised_ax.imshow(selected_bold_data['padded_denoised'].T, cmap=custom_colormap(), vmin=vmin, vmax=vmax, aspect='auto', extent=extent)\n",
    "    \n",
    "    # decorate\n",
    "    total_vertices = n_f1+n_f1f2+n_f2\n",
    "    for ax in [raw_ax, denoised_ax]:\n",
    "        square_f1 = plt.Polygon([(0, 0), (2,0), (2, n_f1), (0, n_f1)], closed=True, color='red')\n",
    "        square_f1f2 = plt.Polygon([(0, n_f1), (2, n_f1), (2, n_f1+n_f1f2), (0, n_f1+n_f1f2)], closed=True, color='gold')\n",
    "        square_f2 = plt.Polygon([(0, n_f1+n_f1f2), (2, n_f1+n_f1f2), (2, total_vertices), (0, total_vertices)], closed=True, color='blue')\n",
    "        for square in [square_f1, square_f2, square_f1f2]:\n",
    "            ax.add_patch(square)\n",
    "    period_f1 = 1/frequencies[0]\n",
    "    period_f2 = 1/frequencies[1]\n",
    "    timescale_f1 = plt.Polygon(\n",
    "        [\n",
    "            (period_offset, total_vertices*.08), \n",
    "            (period_offset+period_f1, total_vertices*.08), \n",
    "            (period_offset+period_f1, total_vertices*.11), \n",
    "            (period_offset, total_vertices*.11)\n",
    "        ], \n",
    "        closed=True, color='red', linewidth=0., zorder=10,\n",
    "    )\n",
    "    timescale_f2 = plt.Polygon(\n",
    "        [\n",
    "            (period_offset, total_vertices*.12), \n",
    "            (period_offset+period_f2, total_vertices*.12),\n",
    "            (period_offset+period_f2, total_vertices*.15),\n",
    "            (period_offset, total_vertices*.15)\n",
    "        ], \n",
    "        closed=True, color='blue', linewidth=0., zorder=10,\n",
    "    )\n",
    "    for square in [timescale_f1, timescale_f2]:\n",
    "        denoised_ax.add_patch(square)\n",
    "        \n",
    "    data_dict = {\n",
    "            \"timepoints\": timepoints_raw,\n",
    "            \"bold_raw\": selected_bold_data['raw'],\n",
    "            \"bold_denoised\": selected_bold_data['denoised'],\n",
    "            \"bold_padded_denoised\": selected_bold_data['padded_denoised'],\n",
    "            \"n_f1\": n_f1,\n",
    "            \"n_f2\": n_f2,\n",
    "            \"n_f1f2\": n_f1f2,\n",
    "            \"stimulated_frequencies\": frequencies,\n",
    "    }\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, figsize=(5,7), dpi=200)\n",
    "\n",
    "truncate_window = (39, 219)\n",
    "repetition_time = .3\n",
    "frequencies = [.125, .2]\n",
    "roi_task_id = \"entrain\"\n",
    "corr_type = \"fdrp\"\n",
    "n_bootstraps = 200\n",
    "bold_data = load_bold_data(\n",
    "    data['raw_bold'], axs[0], data['denoised_bold'], axs[1],\n",
    "    truncate_window, repetition_time,\n",
    "    experiment_id, mri_id, sub_id, task_id, frequencies, \n",
    "    roi_task_id,\n",
    "    corr_type=corr_type, roi_frequency_2=None, control_roi_size=False, fo=.8,\n",
    "    datadir = Path(\"/scratch/fastfmri\"),\n",
    "    n_bootstraps = n_bootstraps,\n",
    "    vmin=-.05, vmax=.05\n",
    ")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finger tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_response_to_target(target_onset_time, combined_response_times, correct_response_times, incorrect_response_times):\n",
    "\n",
    "    if len(combined_response_times) == 0:\n",
    "        return None, combined_response_times\n",
    "\n",
    "    while True:\n",
    "\n",
    "        if len(combined_response_times) == 0:\n",
    "            return (\"wrong\", \"no_response\"), combined_response_times\n",
    "\n",
    "        response_time = combined_response_times[0]\n",
    "        if response_time in correct_response_times:\n",
    "            response_type = \"correct\"\n",
    "        if response_time in incorrect_response_times:\n",
    "            response_type = \"wrong\"\n",
    "\n",
    "        response_delay = response_time - target_onset_time\n",
    "\n",
    "        if response_delay > 0:\n",
    "            combined_response_times = combined_response_times[1:]\n",
    "            return (response_type, response_delay), combined_response_times\n",
    "        \n",
    "        combined_response_times = combined_response_times[1:]\n",
    "\n",
    "def condense_delay_times(target_onset_times_mapping):\n",
    "\n",
    "    correct_delay_times = []\n",
    "    wrong_delay_times = []\n",
    "    for time_mapping in target_onset_times_mapping:\n",
    "        _, response_time = time_mapping[0], time_mapping[1]\n",
    "        if response_time is None:\n",
    "            continue\n",
    "        if response_time[0] == \"correct\":\n",
    "            correct_delay_times.append(response_time[1])\n",
    "        if response_time[0] == \"wrong\":\n",
    "            wrong_delay_times.append(response_time[1])\n",
    "\n",
    "    return  correct_delay_times, wrong_delay_times\n",
    "\n",
    "def calculate_response_delay_times(target_onset_times, correct_response_times, incorrect_response_times):\n",
    "    \n",
    "    combined_response_times = correct_response_times + incorrect_response_times\n",
    "    combined_response_times.sort()\n",
    "    target_onset_times_mapping = []\n",
    "    for ix, target_onset_time in enumerate(target_onset_times):\n",
    "        val, combined_response_times = match_response_to_target(target_onset_time, combined_response_times, correct_response_times, incorrect_response_times)\n",
    "        target_onset_times_mapping.append((target_onset_time, val))\n",
    "\n",
    "    return condense_delay_times(target_onset_times_mapping)\n",
    "\n",
    "def load_fingertracking_data(pkl_path, ax):\n",
    "\n",
    "    if not pkl_path.exists():\n",
    "        return None\n",
    "\n",
    "    data = read_pickle(pkl_path)\n",
    "    PKL_KEYS = [i for i in data.keys()]\n",
    "    for k in [\"correctResponsesTimes\", \"incorrectResponsesTimes\", \"targetOnsetTimes\"]:\n",
    "        assert k in PKL_KEYS, f\"key: {k} not found in {pkl_path}.\"\n",
    "\n",
    "    n_incorrect = len(data[\"incorrectResponsesTimes\"])\n",
    "    n_correct = len(data[\"correctResponsesTimes\"])\n",
    "    if n_correct+n_incorrect == 0:\n",
    "        return None\n",
    "    accuracy = n_correct / (n_correct+n_incorrect)\n",
    "\n",
    "    target_onset_times = [float(i) for i in data[\"targetOnsetTimes\"]]\n",
    "    correct_response_times = [float(i) for i in data[\"correctResponsesTimes\"]]\n",
    "    incorrect_response_times = [float(i) for i in data[\"incorrectResponsesTimes\"]]\n",
    "    correct_delay_times, wrong_delay_times = calculate_response_delay_times(target_onset_times, correct_response_times, incorrect_response_times)\n",
    "\n",
    "    _response_times = [target_onset_times, correct_response_times, incorrect_response_times]\n",
    "    for response_times, response_c in zip(_response_times, ['k', 'g', 'r']):\n",
    "        for response_time in response_times:\n",
    "            ax.axvline(x=response_time, c=response_c, lw=.3)\n",
    "\n",
    "    data_dict = {\n",
    "        \"n_correct\": n_correct,\n",
    "        \"n_incorrect\": n_incorrect,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"timing_onset\": data[\"targetOnsetTimes\"],\n",
    "        \"correct_response_times\": data[\"correctResponsesTimes\"],\n",
    "        \"correct_delay_times\": correct_delay_times,\n",
    "        \"wrong_response_times\": data[\"incorrectResponsesTimes\"],\n",
    "        \"wrong_delay_times\": wrong_delay_times,\n",
    "    }\n",
    "\n",
    "    #assert len(data_dict[\"wrong_response_times\"]) == len(data_dict[\"wrong_delay_times\"])\n",
    "    #assert len(data_dict[\"correct_response_times\"]) == len(data_dict[\"correct_delay_times\"])\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(6,1), dpi=200)\n",
    "fingertracking_data = load_fingertracking_data(data['fingertracking'], ax)\n",
    "if fingertracking_data is not None:\n",
    "    for k, v in fingertracking_data.items():\n",
    "        if isinstance(v, list):\n",
    "            print(k, len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Framewise displacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_motion_data(pkl_path, tr, ax):\n",
    "\n",
    "    data = pd.read_csv(pkl_path, sep='\\t')\n",
    "    cols = data.columns\n",
    "\n",
    "    assert 'framewise_displacement' in cols\n",
    "\n",
    "    fd = data.framewise_displacement.values\n",
    "    n_tps = fd.shape[0]\n",
    "\n",
    "    timepoints = np.arange(tr, n_tps*tr+tr, tr)[1:]\n",
    "    fd = fd[1:]\n",
    "\n",
    "    assert fd.shape == timepoints.shape\n",
    "\n",
    "    data_dict = {\n",
    "        \"timepoints\": timepoints,\n",
    "        \"framewise_displacement\": fd\n",
    "    }\n",
    "\n",
    "    ax.plot(timepoints, fd, c='k', lw=.2, zorder=2, alpha=1.)\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(6,1), dpi=200)\n",
    "tr = .3\n",
    "motion_data = load_motion_data(data['confounds'], tr, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all, which also includes eyetracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(lst):\n",
    "    # Find indices of non-NaN values\n",
    "    number_indices = [i for i, x in enumerate(lst) if not np.isnan(x)]\n",
    "\n",
    "    # Initialize list to store chunks\n",
    "    chunks = []\n",
    "\n",
    "    if len(number_indices) == 0:\n",
    "        return chunks\n",
    "    # Iterate through the list to find consecutive sequences\n",
    "    start = number_indices[0]\n",
    "    for i in range(1, len(number_indices)):\n",
    "        if number_indices[i] != number_indices[i-1] + 1:\n",
    "            chunks.append((start, number_indices[i-1]))\n",
    "            start = number_indices[i]\n",
    "\n",
    "    # Add the last chunk\n",
    "    chunks.append((start, number_indices[-1]))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def load_eyetracking_data(pkl_path, ax, sample_rate=1/500):\n",
    "    if not pkl_path.exists():\n",
    "        return None\n",
    "    data = read_pickle(pkl_path)\n",
    "    PKL_KEYS = [i for i in data.keys()]\n",
    "\n",
    "    assert \"gazeX\" in PKL_KEYS\n",
    "    assert \"gazeY\" in PKL_KEYS\n",
    "\n",
    "    gaze_x = data[\"gazeX\"]\n",
    "    gaze_y = data[\"gazeY\"]\n",
    "\n",
    "    assert gaze_x.shape == gaze_y.shape\n",
    "    assert gaze_x.shape[-1] == 1\n",
    "\n",
    "    gaze_x = gaze_x[:,0]\n",
    "    gaze_y = gaze_y[:,0]\n",
    "    \n",
    "    n_tps = gaze_x.shape[0]\n",
    "    n_duration = sample_rate*n_tps\n",
    "    timepoints = np.arange(sample_rate, n_duration+sample_rate, sample_rate)\n",
    "\n",
    "    #print(gaze_x.shape, n_tps, timepoints.shape)\n",
    "    #print(timepoints)\n",
    "\n",
    "    x_chunks = get_chunks(gaze_x)\n",
    "    y_chunks = get_chunks(gaze_y)\n",
    "    if len(x_chunks) == 0:\n",
    "        return None\n",
    "\n",
    "    assert len(x_chunks) == len(y_chunks)\n",
    "\n",
    "\n",
    "    for i,j in zip(x_chunks, y_chunks):\n",
    "        assert i == j\n",
    "        chunk_gaze_x = gaze_x[i[0]:i[1]+1]\n",
    "        chunk_gaze_y = gaze_y[i[0]:i[1]+1]\n",
    "        chunk_timepoints = timepoints[i[0]:i[1]+1]\n",
    "\n",
    "        ax.plot(chunk_timepoints, chunk_gaze_x, c='r', lw=.2, zorder=2, alpha=.4)\n",
    "        ax.plot(chunk_timepoints, chunk_gaze_y, c='b', lw=.2, zorder=2, alpha=.4)\n",
    "\n",
    "    data_dict = {\n",
    "        \"timepoints\": timepoints,\n",
    "        \"gaze_x\": gaze_x,\n",
    "        \"gaze_y\": gaze_y,\n",
    "    }\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate vertex-wise power spectrums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_im_frequencies(f1,f2):\n",
    "    assert f2 > f1, f\"{f2} <= {f1}\"\n",
    "    im_frequencies = {}\n",
    "    im_frequencies[\"first_order\"] = [f1, f2]\n",
    "    f2_sub_f1 = round(f2-f1, 10)\n",
    "    f1_plus_f2 = round(f1+f2, 10)\n",
    "    f1_mul_2 = round(f1*2, 10)\n",
    "    f2_mul_2 = round(f2*2, 10)\n",
    "    f1_mul_2_sub_f2 = round(2*f1-f2, 10)\n",
    "    f2_mul_2_sub_f1 = round(2*f2-f1, 10)\n",
    "    im_frequencies[\"second_order\"] = [\n",
    "        f2_sub_f1, # f2-f1\n",
    "        f1_plus_f2, # f1+f2\n",
    "        f1_mul_2, # 2*f1\n",
    "        f2_mul_2, # 2*f2\n",
    "    ]\n",
    "    im_frequencies[\"third_order\"] = [\n",
    "        f1_mul_2_sub_f2, # 2f1 - f2\n",
    "        f2_mul_2_sub_f1, # 2f2 - f1\n",
    "    ]\n",
    "\n",
    "    return im_frequencies\n",
    "\n",
    "def calculate_power_spectrum_from_denoised_bold(bold_data, fois, repetition_time, nperseg=1024,):\n",
    "    from collections import defaultdict\n",
    "    from scipy.signal import welch\n",
    "\n",
    "    denoised_bold = bold_data['bold_denoised']\n",
    "    n_tps, n_vertices = denoised_bold.shape[0], denoised_bold.shape[1]\n",
    "\n",
    "    all_fois = get_im_frequencies(fois[0], fois[1])\n",
    "\n",
    "    psd_per_f = defaultdict(list)\n",
    "    foi_list = []\n",
    "    for vertex_id in range(n_vertices):\n",
    "        vertex_bold = denoised_bold[:, vertex_id]\n",
    "        fs, ps = welch(vertex_bold, fs=1/repetition_time, nperseg=nperseg)\n",
    "\n",
    "        for im_key, fois in all_fois.items():\n",
    "            for foi in fois:\n",
    "                psd_per_f[foi].append(np.interp(foi, fs, ps))\n",
    "            if vertex_id == 0:\n",
    "                foi_list += fois\n",
    "\n",
    "    return foi_list, psd_per_f, n_vertices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate all plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_base_dir(basedir):\n",
    "    basedir = Path(basedir)\n",
    "    if not basedir.exists():\n",
    "        basedir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    return basedir\n",
    "\n",
    "def explore_single_subject_run(\n",
    "    experiment_id, \n",
    "    mri_id, \n",
    "    sub_id, \n",
    "    ses_id, \n",
    "    run_id, \n",
    "    roi_task_id, \n",
    "    task_id,\n",
    "    data,\n",
    "    repetition_time,\n",
    "    frequencies, \n",
    "    corr_type = \"uncp\",\n",
    "    STIMULUS_TIMINGS = [0, 14, 14+25, 219],\n",
    "    FONTSIZE=4,\n",
    "    DPI=300,\n",
    "    CLOSE_FIGURES = True,\n",
    "    SKIP_IF_EXISTS = True,\n",
    "):\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=5, ncols=2, \n",
    "        sharex=\"col\", \n",
    "        sharey='row',\n",
    "        figsize=(5,4), \n",
    "        dpi=DPI,\n",
    "        gridspec_kw = {\n",
    "            \"height_ratios\": [.5, 1, 1, 6, 6],\n",
    "            \"width_ratios\": [9,1.5]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    png_out = Path(set_base_dir(f\"./ComputeCanada/frequency_tagging/figures/data_exploration/carpet_plots/{experiment_id}/mri-{mri_id}/{sub_id}/{ses_id}/figures\")) / f\"{sub_id}_{ses_id}_{run_id}_roi-task-{roi_task_id}-{corr_type}_{task_id}_carpetplot.png\"\n",
    "    if png_out.exists() and SKIP_IF_EXISTS:\n",
    "        return None\n",
    "\n",
    "    fig.suptitle(f\"{experiment_id}, {mri_id}, {sub_id}, {ses_id}, {run_id}, roi-task-{roi_task_id}, {task_id}\", fontsize=FONTSIZE)\n",
    "\n",
    "    eyetracking_data = load_eyetracking_data(data[\"eyetracking\"], axs[1,0])\n",
    "    fingertracking_data = load_fingertracking_data(data['fingertracking'], axs[0,0])\n",
    "    motion_data = load_motion_data(data['confounds'], repetition_time, axs[2,0])\n",
    "    \"\"\"bold data\n",
    "    \"\"\"\n",
    "    truncate_window = (STIMULUS_TIMINGS[-2], STIMULUS_TIMINGS[-1])\n",
    "    n_bootstraps = 200\n",
    "    bold_data = load_bold_data(\n",
    "        data['raw_bold'], axs[3,0], data['denoised_bold'], axs[4,0],\n",
    "        truncate_window, repetition_time,\n",
    "        experiment_id, mri_id, sub_id, task_id, frequencies, \n",
    "        roi_task_id,\n",
    "        corr_type=corr_type, roi_frequency_2=None, control_roi_size=False, fo=.8,\n",
    "        datadir = Path(\"/scratch/fastfmri\"),\n",
    "        n_bootstraps = n_bootstraps, period_offset = 16,\n",
    "        vmin=-.04, vmax=.04\n",
    "    )\n",
    "\n",
    "    for ix, ax in enumerate([i for i in axs[:,0]]+[axs[4,1]]):\n",
    "        for stim_time in STIMULUS_TIMINGS:\n",
    "            if ix != 5:\n",
    "                ax.axvline(x=stim_time, lw=1, c='k', zorder=1)\n",
    "        for spine_type in [\"top\", \"bottom\", \"right\", \"left\"]:\n",
    "            ax.spines[spine_type].set_visible(False)\n",
    "        ax.tick_params(axis='x', bottom=False, pad=0, labelsize=FONTSIZE)\n",
    "        ax.tick_params(axis='y', length=2, pad=0, labelsize=FONTSIZE)\n",
    "        ax.set_xlim(0, max(ax.get_xlim()))\n",
    "        if ix in [3,4]:\n",
    "            ax.set_yticks([])\n",
    "\n",
    "    # Add psd, bold\n",
    "    fois, power_per_vertex, n_vertices = calculate_power_spectrum_from_denoised_bold(bold_data, bold_data['stimulated_frequencies'], repetition_time)\n",
    "    extent=[\n",
    "        0, 1, bold_data['n_f1']+bold_data['n_f1f2']+bold_data['n_f2'], 0\n",
    "    ]\n",
    "    psds = np.vstack([\n",
    "            np.array(power_per_vertex[fois[0]])[np.newaxis,:],\n",
    "            np.array(power_per_vertex[fois[1]])[np.newaxis,:],\n",
    "            np.array(power_per_vertex[fois[2]])[np.newaxis,:],\n",
    "            np.array(power_per_vertex[fois[3]])[np.newaxis,:],\n",
    "            np.array(power_per_vertex[fois[4]])[np.newaxis,:],\n",
    "            np.array(power_per_vertex[fois[5]])[np.newaxis,:],\n",
    "            np.array(power_per_vertex[fois[6]])[np.newaxis,:],\n",
    "            np.array(power_per_vertex[fois[7]])[np.newaxis,:],\n",
    "    ])\n",
    "    axs[4,1].imshow(\n",
    "        psds.T, \n",
    "        cmap='magma', \n",
    "        vmin=0, vmax=.001, \n",
    "        aspect='auto', \n",
    "        extent=extent,\n",
    "        interpolation='none',\n",
    "    )\n",
    "    axs[4,1].set_xticks([\n",
    "        axs[4,1].get_xlim()[-1]*(1/16)+((1/8)*0), \n",
    "        axs[4,1].get_xlim()[-1]*(1/16)+((1/8)*1), \n",
    "        axs[4,1].get_xlim()[-1]*(1/16)+((1/8)*2), \n",
    "        axs[4,1].get_xlim()[-1]*(1/16)+((1/8)*3), \n",
    "        axs[4,1].get_xlim()[-1]*(1/16)+((1/8)*4), \n",
    "        axs[4,1].get_xlim()[-1]*(1/16)+((1/8)*5), \n",
    "        axs[4,1].get_xlim()[-1]*(1/16)+((1/8)*6), \n",
    "        axs[4,1].get_xlim()[-1]*(1/16)+((1/8)*7), \n",
    "    ])\n",
    "    xticklabels = [\n",
    "        \"$f_{1}$\",\n",
    "        \"$f_{2}$\",\n",
    "        \"$f_{2}$-$f_{1}$\",\n",
    "        \"$f_{1}$+$f_{2}$\",\n",
    "        \"2$f_{1}$\",\n",
    "        \"2$f_{2}$\",\n",
    "        \"2$f_{1}$-$f_{2}$\",\n",
    "        \"2$f_{2}$-$f_{1}$\",\n",
    "    ]\n",
    "    axs[4,1].set_xticklabels(xticklabels, fontsize=FONTSIZE)\n",
    "    axs[4,1].set_xlabel(\"Power\", fontsize=FONTSIZE)\n",
    "    axs[4,1].tick_params(axis='x', rotation=90)\n",
    "\n",
    "\n",
    "    # Add plot descriptions\n",
    "    if fingertracking_data is not None:\n",
    "        accuracy = fingertracking_data[\"accuracy\"]\n",
    "        mean_correct_delay_times = np.mean(fingertracking_data[\"correct_delay_times\"])\n",
    "        mean_wrong_delay_times = np.mean([i for i in fingertracking_data[\"wrong_delay_times\"] if i != \"no_response\"])\n",
    "        fingertracking_str = f\"Trigger timings [accuracy, correct/wrong mean response times]: {100*accuracy:.2f}%, {mean_correct_delay_times:.3f}/{mean_wrong_delay_times:.3f}s\"\n",
    "        axs[0,0].text(STIMULUS_TIMINGS[-1]*.49, axs[0,0].get_ylim()[-1]*1.15, fingertracking_str, fontsize=FONTSIZE-1, zorder=10)\n",
    "    else:\n",
    "        axs[0,0].remove()\n",
    "    if motion_data is not None:\n",
    "        mean_fd = np.mean(motion_data['framewise_displacement'])\n",
    "        median_fd = np.median(motion_data['framewise_displacement'])\n",
    "        motion_str = f\"Framewise displacement [mean/median]: {mean_fd:.3f}/{median_fd:.3f}mm\"\n",
    "        axs[2,0].text(STIMULUS_TIMINGS[-1]*.66, axs[2,0].get_ylim()[-1]*1.12, motion_str, fontsize=FONTSIZE-1, zorder=10)\n",
    "    else:\n",
    "        axs[2,0].remove()\n",
    "    if eyetracking_data is not None:\n",
    "        axs[1,0].text(STIMULUS_TIMINGS[-1]*.93, axs[1,0].get_ylim()[-1]*1.15, \"Eye tracking\", fontsize=FONTSIZE-1, zorder=10)\n",
    "    else:\n",
    "        axs[1,0].remove()\n",
    "    axs[3,0].set_ylabel(\"Vertex\", fontsize=FONTSIZE)\n",
    "    axs[4,0].set_ylabel(\"Vertex\", fontsize=FONTSIZE)\n",
    "    axs[4,0].set_xlabel(\"Timepoints\", fontsize=FONTSIZE)\n",
    "    y_tracker = .25\n",
    "    stimulated_frequencies = bold_data[\"stimulated_frequencies\"]\n",
    "    stimulated_frequencies = [stimulated_frequencies[0], None, stimulated_frequencies[1]]\n",
    "    for i, (f_count, f) in enumerate(zip([\"n_f1\", \"n_f1f2\", \"n_f2\"], stimulated_frequencies)):\n",
    "        n_f = bold_data[f_count]\n",
    "        if f is not None:\n",
    "            f_label = i+1\n",
    "            if i == 2:\n",
    "                f_label = 2\n",
    "            f_subscript = f\"{f_label},{f}Hz\"\n",
    "        else:\n",
    "            f_subscript = \"1,2\"\n",
    "        axs[4,0].text(16, axs[4,0].get_ylim()[0]*y_tracker, f\"$f_{{{f_subscript}}}$={n_f}\", fontsize=FONTSIZE-1, zorder=10)\n",
    "        y_tracker += .08\n",
    "    # Remove usused plots\n",
    "    axs[0,1].remove()\n",
    "    axs[1,1].remove()\n",
    "    axs[2,1].remove()\n",
    "    axs[3,1].remove()\n",
    "\n",
    "    plt.subplots_adjust(hspace=.1, wspace=0, top=.94)\n",
    "\n",
    "    fig.savefig(png_out, dpi='figure')\n",
    "\n",
    "    if CLOSE_FIGURES:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repetition_time = .3\n",
    "frequencies = [.125, .2]\n",
    "corr_type = \"uncp\"\n",
    "STIMULUS_TIMINGS = [0, 14, 14+25, 219]\n",
    "FONTSIZE = 4\n",
    "DPI=300\n",
    "explore_single_subject_run(\n",
    "    experiment_id, \n",
    "    mri_id, \n",
    "    sub_id, \n",
    "    ses_id, \n",
    "    run_id, \n",
    "    roi_task_id, \n",
    "    task_id,\n",
    "    data,\n",
    "    repetition_time, frequencies, \n",
    "    corr_type=corr_type, \n",
    "    STIMULUS_TIMINGS = STIMULUS_TIMINGS,\n",
    "    FONTSIZE = FONTSIZE,\n",
    "    DPI=DPI,\n",
    "    CLOSE_FIGURES=False,\n",
    "    SKIP_IF_EXISTS=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = \"1_attention\"\n",
    "mri_id = \"7T\"\n",
    "\n",
    "deriv_dir_base = \"oscprep_grayords_fmapless\"\n",
    "deriv_dir = f\"/data/{experiment_id}/{mri_id}/bids/derivatives/{deriv_dir_base}/bold_preproc\"\n",
    "sub_ids = !ls {deriv_dir}\n",
    "ATTENTION_7T = [f\"sub-{i}\" for i in [\"010\", \"011\", \"012\", \"013\", \"014\", \"015\", \"016\"]]\n",
    "NORMAL_3T = [f\"sub-{i}\" for i in [\"000\", \"002\", \"003\", \"004\", \"005\", \"006\", \"007\", \"008\", \"009\"]]\n",
    "NORMAL_7T = [f\"sub-{i}\" for i in [\"Pilot001\", \"Pilot009\", \"Pilot010\", \"Pilot011\"]]\n",
    "VARY_3T = [f\"sub-{i}\" for i in [\"020\", \"021\"]]\n",
    "VARY_7T = [f\"sub-{i}\" for i in [\"020\", \"021\"]]\n",
    "STIMULUS_TIMINGS = [0, 14, 14+25, 219]\n",
    "FONTSIZE = 4\n",
    "DPI=300\n",
    "SKIP_IF_EXISTS = True\n",
    "for corr_type in [\"fdrp\", \"uncp\"]:\n",
    "    for sub_id in sub_ids:\n",
    "\n",
    "        # Set repetition_time\n",
    "        if experiment_id == \"1_attention\" and sub_id in ATTENTION_7T:\n",
    "            repetition_time = .25\n",
    "        else:\n",
    "            repetition_time = .3\n",
    "\n",
    "        # Set roi_task_id\n",
    "        # Attention 7T\n",
    "        if experiment_id == \"1_attention\" and mri_id ==\"7T\" and sub_id in ATTENTION_7T:\n",
    "            roi_task_ids = [\"AttendAway\", \"AttendInF1\", \"AttendInF2\", \"AttendInF1F2\"]\n",
    "            roi_task_ids = [\"match\"]\n",
    "        # Normal 3T\n",
    "        elif experiment_id == \"1_frequency_tagging\" and mri_id == \"3T\" and sub_id in NORMAL_3T:\n",
    "            roi_task_ids = [\"entrain\"]\n",
    "        # Normal 7T\n",
    "        elif experiment_id == \"1_attention\" and mri_id == \"7T\" and sub_id in NORMAL_7T:\n",
    "            roi_task_ids = [\"match\"]\n",
    "        # Vary 3T\n",
    "        elif experiment_id == \"1_frequency_tagging\" and mri_id == \"3T\" and sub_id in VARY_3T:\n",
    "            roi_task_ids = [\"match\"]\n",
    "        # Vary 7T\n",
    "        elif experiment_id == \"1_frequency_tagging\" and mri_id == \"7T\" and sub_id in VARY_7T:\n",
    "            roi_task_ids = [\"match\"]\n",
    "        else:\n",
    "            print(f\"Skipping {experiment_id} {mri_id} {sub_id} {ses_id}\")\n",
    "            continue\n",
    "        \n",
    "        ses_ids = !ls {deriv_dir}/{sub_id}\n",
    "        for ses_id in ses_ids:\n",
    "            dtseries = !ls {deriv_dir}/{sub_id}/{ses_id}/func/*dtseries.nii\n",
    "            for raw_bold in dtseries:\n",
    "                task_id = raw_bold.split(\"_task-\")[1].split(\"_\")[0]\n",
    "                if not any([task_id.startswith(\"Attend\"), task_id.startswith(\"entrain\"), task_id.startswith(\"control\")]):\n",
    "                    continue\n",
    "                task_id = f\"task-{task_id}\"\n",
    "\n",
    "                run_id = raw_bold.split(\"_run-\")[1].split(\"_\")[0]\n",
    "                run_id = f\"run-{run_id}\"\n",
    "                \n",
    "                sub_base = f\"{sub_id}_{ses_id}_{task_id}_{run_id}\"\n",
    "                \n",
    "                raw_bold = !ls {deriv_dir}/{sub_id}/{ses_id}/func/{sub_id}_{ses_id}_{task_id}_*_{run_id}_desc-preproc_bold.dtseries.nii\n",
    "                confounds = !ls {deriv_dir}/{sub_id}/{ses_id}/func/{sub_id}_{ses_id}_{task_id}_*_{run_id}_desc-confounds_timeseries.tsv\n",
    "                for i in [raw_bold, confounds]:\n",
    "                    assert len(i) == 1\n",
    "\n",
    "                denoised_bold = Path(\"/scratch/fastfmri\") / f\"experiment-{experiment_id}_mri-{mri_id}_smooth-0_truncate-39-219_desc-denoised_bold\" / \"00_experiment-min+motion24+wmcsfmean\" / sub_id / ses_id / task_id / run_id/ \"GLM\" / f\"{sub_base}_desc-denoised_bold.dtseries.nii\"\n",
    "                \n",
    "                if not denoised_bold.exists():\n",
    "                    continue\n",
    "                \n",
    "                nvols = nib.load(raw_bold[0]).shape[0]\n",
    "\n",
    "                data = {\n",
    "                    \"raw_bold\": Path(raw_bold[0]),\n",
    "                    \"confounds\": Path(confounds[0]),\n",
    "                    \"denoised_bold\": denoised_bold,\n",
    "                    \"eyetracking\": Path(\"/data/behaviour\") / \"eyetracking\" / experiment_id / mri_id / f\"{sub_base}_eyetracking.pkl\", \n",
    "                    \"fingertracking\": Path(\"/data/behaviour\") / \"fingertracking\" / experiment_id / mri_id / f\"{sub_base}_fingertracking.pkl\", \n",
    "                }\n",
    "\n",
    "                for roi_task_id in roi_task_ids:\n",
    "                    _roi_task_id = roi_task_id\n",
    "                    if roi_task_id == \"match\":\n",
    "                        _roi_task_id = task_id.split(\"-\")[-1].split(\"Q\")[0]\n",
    "\n",
    "                    # Set frequencies\n",
    "                    if \"entrainB\" in task_id:\n",
    "                        frequencies = [.125, .175]\n",
    "                    elif \"entrainC\" in task_id:\n",
    "                        frequencies = [.125, .15]\n",
    "                    elif \"entrainE\" in task_id:\n",
    "                        frequencies = [.15, .2]\n",
    "                    elif \"entrainF\" in task_id:\n",
    "                        frequencies = [.175, .2]\n",
    "                    else:\n",
    "                        frequencies = [.125, .2]\n",
    "                    \n",
    "                    print(\n",
    "                        experiment_id, \n",
    "                        mri_id, \n",
    "                        sub_id, \n",
    "                        ses_id, \n",
    "                        run_id, \n",
    "                        f\"roi-task-{_roi_task_id}\", \n",
    "                        task_id,\n",
    "                        f\"TR: {repetition_time}\", f\"Frequencies: {frequencies}\", corr_type,\n",
    "                        STIMULUS_TIMINGS,\n",
    "                        FONTSIZE,\n",
    "                        DPI,\n",
    "                        True,\n",
    "                    )\n",
    "                    explore_single_subject_run(\n",
    "                        experiment_id, \n",
    "                        mri_id, \n",
    "                        sub_id, \n",
    "                        ses_id, \n",
    "                        run_id, \n",
    "                        _roi_task_id, \n",
    "                        task_id,\n",
    "                        data,\n",
    "                        repetition_time,\n",
    "                        frequencies, \n",
    "                        corr_type = corr_type, \n",
    "                        STIMULUS_TIMINGS = STIMULUS_TIMINGS,\n",
    "                        FONTSIZE = FONTSIZE,\n",
    "                        DPI=DPI,\n",
    "                        CLOSE_FIGURES=True,\n",
    "                        SKIP_IF_EXISTS=SKIP_IF_EXISTS,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
