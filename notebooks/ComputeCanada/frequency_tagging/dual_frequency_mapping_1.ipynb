{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import random\n",
    "from scipy.signal import welch\n",
    "from collections import defaultdict\n",
    "\n",
    "FONTSIZE = 4\n",
    "TR = .3\n",
    "n_permutations = 1_000\n",
    "n_bootstraps = 200\n",
    "\n",
    "datadir = Path(\"/scratch/fastfmri\")\n",
    "\n",
    "sub_to_task_mapping = {\n",
    "    \"020\": [\n",
    "        (\"entrainA\", [.125, .2]),\n",
    "        (\"entrainB\", [.125, .175]),\n",
    "        (\"entrainC\", [.125, .15]),\n",
    "    ],\n",
    "    \"021\": [\n",
    "        (\"entrainD\", [.125, .2]),\n",
    "        (\"entrainE\", [.15, .2]),\n",
    "        (\"entrainF\", [.175, .2]),\n",
    "    ],\n",
    "}\n",
    "\n",
    "def read_pkl(datadir, n_bootstraps, sub_id, roi_task_id, roi_frequency, task_id, experiment_id=\"1_frequency_tagging\", mri_id=\"7T\", fo=.8, roi_frequency_2=None, control_roi_size=False):\n",
    "\n",
    "    import pickle\n",
    "\n",
    "    if roi_frequency_2 is not None:\n",
    "        if control_roi_size:\n",
    "            bootstrap_pkl: Path = datadir / f\"experiment-{experiment_id}_mri-{mri_id}_smooth-0_truncate-39-219_n-{n_bootstraps}_batch-merged_desc-basic_roi-{roi_task_id}-{roi_frequency}_controlroisizetomatch-{roi_frequency_2}_fo-{fo}_bootstrap/sub-{sub_id}/bootstrap/task-{task_id}_bootstrapped_data.pkl\"\n",
    "        else:\n",
    "            bootstrap_pkl: Path = datadir / f\"experiment-{experiment_id}_mri-{mri_id}_smooth-0_truncate-39-219_n-{n_bootstraps}_batch-merged_desc-basic_roi-{roi_task_id}-{roi_frequency}-{roi_frequency_2}_fo-{fo}_bootstrap/sub-{sub_id}/bootstrap/task-{task_id}_bootstrapped_data.pkl\"\n",
    "    else:\n",
    "        bootstrap_pkl: Path = datadir / f\"experiment-{experiment_id}_mri-{mri_id}_smooth-0_truncate-39-219_n-{n_bootstraps}_batch-merged_desc-basic_roi-{roi_task_id}-{roi_frequency}_fo-{fo}_bootstrap/sub-{sub_id}/bootstrap/task-{task_id}_bootstrapped_data.pkl\"\n",
    "    if not bootstrap_pkl.exists():\n",
    "        print(f\"Warning: {bootstrap_pkl} does not exist.\\nReturn None\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Reading: {bootstrap_pkl}\")\n",
    "    with open(bootstrap_pkl, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    return data\n",
    "\n",
    "def set_base_dir(basedir):\n",
    "    basedir = Path(basedir)\n",
    "    if not basedir.exists():\n",
    "        basedir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    return basedir\n",
    "\n",
    "\n",
    "class TimeSeries:\n",
    "    def __init__(self, ts, TR, n_permutations=5_000, nperseg=600):\n",
    "        self.timeseries = ts\n",
    "        self.fs = 1/TR\n",
    "        self.nperseg = nperseg\n",
    "        self.n_permutations = n_permutations\n",
    "        self.frequencies = None\n",
    "                \n",
    "    def process(self, search_frequencies):\n",
    "        p_values, observed_statistics = {}, {}\n",
    "        for f in search_frequencies:\n",
    "            observed_statistic, observed_power_spectrum = self.calculate_observed_statistic(f)\n",
    "            observed_statistics[f] = observed_statistic\n",
    "            null_statistics, null_power_spectrums = self.calculate_null_statistics(f)\n",
    "            p_values[f] = (np.sum(null_statistics >= observed_statistic) + 1) / (n_permutations+1)\n",
    "\n",
    "        return p_values, observed_statistics, observed_power_spectrum, null_power_spectrums\n",
    "\n",
    "    def calculate_observed_statistic(self, f):\n",
    "        if self.frequencies is None:\n",
    "            self.frequencies, power_spectrum = self._estimate_power_spectrum(self.timeseries)\n",
    "        else:\n",
    "            _, power_spectrum = self._estimate_power_spectrum(self.timeseries)\n",
    "        power = self._estimate_power(self.timeseries, f)\n",
    "\n",
    "        return power, power_spectrum\n",
    "\n",
    "    def calculate_null_statistics(self, f):\n",
    "        null_power_spectrums = []\n",
    "        null_statistics = []\n",
    "        for i in range(n_permutations):\n",
    "            y_shuffle = np.random.permutation(self.timeseries.copy())\n",
    "            null_power_spectrums.append(self._estimate_power_spectrum(y_shuffle)[1])\n",
    "            null_statistics.append(self._estimate_power(y_shuffle, f))\n",
    "\n",
    "        return null_statistics, null_power_spectrums\n",
    "\n",
    "    def _estimate_power_spectrum(self, ts):\n",
    "        frequencies, power_spectrum = welch(ts, self.fs, nperseg=self.nperseg)\n",
    "\n",
    "        return (frequencies, power_spectrum)\n",
    "\n",
    "    def _estimate_power(self, ts, f):\n",
    "        frequencies, power_spectrum = self._estimate_power_spectrum(ts)\n",
    "        return np.interp(f, frequencies, power_spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorate_fig_1B(fig, ax, frequencies, p_values, observed_statistics, add_im=False, sub_id=None, roi_frequency=None, fontsize=FONTSIZE):\n",
    "    for f in frequencies:\n",
    "        ax.text(f+.005, observed_statistics[f], f\"p={-np.log10(p_values[f]):.3f}\", fontsize=FONTSIZE)\n",
    "    if add_im:\n",
    "        _frequencies = frequencies.copy()\n",
    "        second_order_frequencies = [\n",
    "            np.abs(frequencies[0]-frequencies[1]), \n",
    "            np.abs(frequencies[1]+frequencies[0]),\n",
    "            frequencies[0]*2,\n",
    "            frequencies[1]*2,\n",
    "        ]\n",
    "        third_order_frequencies = [\n",
    "            np.abs(2*frequencies[0] - frequencies[1]),\n",
    "            np.abs(2*frequencies[1] - frequencies[0]),\n",
    "        ]\n",
    "        _frequencies += second_order_frequencies\n",
    "        _frequencies += third_order_frequencies\n",
    "        #import pdb; pdb.set_trace()\n",
    "    else:\n",
    "        _frequencies = frequencies\n",
    "    for f in _frequencies:\n",
    "        if f not in second_order_frequencies and f not in third_order_frequencies:\n",
    "            c = 'b'\n",
    "        elif f in second_order_frequencies:\n",
    "            c = 'cyan'\n",
    "        elif f in third_order_frequencies:\n",
    "            c = 'g'\n",
    "        else: \n",
    "            raise ValueError(f\"{f} not identified as a harmonic.\")\n",
    "        ax.axvline(x=f, c=c, linestyle=':', zorder=1, lw=.75)\n",
    "    ax.set_xlim((0,.5))\n",
    "    ax.set_ylabel(\"Power\", fontsize=FONTSIZE)\n",
    "    ax.set_xlabel(\"Frequency\", fontsize=FONTSIZE)\n",
    "    ax.tick_params(axis=\"both\", length=0, labelsize=FONTSIZE)\n",
    "    for i in (\"top\", \"right\", \"bottom\", \"left\"):\n",
    "        ax.spines[i].set_visible(False)\n",
    "    ax.set_title(f\"{sub_id}, roi-{roi_frequency}, {frequencies}\", fontsize=FONTSIZE)\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "def plot_power_spectrum(ts, observed_power_spectrum, null_power_spectrums, add_im=False, sub_id=None, roi_frequency=None, close_figure=False, png_out=None):\n",
    "    \"\"\"Fig 1b\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(2,1), dpi=400)\n",
    "    ax.plot(ts.frequencies, observed_power_spectrum, c='k', zorder=2, lw=.5)\n",
    "    null_power_spectrums = np.vstack(null_power_spectrums)\n",
    "    null_power_spectrum = np.mean(null_power_spectrums, axis=0)\n",
    "    std_dev_values = np.std(null_power_spectrum, axis=0)\n",
    "    confidence_interval = 1.96 * std_dev_values / np.sqrt(n_permutations)\n",
    "    ax.fill_between(\n",
    "        ts.frequencies, \n",
    "        null_power_spectrum - confidence_interval, null_power_spectrum + confidence_interval,\n",
    "        color='r', \n",
    "        alpha=.8,\n",
    "    )\n",
    "    fig, ax = decorate_fig_1B(fig, ax, frequencies, p_values, observed_statistics, add_im=add_im, sub_id=sub_id, roi_frequency=roi_frequency)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if png_out:\n",
    "        fig.savefig(png_out,dpi='figure')\n",
    "\n",
    "    if close_figure:\n",
    "        plt.close()\n",
    "\n",
    "def save_bootstrapped_statistics(rel_path, data_dict, pkldir = Path(\"/scratch/fastfmri/pickles\")):\n",
    "\n",
    "    import pickle\n",
    "\n",
    "    if not pkldir.exists():\n",
    "        pkldir.mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "    file_path = pkldir / rel_path \n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(data_dict, f)\n",
    "\n",
    "    assert file_path.exists(), f\"{file_path} not created.\"\n",
    "\n",
    "def check_difference(arr, diff=.3):\n",
    "    differences = np.diff(arr)\n",
    "\n",
    "    return np.all(np.isclose(differences,diff))\n",
    "\n",
    "def extract_carpet_data(data, task_id, task_quadrant, bootstrap_id, phased_flag):\n",
    "\n",
    "    if phased_flag:\n",
    "        data_tps = data[f'data-test_task-{task_id}{task_quadrant}_roi_phaseadjusted_timepoints']\n",
    "        data_bold = data[f'data-test_task-{task_id}{task_quadrant}_roi_phaseadjusted_bold'][:,:,bootstrap_id]\n",
    "        updated_tps, mean_bold = [], []\n",
    "        n_voxels = data_bold.shape[1]\n",
    "        for single_tp in np.unique(data_tps):\n",
    "            coords = (data_tps == single_tp)\n",
    "            tp_all = np.all((coords).sum(0)) == 1\n",
    "            if tp_all:\n",
    "                updated_tps.append(single_tp)\n",
    "                mean_bold.append(data_bold[coords])\n",
    "        updated_tps = np.array(updated_tps)\n",
    "        assert check_difference(updated_tps)\n",
    "        \n",
    "        return updated_tps, np.vstack(mean_bold)\n",
    "\n",
    "    else:\n",
    "        # Select timeseries (timepoints x voxels x bootstraps)\n",
    "        return data[f'data-test_task-{task_id}{task_quadrant}_roi_timepoints'], data[f'data-test_task-{task_id}{task_quadrant}_roi_bold'][:,:,bootstrap_id]\n",
    "                \n",
    "                \n",
    "def extract_bootstrapped_mean_from_data(data, task_id_2, task_quadrant, bootstrap_id, phased_flag):\n",
    "\n",
    "    if phased_flag:\n",
    "        data_tps = data[f'data-test_task-{task_id_2}{task_quadrant}_roi_phaseadjusted_timepoints']\n",
    "        data_bold = data[f'data-test_task-{task_id_2}{task_quadrant}_roi_phaseadjusted_bold'][:,:,bootstrap_id]\n",
    "        updated_tps, mean_bold = [], []\n",
    "        n_voxels = data_bold.shape[1]\n",
    "        for single_tp in np.unique(data_tps):\n",
    "            coords = (data_tps == single_tp)\n",
    "            tp_all = np.all((coords).sum(0)) == 1\n",
    "            if tp_all:\n",
    "                updated_tps.append(single_tp)\n",
    "                mean_bold.append(data_bold[coords].mean())\n",
    "\n",
    "        updated_tps = np.array(updated_tps)\n",
    "        mean_bold = np.array(mean_bold)\n",
    "        assert check_difference(updated_tps)\n",
    "        assert mean_bold.shape == updated_tps.shape\n",
    "\n",
    "        return updated_tps, mean_bold\n",
    "\n",
    "    else:\n",
    "        x = data[f'data-test_task-{task_id_2}{task_quadrant}_roi_timepoints']\n",
    "        y = data[f'data-test_task-{task_id_2}{task_quadrant}_roi_bold'][:,:,bootstrap_id]\n",
    "        tps = x.mean(1)\n",
    "        y_bootstrapped_mean = y.mean(1)\n",
    "\n",
    "        return tps, y_bootstrapped_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7T intermodulation experiment\n",
    "- sub-020\n",
    "    - task_roi: entrainA, look for f in [.125, .2] \n",
    "        - roi: f=.125\n",
    "        - roi: f=.2\n",
    "    - task_roi: entrainB, look for f in [.125, .175]\n",
    "        - roi: f=.125\n",
    "        - roi: f=.175\n",
    "    - task_roi: entrainC, look for f in [.125, .15]\n",
    "        - roi: f=.125\n",
    "        - roi: f=.15\n",
    "- sub-021\n",
    "    - task_roi: entrainD, look for f in [.125, .2]\n",
    "        - roi: f=.125\n",
    "        - roi: f=.2\n",
    "    - task_roi: entrainE, look for f in [.15, .2]\n",
    "        - roi: f=.15\n",
    "        - roi: f=.2\n",
    "    - task_roi: entrainF, look for f in [.175, 2]\n",
    "        - roi: f=.175\n",
    "        - roi: f=.2\n",
    "\n",
    "1) For a task condition show carpet plots for each frequency (carpet plot for each frequency of a `task_roi`/two plots total)\n",
    "    - show example of one bootstrap only\n",
    "2) Compute mean timeseries across each ROI and bootstrap (**carpet plot** shows that there are two population of phase shifts, therefore computing the mean is ill-advised, unless phase shifted)\n",
    "    - compute statistics of the observed frequency using timeseries shuffling\n",
    "        - provides a p-value for each frequency in the task_roi\n",
    "    - also compute mean timeseries across bootstrapped mean timeseries `y_bootstrapped_mean`, and compute statistics\n",
    "3) Compute power spectrum from `y_bootstrapped_mean` for all `task_roi`s\n",
    "    - create carpet plot (carpet plot for each frequency of a `task_roi`/two plots total)\n",
    "        - might have to play with normalization in order to emphasize the frequencies of interest\n",
    "\n",
    "- Consider subsequent analyses using localizers from under task conditions to reproduce results within a subject\n",
    "    - i.e., sub-020, task: `entrainD`, can resolve consistent results with `entrainE` and `entrainF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_raw_bold(i):\n",
    "    \n",
    "    import os\n",
    "    \n",
    "    experiment_id = str(i.parent).split(\"experiment-\")[1].split('_mri-')[0]\n",
    "    mri_id = str(i.parent).split(\"mri-\")[1].split('_')[0]\n",
    "    sub_id = i.stem.split('sub-')[1].split('_')[0]\n",
    "    ses_id = i.stem.split('ses-')[1].split('_')[0]\n",
    "    task_id = i.stem.split('task-')[1].split('_')[0]\n",
    "    run_id = i.stem.split('run-')[1].split('_')[0]\n",
    "\n",
    "    directory = f\"/data/{experiment_id}/{mri_id}/bids/derivatives/oscprep_grayords_fmapless/bold_preproc/sub-{sub_id}/ses-{ses_id}/func\"\n",
    "    raw_bold = [f\"{directory}/{file}\" for file in os.listdir(directory) if f\"run-{run_id}\" in file and f\"task-{task_id}\" in file and file.endswith(\"bold.dtseries.nii\")]\n",
    "    assert len(raw_bold) == 1, f\"Multiple raw bolds found: {raw_bold}\"\n",
    "\n",
    "    return Path(raw_bold[0])\n",
    "\n",
    "def average_bold(bold_list):\n",
    "    for bold_ix, bold in enumerate(bold_list):\n",
    "        _bold_data = nib.load(bold).get_fdata()\n",
    "        if bold_ix == 0:\n",
    "            y_all = _bold_data.copy() \n",
    "        else:\n",
    "            y_all += _bold_data.copy()\n",
    "        \n",
    "    y_all /= len(bold_list)\n",
    "    y_all = (( y_all - y_all.mean(0)) / y_all.std(0) ).T\n",
    "\n",
    "    return y_all\n",
    "\n",
    "def read_bootstrap_txt(bootstrap_txt, bootstrap_idx):\n",
    "    with open(bootstrap_txt, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    fs = lines[bootstrap_idx]\n",
    "    raw_bolds = []\n",
    "    raw_windowed_bolds = []\n",
    "    processed_bolds = []\n",
    "    for i in fs.split(','):\n",
    "        i = Path(i.strip())\n",
    "        raw_windowed_bold = Path(str(i).replace(\"desc-denoised_bold.dtseries.nii\",\"desc-windowed_bold.dtseries.nii\"))\n",
    "        raw_bold = find_raw_bold(Path(i))\n",
    "        assert i.exists(), f\"{i} not found.\"\n",
    "        assert raw_windowed_bold.exists(), f\"{raw_windowed_bold} not found\"\n",
    "        assert raw_bold.exists(), f\"{raw_bold} not found.\"\n",
    "        raw_bolds.append(raw_bold)\n",
    "        raw_windowed_bolds.append(raw_windowed_bold)\n",
    "        processed_bolds.append(i)\n",
    "\n",
    "    raw_avg = average_bold(raw_bolds)\n",
    "    raw_windowed_avg = average_bold(raw_windowed_bolds)\n",
    "    processed_avg = average_bold(processed_bolds)\n",
    "\n",
    "    #print(f\"Raw: {raw_avg.shape}\")\n",
    "    #print(f\"Raw: {raw_windowed_avg.shape}\")\n",
    "    #print(f\"Raw: {processed_avg.shape}\")\n",
    "\n",
    "    return raw_avg, raw_windowed_avg, processed_avg\n",
    "\n",
    "def find_quadrant_id_from_keys(_dict):\n",
    "    for i in _dict.keys():\n",
    "        if task_id in i:\n",
    "            q_idx = i.find(\"Q\")\n",
    "            q_id = i[q_idx:q_idx+2]\n",
    "            assert q_id in ['Q1', 'Q2']\n",
    "            return q_id\n",
    "    raise ValueError(\"No quadrant id found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot **test** set timeseries of a single bootstrap from a 50/50 data split for each subject. Timeseries are extracted from ROIs defined by the fractional overlap across 200 bootstrapped activation profiles. This procedure generates vertices with f1, f2, f1/f2 intersection encoding.\n",
    "- Plot raw, windowed, windowed+denoised, windowed+denoised+rephased\n",
    "    - Phase delays are modelled from the **train** set, and applied to the **test** set \n",
    "    - saved directory: `./ComputeCanada/frequency_tagging/figures/dual_frequency_timeseries`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorate_fig_1A(fig, ax, im, f1, f2, n_f1, n_f2, n_f1f2, FONTSIZE=FONTSIZE, TR=TR):\n",
    "\n",
    "    cbar = plt.colorbar(im, ax=ax, shrink=.5, drawedges=False)\n",
    "    cbar.ax.set_title(\"Z-score\", fontsize=FONTSIZE-2)\n",
    "    cbar.ax.tick_params(axis=\"both\", length=0, labelsize=FONTSIZE)\n",
    "    cbar.outline.set_edgecolor('none')\n",
    "\n",
    "    #ax.set_title(f\"{sub_id}, roi-{task_id}, roi-frequency-{f}\", fontsize=FONTSIZE)\n",
    "    ax.title.set_position([.75,1.05])\n",
    "\n",
    "    ax.set_ylabel(\"Voxel\", fontsize=FONTSIZE)\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    ax.set_xlabel(\"Acquisition Time (s)\", fontsize=FONTSIZE)\n",
    "    xticks = [i for i in ax.get_xticks()[1:]]\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels([f\"{i*TR:.2f}\" for i in xticks], fontsize=FONTSIZE)\n",
    "    ax.tick_params(axis=\"both\", length=0)\n",
    "\n",
    "    period_f1 = 1/f1\n",
    "    period_f2 = 1/f2\n",
    "    \n",
    "    ax.plot([0,period_f1/TR], [-20,-20], c='white', zorder=1)\n",
    "    ax.plot([0,period_f2/TR], [-50,-50], c='white', zorder=2)\n",
    "    \n",
    "    square_f1 = plt.Polygon([(-2, 0), (-15, 0), (-15, n_f1), (-2, n_f1)], closed=True, color='red', linewidth=0.)\n",
    "    square_f1f2 = plt.Polygon([(-2, n_f1), (-15, n_f1), (-15, n_f1+n_f1f2), (-2, n_f1+n_f1f2)], closed=True, color='gold', linewidth=0.)\n",
    "    square_f2 = plt.Polygon([(-2, n_f1+n_f1f2), (-15, n_f1+n_f1f2), (-15, n_f1+n_f1f2+n_f2), (-2, n_f1+n_f1f2+n_f2)], closed=True, color='blue', linewidth=0.)\n",
    "    timescale_f1 = plt.Polygon([(0, -10), (period_f1/TR, -10), (period_f1/TR, -30), (0, -30)], closed=True, color='red', linewidth=0., zorder=10)\n",
    "    timescale_f2 = plt.Polygon([(0, -40), (period_f2/TR, -40), (period_f2/TR, -60), (0, -60)], closed=True, color='blue', linewidth=0., zorder=10)\n",
    "\n",
    "    for square in [square_f1, square_f1f2, square_f2, timescale_f1, timescale_f2]:\n",
    "        ax.add_patch(square)\n",
    "\n",
    "    for i in (\"top\", \"right\", \"bottom\", \"left\"):\n",
    "        ax.spines[i].set_visible(False)\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = Path(\"/scratch/fastfmri\")\n",
    "n_bootstraps = 200\n",
    "bootstrap_id = 0\n",
    "roi_frequency_2 = None\n",
    "control_roi_size = False\n",
    "window_size = (39, 219)\n",
    "close_figures = True\n",
    "    \n",
    "experiment_id = \"1_frequency_tagging\" \n",
    "normal_3T_sub_ids = [\"000\", \"002\", \"003\", \"004\", \"005\", \"006\", \"007\", \"008\", \"009\"] \n",
    "normal_7T_sub_ids = [\"Pilot001\", \"Pilot009\", \"Pilot010\", \"Pilot011\"]\n",
    "vary_sub_ids = [\"020\"]*3 + [\"021\"]*3\n",
    "vary_task_ids = [f\"entrain{i}\" for i in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]]\n",
    "\n",
    "fos = [.4,.6,.8,1.]\n",
    "sub_ids = normal_3T_sub_ids*2 + normal_7T_sub_ids + vary_sub_ids*3*2\n",
    "experiment_ids = [\"1_frequency_tagging\"]*len(normal_3T_sub_ids)*2 + [\"1_attention\"]*len(normal_7T_sub_ids) + [\"1_frequency_tagging\"]*len(vary_sub_ids)*3*2\n",
    "mri_ids = [\"3T\"]*len(normal_3T_sub_ids)*2 + [\"7T\"]*len(normal_7T_sub_ids) + [\"3T\"]*len(vary_sub_ids)*3 + [\"7T\"]*len(vary_sub_ids)*3\n",
    "roi_task_ids= [\"entrain\"]*len(normal_3T_sub_ids) + [\"entrain\"]*len(normal_3T_sub_ids) + ['AttendAway']*len(normal_7T_sub_ids) + ([\"entrainA\"]*3 + [\"entrainD\"]*3 + [\"entrainB\"]*3 + [\"entrainE\"]*3 + [\"entrainC\"]*3 + [\"entrainF\"]*3) * 2\n",
    "task_ids= [\"control\"]*len(normal_3T_sub_ids) + [\"entrain\"]*len(normal_3T_sub_ids) + ['AttendAway']*len(normal_7T_sub_ids) + vary_task_ids*3*2\n",
    "roi_frequencies = [[.125, .2]]*(len(normal_3T_sub_ids)*2+len(normal_7T_sub_ids)) + ([[.125,.2]]*3 + [[.125,.2]]*3 + [[.125,.175]]*3 + [[.15,.2]]*3 + [[.125,.15]]*3 + [[.175,.2]]*3) * 2\n",
    "task_frequencies = [[.125, .2]]*(len(normal_3T_sub_ids)*2+len(normal_7T_sub_ids)) + [[.125,.2],[.125,.175],[.125,.15],[.125,.2],[.15,.2],[.175,.2]]*3*2\n",
    "\n",
    "for i in [sub_ids, experiment_ids, mri_ids, roi_task_ids, task_ids, roi_frequencies, task_frequencies]:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fo in fos:\n",
    "    for experiment_id, mri_id, sub_id, roi_task_id, task_id, frequencies, _task_frequencies in zip(\n",
    "        experiment_ids, mri_ids, sub_ids, roi_task_ids, task_ids, roi_frequencies, task_frequencies,\n",
    "    ):\n",
    "\n",
    "        f_data = {}\n",
    "        for roi_f in frequencies:\n",
    "            f_data[roi_f] = read_pkl(\n",
    "                datadir, \n",
    "                n_bootstraps, \n",
    "                sub_id, \n",
    "                roi_task_id, \n",
    "                roi_f, \n",
    "                task_id,\n",
    "                experiment_id=experiment_id,\n",
    "                mri_id=mri_id,\n",
    "                fo=fo,\n",
    "                roi_frequency_2=roi_frequency_2,\n",
    "                control_roi_size=control_roi_size,\n",
    "            )\n",
    "\n",
    "        task_quadrant = find_quadrant_id_from_keys(f_data[frequencies[0]])\n",
    "                \n",
    "        assert frequencies[1]>frequencies[0]\n",
    "        f1_dict = f_data[frequencies[0]].copy()\n",
    "        f2_dict = f_data[frequencies[1]].copy()\n",
    "        f1_coords = f1_dict['roi_coords']\n",
    "        f2_coords = f2_dict['roi_coords']\n",
    "        f1_only_coords = f1_coords.astype(int) + f2_coords.astype(int)\n",
    "        f1_only_coords = f1_only_coords[f1_coords]\n",
    "        f2_only_coords = f1_coords.astype(int) + f2_coords.astype(int)\n",
    "        f2_only_coords = f2_only_coords[f2_coords]\n",
    "        # Masks\n",
    "        inter_from_f1 = f1_only_coords == 2\n",
    "        f1_from_f1 = f1_only_coords == 1\n",
    "        f2_from_f2 = f2_only_coords == 1\n",
    "        n_f1, n_f1f2, n_f2 = f1_from_f1.sum(), inter_from_f1.sum(), f2_from_f2.sum()\n",
    "\n",
    "        # Load data from nifti\n",
    "        # 1) untruncated, 2) preprocessed\n",
    "        bootstrap_txt = Path(f\"/scratch/fastfmri/experiment-{experiment_id}_mri-{mri_id}_smooth-0_truncate-{window_size[0]}-{window_size[1]}_n-100_batch-00_desc-basic_bootstrap/sub-{sub_id}/task-{task_id}{task_quadrant}_test_splits.txt\")\n",
    "        assert bootstrap_txt.exists()\n",
    "        data_from_dtseries_raw, data_from_dtseries_windowed, data_from_dtseries_preprocessed = read_bootstrap_txt(bootstrap_txt, bootstrap_id) # Load single bootstrap\n",
    "\n",
    "        data_from_dtseries_raw = np.hstack(\n",
    "            [\n",
    "                data_from_dtseries_raw[f1_coords,:][f1_from_f1,:].T,\n",
    "                data_from_dtseries_raw[f1_coords,:][inter_from_f1,:].T,\n",
    "                data_from_dtseries_raw[f2_coords,:][f2_from_f2,:].T,\n",
    "            ]\n",
    "        )\n",
    "        data_from_dtseries_windowed = np.hstack(\n",
    "            [\n",
    "                data_from_dtseries_windowed[f1_coords,1:][f1_from_f1,:].T,\n",
    "                data_from_dtseries_windowed[f1_coords,1:][inter_from_f1,:].T,\n",
    "                data_from_dtseries_windowed[f2_coords,1:][f2_from_f2,:].T,\n",
    "            ]\n",
    "        )\n",
    "        data_from_dtseries_preprocessed = np.hstack(\n",
    "            [\n",
    "                data_from_dtseries_preprocessed[f1_coords,1:][f1_from_f1,:].T,\n",
    "                data_from_dtseries_preprocessed[f1_coords,1:][inter_from_f1,:].T,\n",
    "                data_from_dtseries_preprocessed[f2_coords,1:][f2_from_f2,:].T,\n",
    "            ]\n",
    "        )\n",
    "        # Load data from pickle\n",
    "        # 3) preprocessed, 4) preprocessed & phased\n",
    "        _, f1_data_from_pkl_preprocessed = extract_carpet_data(f1_dict, task_id, task_quadrant, bootstrap_id, False)\n",
    "        f1_phased_tps, f1_data_from_pkl_preprocessed_phased = extract_carpet_data(f1_dict, task_id, task_quadrant, bootstrap_id, True)\n",
    "        _, f2_data_from_pkl_preprocessed = extract_carpet_data(f2_dict, task_id, task_quadrant, bootstrap_id, False)\n",
    "        f2_phased_tps, f2_data_from_pkl_preprocessed_phased = extract_carpet_data(f2_dict, task_id, task_quadrant, bootstrap_id, True)\n",
    "        intersected_phased_tps = [i for i in set(f1_phased_tps).intersection(f2_phased_tps)]\n",
    "        f1_phased_tp_mask = [tp in intersected_phased_tps for tp in f1_phased_tps]\n",
    "        f2_phased_tp_mask = [tp in intersected_phased_tps for tp in f2_phased_tps]\n",
    "\n",
    "        data_from_pkl_preprocessed = np.hstack(\n",
    "            [\n",
    "                f1_data_from_pkl_preprocessed[:,f1_from_f1],\n",
    "                f1_data_from_pkl_preprocessed[:,inter_from_f1],\n",
    "                f2_data_from_pkl_preprocessed[:,f2_from_f2],\n",
    "            ]\n",
    "        )\n",
    "        data_from_pkl_preprocessed_phased = np.hstack(\n",
    "            [\n",
    "                f1_data_from_pkl_preprocessed_phased[:,f1_from_f1][f1_phased_tp_mask,:],\n",
    "                f1_data_from_pkl_preprocessed_phased[:,inter_from_f1][f1_phased_tp_mask,:],\n",
    "                f2_data_from_pkl_preprocessed_phased[:,f2_from_f2][f2_phased_tp_mask,:],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        ts_labels = [\n",
    "            \"raw\", \"windowed\", \"denoised\", \"denoised_rephased\"\n",
    "        ]\n",
    "        ts_data = [\n",
    "            data_from_dtseries_raw, \n",
    "            data_from_dtseries_windowed,\n",
    "            data_from_dtseries_preprocessed,\n",
    "            #data_from_pkl_preprocessed, \n",
    "            data_from_pkl_preprocessed_phased,\n",
    "        ]\n",
    "\n",
    "        stim_start = 14\n",
    "        cmap = \"Greys_r\"\n",
    "        vmin, vmax = -1.31, 1.31\n",
    "\n",
    "        # Get sorting order based on `data_from_dtseries_preprocessed`\n",
    "        # Sort for each set of vertices: f1, f1f2, and f2 (this is the order that the reoriented data)\n",
    "        # Note: `data_from_dtseries_preprocessed` == `data_from_pkl_preprocessed`\n",
    "\n",
    "        try:\n",
    "            # This will error out if there is any of f1, f2, or f1f2 has 0 vertices.. I THINK?\n",
    "            y = data_from_dtseries_preprocessed.copy()\n",
    "            y = (( y - y.mean(0)) / y.std(0) ).T\n",
    "            sorted_voxels = {}\n",
    "            y_f1 = y[:n_f1,:].copy()\n",
    "            y_f1f2 = y[n_f1:n_f1+n_f1f2,:].copy()\n",
    "            y_f2 = y[n_f1+n_f1f2:,:].copy()\n",
    "            for f_group, y in zip([\"f1\",\"f1f2\",\"f2\"], [y_f1, y_f1f2, y_f2]):\n",
    "                C = np.corrcoef(y)\n",
    "                correlation_strength = np.abs(C).sum(axis=1)\n",
    "                sorted_voxels[f_group] = np.argsort(correlation_strength)[::-1]\n",
    "\n",
    "            for y_ix, (y_label, y) in enumerate(zip(ts_labels, ts_data)):\n",
    "                fig, ax = plt.subplots(\n",
    "                    nrows=1,ncols=1, figsize=(2,1.), dpi=300,\n",
    "                    #gridspec_kw=dict(height_ratios=[286, 119]),\n",
    "                )\n",
    "                \n",
    "                y = (( y - y.mean(0)) / y.std(0) ).T\n",
    "\n",
    "                # Sort\n",
    "                y[:n_f1, :] = y[:n_f1,:][sorted_voxels[\"f1\"],:]\n",
    "                y[n_f1:n_f1+n_f1f2, :] = y[n_f1:n_f1+n_f1f2,:][sorted_voxels[\"f1f2\"],:]\n",
    "                y[n_f1+n_f1f2:, :] = y[n_f1+n_f1f2:,:][sorted_voxels[\"f2\"],:]\n",
    "\n",
    "                im = ax.imshow(y, cmap=cmap, vmin=vmin, vmax=vmax, aspect='auto')\n",
    "                if y_ix == 0:\n",
    "                    for i in window_size:\n",
    "                        ax.axvline(x=i/TR, color='yellow', linestyle='-', lw=1.)\n",
    "                    ax.axvline(x=stim_start/TR, color='orange', linestyle='-', lw=1.)\n",
    "                fig, ax = decorate_fig_1A(fig, ax, im, _task_frequencies[0], _task_frequencies[1], n_f1, n_f2, n_f1f2, FONTSIZE=FONTSIZE, TR=TR)\n",
    "\n",
    "                fig.tight_layout()\n",
    "\n",
    "                png_out = Path(set_base_dir(f\"./ComputeCanada/frequency_tagging/figures/dual_frequency_timeseries\")) / f\"experiment-{experiment_id}_mri-{mri_id}_sub-{sub_id}_task-{roi_task_id}_task-{task_id}_fo-{fo}_{y_ix}{y_label}.png\"\n",
    "                fig.savefig(png_out, dpi='figure')\n",
    "\n",
    "                if close_figures:\n",
    "                    plt.close()\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot single-subject PSDs based on three ROIs (f1, f2, and f1/f2 intersection)\n",
    "- main point: to show that peaks are clearly delineated in every subject (Shown as Z-scored power values)\n",
    "- extra data will be generated as `.pkl`s and used in the next notebook to investigate trends of raw power values\n",
    "- a PSD figure will be generated for each experiment\n",
    "- hyperparameter: fractional overlap (or `fo`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMAL_3T_SUB_IDS = [\"000\", \"002\", \"003\", \"004\", \"005\", \"006\", \"007\", \"008\", \"009\"]\n",
    "NORMAL_3T = (\"1_frequency_tagging\", \"3T\", {key: [(\"entrain\", [0.125, 0.2])] for key in NORMAL_3T_SUB_IDS})\n",
    "NORMAL_7T_SUB_IDS = [\"Pilot001\", \"Pilot009\", \"Pilot010\", \"Pilot011\"]\n",
    "NORMAL_7T = (\"1_attention\", \"7T\", {key: [(\"AttendAway\", [0.125, 0.2])] for key in NORMAL_7T_SUB_IDS})\n",
    "VARY_3T = (\n",
    "    \"1_frequency_tagging\",\n",
    "    \"3T\",\n",
    "    {\n",
    "        \"020\": [\n",
    "            (\"entrainA\", [.125, .2]),\n",
    "            (\"entrainB\", [.125, .175]),\n",
    "            (\"entrainC\", [.125, .15]),\n",
    "        ],\n",
    "        \"021\": [\n",
    "            (\"entrainD\", [.125, .2]),\n",
    "            (\"entrainE\", [.15, .2]),\n",
    "            (\"entrainF\", [.175, .2]),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "VARY_7T = (\n",
    "    \"1_frequency_tagging\",\n",
    "    \"7T\",\n",
    "    {\n",
    "        \"020\": [\n",
    "            (\"entrainA\", [.125, .2]),\n",
    "            (\"entrainB\", [.125, .175]),\n",
    "            (\"entrainC\", [.125, .15]),\n",
    "        ],\n",
    "        \"021\": [\n",
    "            (\"entrainD\", [.125, .2]),\n",
    "            (\"entrainE\", [.15, .2]),\n",
    "            (\"entrainF\", [.175, .2]),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "def read_data(d):\n",
    "    return d[0], d[1], d[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used for generating all pickles\n",
    "- Change `task_id_2`, and looping parameters (i.e., `dataset_id`, `control_roi_size`, and `phased_flag`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "#for dataset_id, control_roi_size, phased_flag in itertools.product([NORMAL_7T], [True, False], [True,False]):\n",
    "for dataset_id, control_roi_size, phased_flag in itertools.product([NORMAL_7T], [True,False], [True,False]):\n",
    "\n",
    "    experiment_id, mri_id, sub_to_task_mapping = read_data(dataset_id)\n",
    "\n",
    "    control_roi_size = control_roi_size\n",
    "    phased_flag = phased_flag\n",
    "    fo = .8\n",
    "    frequency_grid = None\n",
    "    experiment_info = []\n",
    "    subject_task_level_psd = defaultdict(list)\n",
    "    for sub_ix, (sub_id, sub_task_info) in enumerate(sub_to_task_mapping.items()):\n",
    "        for task_ix, (task_id, frequencies) in enumerate(sub_task_info):\n",
    "\n",
    "            bold_list = !ls /data/{experiment_id}/{mri_id}/bids/sub-{sub_id}/*/func/*{task_id}*nii.gz\n",
    "            task_quadrant = list(set([i.split(task_id)[1].split('_')[0] for i in bold_list]))\n",
    "            assert len(task_quadrant) == 1, f\"More than 1 task quadrant detected: {task_quadrant}\"\n",
    "            task_quadrant = task_quadrant[0]\n",
    "\n",
    "            assert len(frequencies) == 2 and frequencies[0]<frequencies[1]\n",
    "\n",
    "            if sub_id == \"020\":\n",
    "                task_id_2 = \"entrainC\"\n",
    "            else:\n",
    "                task_id_2 = \"entrainF\"\n",
    "            task_id_2 = task_id\n",
    "\n",
    "            for f_ix, f in enumerate(frequencies + [frequencies]):\n",
    "\n",
    "                if control_roi_size and f_ix < 2:\n",
    "                    print(f\"Skipping {task_id} {f}\")\n",
    "                    continue\n",
    "\n",
    "                if isinstance(f, list) and len(f) == 2:\n",
    "                    if control_roi_size:\n",
    "                        data = read_pkl(datadir, n_bootstraps, sub_id, task_id, f[0], task_id_2, experiment_id=experiment_id, mri_id=mri_id, fo=fo, roi_frequency_2=f[1], control_roi_size=control_roi_size)\n",
    "                    else:\n",
    "                        data = read_pkl(datadir, n_bootstraps, sub_id, task_id, f[0], task_id_2, experiment_id=experiment_id, mri_id=mri_id, fo=fo, roi_frequency_2=f[1])\n",
    "                elif isinstance(f, float):\n",
    "                    data = read_pkl(datadir, n_bootstraps, sub_id, task_id, f, task_id_2, experiment_id=experiment_id, mri_id=mri_id, fo=fo)\n",
    "                else:\n",
    "                    raise ValueError(\"\")\n",
    "                    \n",
    "                if data is None:\n",
    "                    print(f\"sub-{sub_id}, ROI info: {task_id}/f={f} [n=0], task-frequencies: {frequencies}, No data found\")\n",
    "                    subject_task_level_psd[f\"f-{f_ix}\"].append(None)\n",
    "                    continue\n",
    "                n_voxels = data['roi_coords'].sum()\n",
    "                print(f\"sub-{sub_id}, ROI info: {task_id}/f={f} [n={n_voxels}], task-frequencies: {frequencies}\")\n",
    "                \n",
    "                ####\n",
    "                if task_id_2 == \"AttendAway\":\n",
    "                    frequencies_to_probe = [.125, .2, .075]\n",
    "                if task_id_2 == \"entrain\":\n",
    "                    frequencies_to_probe = [.125, .2, .075]\n",
    "                if task_id_2 == \"control\":\n",
    "                    frequencies_to_probe = [.125, .2, .075]\n",
    "                if task_id_2 == \"entrainA\":\n",
    "                    frequencies_to_probe = [.125, .2, .075]\n",
    "                if task_id_2 == \"entrainB\":\n",
    "                    frequencies_to_probe = [.125, .175, .05]\n",
    "                if task_id_2 == \"entrainC\":\n",
    "                    frequencies_to_probe = [.125, .15, .025]\n",
    "                if task_id_2 == \"entrainD\":\n",
    "                    frequencies_to_probe = [.125, .2, .075]\n",
    "                if task_id_2 == \"entrainE\":\n",
    "                    frequencies_to_probe = [.15, .2, .05]\n",
    "                if task_id_2 == \"entrainF\":\n",
    "                    frequencies_to_probe = [.175, .2, .025]\n",
    "                print(f\"Processing {frequencies_to_probe} in sub-{sub_id}_task-{task_id_2}\\n\")\n",
    "        \n",
    "                # Select timeseries (timepoints x voxels x bootstraps)\n",
    "                bootstrapped_means = []\n",
    "                bootstrapped_statistics = defaultdict(list)\n",
    "                for bootstrap_id in range(n_bootstraps):\n",
    "                    \n",
    "                    _, y_bootstrapped_mean = extract_bootstrapped_mean_from_data(data, task_id_2, task_quadrant, bootstrap_id, phased_flag)\n",
    "\n",
    "                    bootstrapped_means.append(y_bootstrapped_mean) # Track\n",
    "\n",
    "                    ts = TimeSeries(y_bootstrapped_mean, TR, n_permutations=n_permutations)\n",
    "\n",
    "                    p_values, observed_statistics, observed_power_spectrum, null_power_spectrums = ts.process(frequencies_to_probe)\n",
    "                    for test_f in frequencies_to_probe:\n",
    "                        bootstrapped_statistics[f\"test-{test_f}\"].append((p_values[test_f], observed_statistics[test_f]))\n",
    "                    \"\"\"\n",
    "                    for test_f in frequencies:\n",
    "                        bootstrapped_statistics[f\"sub-{sub_id}_task-{task_id}_roi-{f}_test-{test_f}_{task_id_2}\"].append((p_values[test_f], observed_statistics[test_f]))\n",
    "                    \"\"\"\n",
    "                \n",
    "                if isinstance(f, list) and len(f) == 2:\n",
    "                    if control_roi_size:\n",
    "                        save_pkl = f\"experiment-{experiment_id}_mri-{mri_id}_sub-{sub_id}_roitask-{task_id}_roi-{f[0]}_controlroisizetomatch-{f[1]}_task-{task_id_2}_fo-{fo}_phaseadjusted-{phased_flag}_n-{n_permutations}.pkl\"\n",
    "                        save_bootstrapped_statistics(save_pkl, bootstrapped_statistics)\n",
    "                    else:\n",
    "                        save_pkl = f\"experiment-{experiment_id}_mri-{mri_id}_sub-{sub_id}_roitask-{task_id}_roi-{f[0]}-{f[1]}_task-{task_id_2}_fo-{fo}_phaseadjusted-{phased_flag}_n-{n_permutations}.pkl\"\n",
    "                        save_bootstrapped_statistics(save_pkl, bootstrapped_statistics)\n",
    "                elif isinstance(f, float):\n",
    "                    save_pkl = f\"experiment-{experiment_id}_mri-{mri_id}_sub-{sub_id}_roitask-{task_id}_roi-{f}_task-{task_id_2}_fo-{fo}_phaseadjusted-{phased_flag}_n-{n_permutations}.pkl\"\n",
    "                    save_bootstrapped_statistics(save_pkl, bootstrapped_statistics)\n",
    "                    \n",
    "                del bootstrapped_statistics\n",
    "                    \n",
    "                bootstrapped_means = np.vstack(bootstrapped_means)\n",
    "                y_bootstrapped_mean = bootstrapped_means.mean(0)\n",
    "                \n",
    "                ts = TimeSeries(y_bootstrapped_mean, TR, n_permutations=n_permutations)\n",
    "                p_values, observed_statistics, observed_power_spectrum, null_power_spectrums = ts.process(frequencies_to_probe)\n",
    "                \n",
    "                if not phased_flag:\n",
    "                    if frequency_grid is None:\n",
    "                        frequency_grid = ts.frequencies\n",
    "                    else:\n",
    "                        assert np.allclose(frequency_grid, ts.frequencies, rtol=1e-05, atol=1e-08)\n",
    "\n",
    "                subject_task_level_psd[f\"f-{f_ix}\"].append(observed_power_spectrum)\n",
    "\n",
    "                # Plot\n",
    "                \"\"\"\n",
    "                if sub_ix == 0 and task_ix == 0 and f_ix == 0:\n",
    "                    plot_power_spectrum(ts, observed_power_spectrum, null_power_spectrums, add_im=True, sub_id=sub_id, roi_frequency=f)\n",
    "                \"\"\"\n",
    "                \n",
    "            experiment_info.append((sub_id, task_id,frequencies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use to generate single experiment PSD heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "def decorate_fig_1C(\n",
    "    fig, ax, im, \n",
    "    frequencies_per_experiment, frequency_grid,\n",
    "    arrow_pos = [],\n",
    "    yticks=[], yticklabels=[], \n",
    "    xticks=[], xticklabels=[], \n",
    "    FONTSIZE=FONTSIZE,\n",
    "    lower_f=True\n",
    "):\n",
    "\n",
    "    cbar = plt.colorbar(im, ax=ax, shrink=.5, drawedges=False)\n",
    "    cbar.ax.set_title(\"Z-scored\\nPSD\", fontsize=FONTSIZE)\n",
    "    cbar.ax.tick_params(axis=\"both\", length=0, labelsize=FONTSIZE)\n",
    "    cbar.outline.set_edgecolor('none')\n",
    "\n",
    "    ax.set_ylabel(\"Experiments\", fontsize=FONTSIZE)\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels(yticklabels, fontsize=FONTSIZE)\n",
    "\n",
    "    ax.set_xlabel(\"Frequency (Hz)\", fontsize=FONTSIZE)\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels(xticklabels, fontsize=FONTSIZE)\n",
    "    \n",
    "    ax.tick_params(axis=\"both\", length=0)\n",
    "\n",
    "    for experiment_ix, _fs in enumerate(frequencies_per_experiment):\n",
    "        match_f = 0\n",
    "        if lower_f:\n",
    "            match_f = 1\n",
    "        for _ix, f in enumerate(_fs):\n",
    "            fc = 'red'\n",
    "            if _ix == match_f:\n",
    "                if lower_f is not None:\n",
    "                    fc = 'cyan'\n",
    "            arrow_props = dict(facecolor=fc, edgecolor=fc, arrowstyle='simple', linewidth=0, mutation_scale=3)\n",
    "            _xpos = np.interp(f, frequency_grid, np.arange(len(frequency_grid)))\n",
    "            ax.annotate('', xy=(_xpos,experiment_ix), xytext=(_xpos+1,experiment_ix), arrowprops=arrow_props, annotation_clip=False)\n",
    "\n",
    "\n",
    "    for i in (\"top\", \"right\", \"bottom\", \"left\"):\n",
    "        ax.spines[i].set_visible(False)\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "def clean_subject_task_level_psd(psd_list):\n",
    "    for psd_ix, i in enumerate(psd_list):\n",
    "        if i is None:\n",
    "            for j in psd_list:\n",
    "                if j is not None:\n",
    "                    psd_list[psd_ix] = np.zeros_like(j)\n",
    "    \n",
    "    return psd_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_roi_size = False\n",
    "phased_flag = False\n",
    "n_permutations=5\n",
    "close_figure = True # closes single ROI psds\n",
    "\n",
    "for fo in [.4, .6, .8, 1.]:\n",
    "    dataset_ids = [NORMAL_3T, NORMAL_3T, NORMAL_7T, VARY_3T, VARY_7T]\n",
    "    dataset_labels = [\"NORMAL_3T\", \"NORMAL_3T_CONTROL\", \"NORMAL_7T\", \"VARY_3T\", \"VARY_7T\"]\n",
    "    for dataset_ix, (dataset_label, dataset_id) in enumerate(zip(dataset_labels, dataset_ids)):\n",
    "        experiment_id, mri_id, sub_to_task_mapping = read_data(dataset_id)\n",
    "        frequency_grid = None\n",
    "        experiment_info = []\n",
    "        subject_task_level_psd = defaultdict(list)\n",
    "        for sub_ix, (sub_id, sub_task_info) in enumerate(sub_to_task_mapping.items()):\n",
    "            for task_ix, (task_id, frequencies) in enumerate(sub_task_info):\n",
    "\n",
    "                bold_list = !ls /data/{experiment_id}/{mri_id}/bids/sub-{sub_id}/*/func/*{task_id}*nii.gz\n",
    "                task_quadrant = list(set([i.split(task_id)[1].split('_')[0] for i in bold_list]))\n",
    "                assert len(task_quadrant) == 1, f\"More than 1 task quadrant detected: {task_quadrant}\"\n",
    "                task_quadrant = task_quadrant[0]\n",
    "\n",
    "                assert len(frequencies) == 2 and frequencies[0]<frequencies[1]\n",
    "\n",
    "                \"\"\"\n",
    "                if sub_id == \"020\":\n",
    "                    task_id_2 = \"entrainC\"\n",
    "                else:\n",
    "                    task_id_2 = \"entrainF\"\n",
    "                task_id_2 = task_id\n",
    "                \"\"\"\n",
    "                if dataset_ix == 1:\n",
    "                    task_id_2 = 'control'\n",
    "                else:\n",
    "                    task_id_2 = task_id\n",
    "\n",
    "                for f_ix, f in enumerate(frequencies + [frequencies]):\n",
    "\n",
    "                    if control_roi_size and f_ix < 2:\n",
    "                        print(f\"Skipping {task_id} {f}\")\n",
    "                        continue\n",
    "\n",
    "                    if isinstance(f, list) and len(f) == 2:\n",
    "                        if control_roi_size:\n",
    "                            data = read_pkl(datadir, n_bootstraps, sub_id, task_id, f[0], task_id_2, experiment_id=experiment_id, mri_id=mri_id, fo=fo, roi_frequency_2=f[1], control_roi_size=control_roi_size)\n",
    "                        else:\n",
    "                            data = read_pkl(datadir, n_bootstraps, sub_id, task_id, f[0], task_id_2, experiment_id=experiment_id, mri_id=mri_id, fo=fo, roi_frequency_2=f[1])\n",
    "                    elif isinstance(f, float):\n",
    "                        data = read_pkl(datadir, n_bootstraps, sub_id, task_id, f, task_id_2, experiment_id=experiment_id, mri_id=mri_id, fo=fo)\n",
    "                    else:\n",
    "                        raise ValueError(\"\")\n",
    "                        \n",
    "                    if data is None:\n",
    "                        print(f\"sub-{sub_id}, ROI info: {task_id}/f={f} [n=0], task-frequencies: {frequencies}, No data found\")\n",
    "                        subject_task_level_psd[f\"f-{f_ix}\"].append(None)\n",
    "                        continue\n",
    "                    n_voxels = data['roi_coords'].sum()\n",
    "                    print(f\"sub-{sub_id}, ROI info: {task_id}/f={f} [n={n_voxels}], task-frequencies: {frequencies}\")\n",
    "                    \n",
    "                    ####\n",
    "                    if task_id_2 == \"AttendAway\":\n",
    "                        frequencies_to_probe = [.125, .2]\n",
    "                    if task_id_2 == \"entrain\":\n",
    "                        frequencies_to_probe = [.125, .2]\n",
    "                    if task_id_2 == \"control\":\n",
    "                        frequencies_to_probe = [.125, .2]\n",
    "                    if task_id_2 == \"entrainA\":\n",
    "                        frequencies_to_probe = [.125, .2]\n",
    "                    if task_id_2 == \"entrainB\":\n",
    "                        frequencies_to_probe = [.125, .175]\n",
    "                    if task_id_2 == \"entrainC\":\n",
    "                        frequencies_to_probe = [.125, .15]\n",
    "                    if task_id_2 == \"entrainD\":\n",
    "                        frequencies_to_probe = [.125, .2]\n",
    "                    if task_id_2 == \"entrainE\":\n",
    "                        frequencies_to_probe = [.15, .2]\n",
    "                    if task_id_2 == \"entrainF\":\n",
    "                        frequencies_to_probe = [.175, .2]\n",
    "                    print(f\"Processing {frequencies_to_probe} in sub-{sub_id}_task-{task_id_2}\\n\")\n",
    "            \n",
    "                    # Select timeseries (timepoints x voxels x bootstraps)\n",
    "                    bootstrapped_means = []\n",
    "                    bootstrapped_statistics = defaultdict(list)\n",
    "                    for bootstrap_id in range(n_bootstraps):\n",
    "                        \n",
    "                        _, y_bootstrapped_mean = extract_bootstrapped_mean_from_data(data, task_id_2, task_quadrant, bootstrap_id, phased_flag)\n",
    "\n",
    "                        bootstrapped_means.append(y_bootstrapped_mean) # Track\n",
    "\n",
    "                        ts = TimeSeries(y_bootstrapped_mean, TR, n_permutations=n_permutations)\n",
    "\n",
    "                        p_values, observed_statistics, observed_power_spectrum, null_power_spectrums = ts.process(frequencies_to_probe)\n",
    "                        for test_f in frequencies_to_probe:\n",
    "                            bootstrapped_statistics[f\"test-{test_f}\"].append((p_values[test_f], observed_statistics[test_f]))\n",
    "                        \n",
    "                    bootstrapped_means = np.vstack(bootstrapped_means)\n",
    "                    y_bootstrapped_mean = bootstrapped_means.mean(0)\n",
    "                    \n",
    "                    ts = TimeSeries(y_bootstrapped_mean, TR, n_permutations=n_permutations)\n",
    "                    p_values, observed_statistics, observed_power_spectrum, null_power_spectrums = ts.process(frequencies_to_probe)\n",
    "                    \n",
    "                    if not phased_flag:\n",
    "                        if frequency_grid is None:\n",
    "                            frequency_grid = ts.frequencies\n",
    "                        else:\n",
    "                            assert np.allclose(frequency_grid, ts.frequencies, rtol=1e-05, atol=1e-08)\n",
    "\n",
    "                    subject_task_level_psd[f\"f-{f_ix}\"].append(observed_power_spectrum)\n",
    "\n",
    "                    # Plot\n",
    "                    if isinstance(f, list):\n",
    "                        figlabel = '-'.join(str(i) for i in f)\n",
    "                    else:\n",
    "                        figlabel = copy(f)\n",
    "                    png_out = Path(set_base_dir(f\"./ComputeCanada/frequency_tagging/figures/dual_frequency_roi_psd\")) / f\"experiment-{experiment_id}_mri-{mri_id}_sub-{sub_id}_roitask-{task_id}-{figlabel}_task-{task_id_2}_fo-{fo}_.png\"\n",
    "                    plot_power_spectrum(\n",
    "                        ts, \n",
    "                        observed_power_spectrum, \n",
    "                        null_power_spectrums, \n",
    "                        add_im=True, \n",
    "                        sub_id=sub_id, \n",
    "                        roi_frequency=f, \n",
    "                        close_figure=close_figure,\n",
    "                        png_out=png_out,\n",
    "                    )\n",
    "                    \n",
    "                experiment_info.append((sub_id, task_id,frequencies))\n",
    "\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(3,1), dpi=300)\n",
    "\n",
    "        xmax = (frequency_grid<.5).sum()\n",
    "\n",
    "        all_frequencies = []\n",
    "        for i in experiment_info:\n",
    "            all_frequencies += i[2]\n",
    "        all_frequencies = list(set(all_frequencies))\n",
    "\n",
    "        for ix, (i, ax) in enumerate(zip(range(3), axs)):\n",
    "            subject_task_level_psd[f\"f-{i}\"] = clean_subject_task_level_psd(subject_task_level_psd[f\"f-{i}\"])\n",
    "            sub_task_psds = np.vstack(subject_task_level_psd[f'f-{i}'])\n",
    "            sub_task_psds = ( sub_task_psds - sub_task_psds.mean(1, keepdims=True) ) / sub_task_psds.std(1, keepdims=True)\n",
    "            im = ax.imshow(\n",
    "                sub_task_psds[:,:xmax], \n",
    "                cmap='magma',\n",
    "                interpolation='none', aspect='auto',\n",
    "                vmax=4, vmin=0\n",
    "            )\n",
    "\n",
    "            if ix == 2:\n",
    "                lower_f = None\n",
    "            else: \n",
    "                lower_f = i==0\n",
    "            xticklabels = [0, .1, .2, .3, .4, .5]\n",
    "            decorate_fig_1C(\n",
    "                fig, ax, im,\n",
    "                [i[2] for i in experiment_info], frequency_grid,\n",
    "                yticks=[i for i in range(len(experiment_info))], \n",
    "                yticklabels=[f\"{i[0]} {i[1]}\" for i in experiment_info],\n",
    "                xticks = [np.where(frequency_grid == i)[0][0] for i in xticklabels],\n",
    "                xticklabels=xticklabels,\n",
    "                lower_f=lower_f,\n",
    "                FONTSIZE=FONTSIZE-2\n",
    "            )\n",
    "\n",
    "        fig.tight_layout()\n",
    "                \n",
    "        png_out = Path(set_base_dir(f\"./ComputeCanada/frequency_tagging/figures/dual_frequency_roi_and_group_psd\")) / f\"group-{dataset_label}_fo-{fo}.png\"\n",
    "        fig.savefig(png_out, dpi='figure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot ROI timeseries (normal, and not rephased) of a single bootstrap from a sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_id = 0\n",
    "fig, ax = plt.subplots(figsize=(4,1), dpi=200)\n",
    "x, y = extract_bootstrapped_mean_from_data(data, task_id_2, task_quadrant, bootstrap_id, True)\n",
    "ax.plot(x,y, c='r', zorder=2)\n",
    "x, y = extract_bootstrapped_mean_from_data(data, task_id_2, task_quadrant, bootstrap_id, False)\n",
    "ax.plot(x,y, c='grey', zorder=1)\n",
    "ax.set_title(f'sub-{sub_id} roi-{task_id}-{f} task-{task_id_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
