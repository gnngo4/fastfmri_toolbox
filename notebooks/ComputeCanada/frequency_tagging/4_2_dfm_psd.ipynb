{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"ComputeCanada/frequency_tagging\")\n",
    "from utils import (\n",
    "    set_base_dir,\n",
    "    f1_f2_data, \n",
    "    plot_power_spectrum,\n",
    "    psd_analyze_rois as analyze_rois,\n",
    "    psd_store_data_in_dict as store_data_in_dict,\n",
    "    extract_im_products,\n",
    "    get_roi_colour_codes,\n",
    "    get_frequency_text_codes,\n",
    "    extract_im_products,\n",
    "    change_font,\n",
    "    DFM_ROI_PSDS, PICKLE_DIR, SCRATCH_DIR,\n",
    "    MAIN\n",
    ")\n",
    "change_font()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cohort info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMAL_3T_SUB_IDS = [\"000\", \"002\", \"003\", \"004\", \"005\", \"006\", \"007\", \"008\", \"009\"]\n",
    "NORMAL_3T = (\"1_frequency_tagging\", \"3T\", {key: [(\"entrain\", [0.125, 0.2])] for key in NORMAL_3T_SUB_IDS})\n",
    "NORMAL_7T_SUB_IDS = [\"Pilot001\", \"Pilot009\", \"Pilot010\", \"Pilot011\"]\n",
    "NORMAL_7T = (\"1_attention\", \"7T\", {key: [(\"AttendAway\", [0.125, 0.2])] for key in NORMAL_7T_SUB_IDS})\n",
    "VARY_3T = (\n",
    "    \"1_frequency_tagging\",\n",
    "    \"3T\",\n",
    "    {\n",
    "        \"020\": [\n",
    "            (\"entrainA\", [.125, .2]),\n",
    "            (\"entrainB\", [.125, .175]),\n",
    "            (\"entrainC\", [.125, .15]),\n",
    "        ],\n",
    "        \"021\": [\n",
    "            (\"entrainD\", [.125, .2]),\n",
    "            (\"entrainE\", [.15, .2]),\n",
    "            (\"entrainF\", [.175, .2]),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "VARY_7T = (\n",
    "    \"1_frequency_tagging\",\n",
    "    \"7T\",\n",
    "    {\n",
    "        \"020\": [\n",
    "            (\"entrainA\", [.125, .2]),\n",
    "            (\"entrainB\", [.125, .175]),\n",
    "            (\"entrainC\", [.125, .15]),\n",
    "        ],\n",
    "        \"021\": [\n",
    "            (\"entrainD\", [.125, .2]),\n",
    "            (\"entrainE\", [.15, .2]),\n",
    "            (\"entrainF\", [.175, .2]),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "task_to_test_frequencies_map = {\n",
    "    \"entrain\": [.125, .2],\n",
    "    \"control\": [.125, .2],\n",
    "    \"AttendAway\": [.125, .2],\n",
    "    \"entrainA\": [.125, .2],\n",
    "    \"entrainD\": [.125, .2],\n",
    "    \"entrainB\": [.125, .175],\n",
    "    \"entrainC\": [.125, .15],\n",
    "    \"entrainE\": [.15, .2],\n",
    "    \"entrainF\": [.175, .2],\n",
    "}\n",
    "\n",
    "def read_data(d):\n",
    "    return d[0], d[1], d[2]\n",
    "\n",
    "def save_bootstrapped_statistics(pkl_path, data_dict):\n",
    "    import pickle\n",
    "    with open(pkl_path, 'wb') as f:\n",
    "        pickle.dump(data_dict, f)\n",
    "\n",
    "def load_bootstrapped_statistics(pkl_path):\n",
    "    import pickle\n",
    "    with open(pkl_path, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all statistics as pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = SCRATCH_DIR\n",
    "n_permutations = 500\n",
    "n_bootstraps = 400\n",
    "TR = .3\n",
    "fos = [.8]\n",
    "pvals = [\"uncp\"]\n",
    "nperseg = 572\n",
    "\n",
    "# directories\n",
    "fig_dir = Path(set_base_dir(str(DFM_ROI_PSDS)))\n",
    "pickle_dir = PICKLE_DIR\n",
    "\n",
    "# data stores\n",
    "frequency_grid = None # track, ensuring frequency_grid is consistent\n",
    "#experiment_info = []\n",
    "group_data_dict = None\n",
    "# Loop over roi params: fos and pvals\n",
    "for fo, pval in itertools.product(fos, pvals):\n",
    "\n",
    "    # Loop over datasets\n",
    "    dataset_ids = [NORMAL_3T, NORMAL_3T, NORMAL_7T, VARY_3T, VARY_7T]\n",
    "    dataset_labels = [\"NORMAL_3T\", \"NORMAL_3T_CONTROL\", \"NORMAL_7T\", \"VARY_3T\", \"VARY_7T\"]\n",
    "    for dataset_ix, (dataset_label, dataset_id) in enumerate(zip(dataset_labels, dataset_ids)):\n",
    "        experiment_id, mri_id, sub_to_task_mapping = read_data(dataset_id)\n",
    "\n",
    "        # Loop over subjects\n",
    "        for sub_ix, (sub_id, sub_task_info) in enumerate(sub_to_task_mapping.items()):\n",
    "            for task_ix, (roi_task_id, _) in enumerate(sub_task_info):\n",
    "\n",
    "\n",
    "                if dataset_ix == 1:\n",
    "                    task_id = \"control\"\n",
    "                else:\n",
    "                    task_id = roi_task_id\n",
    "\n",
    "                test_frequencies = task_to_test_frequencies_map[task_id] # Load first order frequencies\n",
    "                assert len(test_frequencies) == 2 and test_frequencies[0] < test_frequencies[1]\n",
    "                \n",
    "                pkl_handler = f1_f2_data(\n",
    "                    datadir, \n",
    "                    n_bootstraps, \n",
    "                    sub_id, \n",
    "                    roi_task_id, \n",
    "                    test_frequencies[0], test_frequencies[1], \n",
    "                    task_id, \n",
    "                    experiment_id=experiment_id, \n",
    "                    mri_id=mri_id, \n",
    "                    fo=fo, \n",
    "                    pval=pval\n",
    "                )\n",
    "                \n",
    "                # Update frequencies to get secondary, and tertiary IM frequencies\n",
    "                im_test_frequencies_map = extract_im_products(test_frequencies[0], test_frequencies[1])\n",
    "                im_test_frequencies = [v for v in im_test_frequencies_map.values()]\n",
    "\n",
    "                info = (\n",
    "                    f\"Processing {dataset_label}, sub-{sub_id}, roi-task-id-{roi_task_id}, task-{task_id}, pval-{pval}, fo-{fo}\\n\"\n",
    "                    f\"   - Primary frequencies: {test_frequencies}\\n\"\n",
    "                    f\"   - Test frequencies: {im_test_frequencies}\"\n",
    "                )\n",
    "                print(info)\n",
    "\n",
    "                # Loop over rephase (enabling rephasing of timeseries with phase delay), frequency of ROIs (f1, f2, f1&f2)\n",
    "                for rephase, f_type in itertools.product([True,False], [\"f1\", \"f2\", \"f1f2\"]):\n",
    "                    if rephase and f_type == \"f1f2\":\n",
    "                        n_intersected_rois = (pkl_handler.f_data['f1']['roi_coords'] * pkl_handler.f_data['f2']['roi_coords']).sum()\n",
    "                        if n_intersected_rois.sum() == 0:\n",
    "                            print(f\"Skipping since 0 voxels were found at the intersection.\")\n",
    "                            continue\n",
    "                        for rephase_with in [\"f1\", \"f2\"]:\n",
    "                            pkl_path = pickle_dir / f\"experiment-{experiment_id}_mri-{mri_id}_sub-{sub_id}_roitask-{roi_task_id}-{f_type}_task-{task_id}_rephase-{rephase}-{rephase_with}_pval-{pval}_fo-{fo}.pkl\"\n",
    "                            png_out = fig_dir / f\"experiment-{experiment_id}_mri-{mri_id}_sub-{sub_id}_roitask-{roi_task_id}-{f_type}_task-{task_id}_rephase-{rephase}-{rephase_with}_pval-{pval}_fo-{fo}.png\"\n",
    "                            if png_out.exists() and pkl_path.exists():\n",
    "                                data_dict = load_bootstrapped_statistics(pkl_path)\n",
    "                            else:\n",
    "                                frequency_grid, observed_statistics, observed_power_spectrum, null_power_spectrums, p_values, bootstrapped_statistics = analyze_rois(\n",
    "                                    pkl_handler, \n",
    "                                    f_type, \n",
    "                                    im_test_frequencies, \n",
    "                                    n_bootstraps, \n",
    "                                    TR, \n",
    "                                    n_permutations=n_permutations, \n",
    "                                    nperseg=nperseg, \n",
    "                                    rephase=rephase, \n",
    "                                    rephase_with=rephase_with,\n",
    "                                    frequency_grid=frequency_grid,\n",
    "                                )\n",
    "                                # Save pkl_path\n",
    "                                data_dict = {\n",
    "                                    \"frequency_grid\": frequency_grid, \n",
    "                                    \"observed_power_spectrum\": observed_power_spectrum, \n",
    "                                    \"null_power_spectrums\": null_power_spectrums, \n",
    "                                    \"observed_statistics\": observed_statistics, \n",
    "                                    \"p_values\": p_values, \n",
    "                                    \"bootstrapped_statistics\": bootstrapped_statistics,\n",
    "                                }\n",
    "                                save_bootstrapped_statistics(pkl_path, data_dict)\n",
    "                                # Save png_out\n",
    "                                plot_power_spectrum(frequency_grid, observed_power_spectrum, null_power_spectrums, n_permutations, test_frequencies, p_values, observed_statistics, add_im=True, sub_id=sub_id, roi_frequency=f_type, close_figure=True, png_out=png_out)\n",
    "                            group_data_dict = store_data_in_dict(\n",
    "                                dataset_label, sub_id,\n",
    "                                roi_task_id, pval, fo, f_type,\n",
    "                                rephase, rephase_with,\n",
    "                                im_test_frequencies_map, data_dict,\n",
    "                                n_bootstraps,\n",
    "                                loaded_data_dict=group_data_dict\n",
    "                            )\n",
    "                    else:\n",
    "                        pkl_path = pickle_dir / f\"experiment-{experiment_id}_mri-{mri_id}_sub-{sub_id}_roitask-{roi_task_id}-{f_type}_task-{task_id}_rephase-{rephase}_pval-{pval}_fo-{fo}.pkl\"\n",
    "                        png_out = fig_dir / f\"experiment-{experiment_id}_mri-{mri_id}_sub-{sub_id}_roitask-{roi_task_id}-{f_type}_task-{task_id}_rephase-{rephase}_pval-{pval}_fo-{fo}.png\"\n",
    "                        if png_out.exists() and pkl_path.exists():\n",
    "                            data_dict = load_bootstrapped_statistics(pkl_path)\n",
    "                        else:\n",
    "                            frequency_grid, observed_statistics, observed_power_spectrum, null_power_spectrums, p_values, bootstrapped_statistics = analyze_rois(\n",
    "                                pkl_handler, \n",
    "                                f_type, \n",
    "                                im_test_frequencies, \n",
    "                                n_bootstraps, \n",
    "                                TR, \n",
    "                                n_permutations=n_permutations, \n",
    "                                nperseg=nperseg, \n",
    "                                rephase=rephase,\n",
    "                                rephase_with=None,\n",
    "                                frequency_grid=frequency_grid,\n",
    "                            )\n",
    "                            # Save pkl_path\n",
    "                            data_dict = {\n",
    "                                \"frequency_grid\": frequency_grid, \n",
    "                                \"observed_power_spectrum\": observed_power_spectrum, \n",
    "                                \"null_power_spectrums\": null_power_spectrums, \n",
    "                                \"observed_statistics\": observed_statistics, \n",
    "                                \"p_values\": p_values, \n",
    "                                \"bootstrapped_statistics\": bootstrapped_statistics,\n",
    "                            }\n",
    "                            save_bootstrapped_statistics(pkl_path, data_dict)\n",
    "                            # Save png_out\n",
    "                            plot_power_spectrum(frequency_grid, observed_power_spectrum, null_power_spectrums, n_permutations, test_frequencies, p_values, observed_statistics, add_im=True, sub_id=sub_id, roi_frequency=f_type, close_figure=True, png_out=png_out)\n",
    "                        group_data_dict = store_data_in_dict(\n",
    "                            dataset_label, sub_id,\n",
    "                            roi_task_id, pval, fo, f_type,\n",
    "                            rephase, None,\n",
    "                            im_test_frequencies_map, data_dict,\n",
    "                            n_bootstraps,\n",
    "                            loaded_data_dict=group_data_dict\n",
    "                        )\n",
    "\n",
    "df = pd.DataFrame(group_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1_cohort_psds(ax, psd_list,xmax, add_cbar=False, fontsize=6,linewidth=.4):\n",
    "    # Stack all PSDs\n",
    "    vstacked_psd = None\n",
    "    for i in psd_list:\n",
    "        n_fs = i.shape[-1]\n",
    "        if vstacked_psd is None:\n",
    "            vstacked_psd = np.zeros((3,n_fs))-1\n",
    "            vstacked_psd = np.vstack((vstacked_psd,i))\n",
    "        else:\n",
    "            vstacked_psd = np.vstack((vstacked_psd,np.zeros((1,n_fs))-1))\n",
    "            vstacked_psd = np.vstack((vstacked_psd,i))\n",
    "\n",
    "\n",
    "    # Plot all psds\n",
    "    vstacked_psd = np.ma.array(vstacked_psd, mask=(vstacked_psd==-1))\n",
    "    cmap = plt.get_cmap(\"BuPu\")\n",
    "    cmap.set_bad(\"white\")\n",
    "    im = ax.imshow(vstacked_psd[:,:xmax], cmap=cmap,interpolation=\"none\",aspect=\"auto\",vmin=-.5,vmax=3)\n",
    "\n",
    "    if add_cbar:\n",
    "        from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "        axins = inset_axes(\n",
    "            ax, width=\"5%\",height=\"25%\",loc=\"center right\",borderpad=-1\n",
    "        )\n",
    "        cbar = fig.colorbar(im, cax=axins)\n",
    "        cbar.outline.set_linewidth(0)\n",
    "        cbar.set_ticks([0,.5,1,1.5,2,2.5,3])\n",
    "        cbar.ax.tick_params(axis='y', pad=0.4, length=2, width=linewidth, direction=\"in\", which=\"both\",colors='white')\n",
    "        cbar.set_ticklabels([f\"{i:.1f}\" for i in [0,.5,1,1.5,2,2.5,3]], fontsize=fontsize,c='k')\n",
    "        cbar.set_label(\"Z-scored PSD\",fontsize=fontsize)\n",
    "\n",
    "def plot_2_cohort_statistics(ax, pval_list,power_list, fontsize=6,linewidth=.4):\n",
    "    vstacked_pval = None\n",
    "    vstacked_power = None\n",
    "    for pval, power in zip(pval_list,power_list):\n",
    "        n_stats = pval.shape[-1]\n",
    "        if vstacked_pval is None:\n",
    "            vstacked_pval = np.zeros((3,n_stats))-1\n",
    "            vstacked_pval = np.vstack((vstacked_pval,pval))\n",
    "        else:\n",
    "            vstacked_pval = np.vstack((vstacked_pval,np.zeros((1,n_stats))-1))\n",
    "            vstacked_pval = np.vstack((vstacked_pval,pval))\n",
    "        if vstacked_power is None:\n",
    "            vstacked_power = np.zeros((3,n_stats))-1\n",
    "            vstacked_power = np.vstack((vstacked_power,power))\n",
    "        else:\n",
    "            vstacked_power = np.vstack((vstacked_power,np.zeros((1,n_stats))-1))\n",
    "            vstacked_power = np.vstack((vstacked_power,power))\n",
    "\n",
    "    assert vstacked_pval.shape == vstacked_power.shape\n",
    "    # Plot empty imshow\n",
    "    empty_arr = np.ma.array(np.zeros_like(vstacked_pval),mask=(np.zeros_like(vstacked_pval)==0))\n",
    "    cmap = plt.get_cmap(\"binary\")\n",
    "    cmap.set_bad(\"white\")\n",
    "    im = ax.imshow(empty_arr,cmap=cmap,interpolation=\"none\",aspect=\"auto\")\n",
    "\n",
    "    return vstacked_pval, vstacked_power\n",
    "\n",
    "def plot_1_arrows(ax, test_frequencies_list,frequency_grid,f1f2_c,start_yloc=2.2,arrow_down_marker_s=12,space_btwn_cohort=1):\n",
    "\n",
    "    yloc = None\n",
    "    for f1,f2,n_sub_ids in test_frequencies_list:\n",
    "\n",
    "        if yloc is None:\n",
    "            yloc = start_yloc\n",
    "        \n",
    "        for _f,c in zip([f1,f2],f1f2_c):\n",
    "            ax.scatter(\n",
    "                np.interp(_f, frequency_grid, range(len(frequency_grid))), \n",
    "                yloc, \n",
    "                s=arrow_down_marker_s, \n",
    "                c=c,\n",
    "                edgecolors='k',\n",
    "                linewidths=0.25, marker='v'\n",
    "            )\n",
    "        \n",
    "        yloc+=(n_sub_ids+space_btwn_cohort)\n",
    "\n",
    "def plot_1_spines_and_ticks(ax, test_frequencies_list,xmax,roi_c,frequency_grid,start_yloc=2.5,linewidth=.4,linestyle='dashed',space_btwn_cohort=1,ytick_on=False,fontsize=6):\n",
    "    \n",
    "    for i in (\"top\", \"right\", \"bottom\", \"left\"):\n",
    "        ax.spines[i].set_visible(False)\n",
    "\n",
    "    yloc_top = None\n",
    "    yloc_bottom = None\n",
    "    ytick_tracker = []\n",
    "    yticklabel_tracker = []\n",
    "    for _,_,n_sub_ids in test_frequencies_list:\n",
    "\n",
    "        if yloc_top is None:\n",
    "            yloc_top = start_yloc\n",
    "        yloc_bottom = yloc_top + n_sub_ids\n",
    "\n",
    "        ax.plot([0,xmax],[yloc_bottom,yloc_bottom],c='k',lw=linewidth,linestyle=linestyle) # bottom\n",
    "        ax.plot([0,xmax],[yloc_top,yloc_top],c='k',lw=linewidth,linestyle=linestyle) # top\n",
    "        ax.plot([0,0],[yloc_bottom,yloc_top],c='k',lw=linewidth,linestyle=linestyle)\n",
    "        ax.plot([xmax,xmax],[yloc_bottom,yloc_top],c='k',lw=linewidth,linestyle=linestyle)\n",
    "\n",
    "        ytick_tracker += [i for i in range(int(yloc_top)+1,int(yloc_top)+n_sub_ids+1)]\n",
    "        yticklabel_tracker += [i for i in range(n_sub_ids)]\n",
    "\n",
    "        yloc_top +=(n_sub_ids+space_btwn_cohort)\n",
    "        \n",
    "    ax.plot([0,xmax],[0.5,0.5],c=roi_c,lw=linewidth) # bottom\n",
    "    ax.plot([0,xmax],[1.5,1.5],c=roi_c,lw=linewidth) # top\n",
    "    ax.fill_between([0,xmax],[.5,.5],[1.5,1.5],color=roi_c) # top\n",
    "    \n",
    "    YTICKLABELS = [1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,10,11,12,13,14,14,14,15,15,15,14,14,14,15,15,15]\n",
    "    if ytick_on:\n",
    "        ax.set_yticks(ytick_tracker)\n",
    "        ax.set_yticklabels([f\"{i:03}\" for i in YTICKLABELS], fontsize=fontsize)\n",
    "        ax.tick_params(axis=\"y\", length=4.,width=linewidth,pad=0)\n",
    "    else:\n",
    "        ax.set_yticks([])\n",
    "    ax.set_xticks([np.interp(_f, frequency_grid, range(len(frequency_grid))) for _f in [0,.1,.2,.3,.4,.5]])\n",
    "    ax.set_xticklabels([f\"{i:.1f}\" for i in [0,.1,.2,.3,.4,.5]],fontsize=fontsize)\n",
    "    ax.tick_params(axis=\"x\", length=2.,width=linewidth,pad=0)\n",
    "\n",
    "def plot_2_spines_and_ticks(ax, test_frequencies_list,xmax,c_dict,start_yloc=2.5,linewidth=.4,linestyle='dashed',space_btwn_cohort=1,ytick_on=False,fontsize=6):\n",
    "    \n",
    "    for i in (\"top\", \"right\", \"bottom\", \"left\"):\n",
    "        ax.spines[i].set_visible(False)\n",
    "\n",
    "    yloc_top = None\n",
    "    yloc_bottom = None\n",
    "    ytick_tracker = []\n",
    "    yticklabel_tracker = []\n",
    "    for _,_,n_sub_ids in test_frequencies_list:\n",
    "\n",
    "        if yloc_top is None:\n",
    "            yloc_top = start_yloc\n",
    "        yloc_bottom = yloc_top + n_sub_ids\n",
    "        ax.plot([0,xmax],[yloc_bottom,yloc_bottom],c='k',lw=linewidth,linestyle=linestyle) # bottom\n",
    "        ax.plot([0,xmax],[yloc_top,yloc_top],c='k',lw=linewidth,linestyle=linestyle) # top\n",
    "        for _xpos in [0,2,4,xmax]:\n",
    "            ax.plot([_xpos,_xpos],[yloc_bottom,yloc_top],c='k',lw=linewidth,linestyle=linestyle)\n",
    "\n",
    "        ytick_tracker += [i for i in range(int(yloc_top)+1,int(yloc_top)+n_sub_ids+1)]\n",
    "        yticklabel_tracker += [i for i in range(n_sub_ids)]\n",
    "\n",
    "        yloc_top +=(n_sub_ids+space_btwn_cohort)\n",
    "\n",
    "    for _xpos, _ypos, f_type in zip([0,2,4],[2,4,6],[\"f1\",\"f2\",\"f1f2\"]):\n",
    "        ax.plot([_xpos,_ypos],[0.5,0.5],c=c_dict[f_type],lw=linewidth) # bottom\n",
    "        ax.plot([_xpos,_ypos],[1.5,1.5],c=c_dict[f_type],lw=linewidth) # top\n",
    "        ax.fill_between([_xpos,_ypos],[.5,.5],[1.5,1.5],color=c_dict[f_type]) # top\n",
    "    \n",
    "    if ytick_on:\n",
    "        ax.set_yticks(ytick_tracker)\n",
    "        ax.set_yticklabels([f\"{i+1:03}\" for i in yticklabel_tracker], fontsize=fontsize)\n",
    "        ax.tick_params(axis=\"y\", length=4.,width=linewidth,pad=0)\n",
    "    else:\n",
    "        ax.set_yticks([])\n",
    "    ax.set_xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTSIZE = 6\n",
    "DPI = 300\n",
    "fig = plt.figure(\n",
    "    layout=\"constrained\",figsize=(7.2,6.), # max 7.2\n",
    "    dpi=DPI\n",
    ")\n",
    "ax_dict = fig.subplot_mosaic(\n",
    "    [\n",
    "        [\"f1\", \"f2\", \"f1f2\", \"stats\", \"Legend\"],\n",
    "    ],\n",
    "    gridspec_kw={\n",
    "        \"width_ratios\": [1,1,1,.7,.75]\n",
    "    },\n",
    ")\n",
    "roi_c_dict = get_roi_colour_codes()\n",
    "frequency_text_codes = get_frequency_text_codes()\n",
    "\n",
    "roi_pval = \"uncp\"\n",
    "roi_fractional_overlap = .8\n",
    "rephase = False\n",
    "rephase_with = \"None\"\n",
    "dataset_labels = [\"NORMAL_3T_CONTROL\",\"NORMAL_3T\",\"NORMAL_7T\"] + 6*[\"VARY_3T\"] + 6*[\"VARY_7T\"]\n",
    "roi_task_ids = [\"entrain\",\"entrain\",\"AttendAway\"] + 2 * [f\"entrain{i}\" for i in [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]]\n",
    "ax_dataset_labels = [\"N3TC\",\"N3T\",\"N7T\"] + [f\"V3T{i}\" for i in [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]] + [f\"V7T{i}\" for i in [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]]\n",
    "roi_f_types = [\"f1\",\"f2\",\"f1f2\"]\n",
    "statistic_f_types = [\"f1\",\"f2\"] # COLUMN B\n",
    "arrow_down_marker_s = 10\n",
    "pval_marker_s = 8\n",
    "\n",
    "# Threshold x-axis of all PSDs\n",
    "frequency_grid = data_dict['frequency_grid']\n",
    "xmax = (frequency_grid < .5).sum()\n",
    "\n",
    "cohort_psds = defaultdict(list)\n",
    "cohort_test_frequencies = defaultdict(list)\n",
    "cohort_pval_statistics = []\n",
    "cohort_power_statistics = []\n",
    "for ix, (dataset_label, roi_task_id, ax_dataset_label) in enumerate(zip(dataset_labels, roi_task_ids, ax_dataset_labels)):\n",
    "    \n",
    "    n_sub_ids = len(df[(df.experiment_id==dataset_label) & (df.roi_task_id==roi_task_id)].sub_id.unique())\n",
    "    bootstrapped_pvals = np.zeros((n_sub_ids,len(roi_f_types)*len(statistic_f_types)))\n",
    "    bootstrapped_power = np.zeros((n_sub_ids,len(roi_f_types)*len(statistic_f_types)))\n",
    "    bootstrapped_col_ix = 0\n",
    "\n",
    "    for roi_f_type in roi_f_types:\n",
    "        # Subset data frame\n",
    "        subset_df = df[\n",
    "            (df.experiment_id==dataset_label) &\n",
    "            (df.roi_task_id==roi_task_id) &\n",
    "            (df.roi_pval==roi_pval) &\n",
    "            (df.roi_fractional_overlap==roi_fractional_overlap) &\n",
    "            (df.roi_f_type==roi_f_type) &\n",
    "            (df.rephase==rephase) &\n",
    "            (~df.rephase_with.notnull())\n",
    "        ]\n",
    "        f1 = subset_df['f1'].unique()\n",
    "        f2 = subset_df['f2'].unique()\n",
    "        cohort_test_frequencies[roi_f_type].append((f1[0],f2[0],n_sub_ids))\n",
    "        for f in [f1,f2]:\n",
    "            if f.shape[0] != 1:\n",
    "                raise ValueError(f\"1 frequency expected: {f}\")\n",
    "        \n",
    "        \"\"\"Store PSDs\"\"\"\n",
    "        # Stack single-subject PSDs\n",
    "        psds = []\n",
    "        for psd in subset_df.power_spectrum:\n",
    "            psd = ( psd-psd.mean() ) / psd.std() # Z-score\n",
    "            psds.append(psd)\n",
    "        psds = np.vstack(psds)\n",
    "        cohort_psds[roi_f_type].append(psds)\n",
    "        \"\"\"Store statistics for COLUMN B figure\"\"\"\n",
    "        for _f_type in statistic_f_types:\n",
    "            for bootstrapped_row_ix, (_power, _pval) in enumerate(zip(subset_df[f\"bootstrap_power_{_f_type}\"],subset_df[f\"bootstrap_pval_{_f_type}\"])):\n",
    "                bootstrapped_pvals[bootstrapped_row_ix,bootstrapped_col_ix] = _pval\n",
    "                bootstrapped_power[bootstrapped_row_ix,bootstrapped_col_ix] = _power\n",
    "            bootstrapped_col_ix+=1\n",
    "    cohort_pval_statistics.append(bootstrapped_pvals)\n",
    "    cohort_power_statistics.append(bootstrapped_power)\n",
    "\n",
    "\n",
    "arrow_marker_s=20\n",
    "\"\"\"Plot PSDs\"\"\"\n",
    "for f_type,ax in ax_dict.items():\n",
    "    if f_type.startswith(\"f\"):\n",
    "        ytick_on = False\n",
    "        add_cbar=False\n",
    "        if f_type == \"f1\":\n",
    "            f1f2_c = [\"k\",\"white\"]\n",
    "            ytick_on = True\n",
    "        if f_type == \"f2\":\n",
    "            f1f2_c = [\"white\",\"k\"]\n",
    "        if f_type == \"f1f2\":\n",
    "            f1f2_c = [\"k\",\"k\"]\n",
    "            add_cbar=True\n",
    "        plot_1_cohort_psds(ax,cohort_psds[f_type],xmax,add_cbar=add_cbar,fontsize=FONTSIZE)\n",
    "        plot_1_arrows(ax,cohort_test_frequencies[f_type],frequency_grid,f1f2_c,arrow_down_marker_s=arrow_marker_s)\n",
    "        plot_1_spines_and_ticks(ax,cohort_test_frequencies[f_type],xmax,roi_c_dict[f_type],frequency_grid,ytick_on=ytick_on,fontsize=FONTSIZE)\n",
    "ax = ax_dict[\"stats\"]\n",
    "pval, power = plot_2_cohort_statistics(ax,cohort_pval_statistics,cohort_power_statistics,)\n",
    "plot_2_spines_and_ticks(ax,cohort_test_frequencies[\"f1\"],6,roi_c_dict,fontsize=FONTSIZE,)\n",
    "ax.set_xlim(-3.,ax.get_xlim()[-1])\n",
    "ax.scatter(.5, 2.2, s=arrow_marker_s, c='k',edgecolors='k',linewidths=0.25, marker='v')\n",
    "ax.scatter(1.5, 2.2, s=arrow_marker_s, c='white',edgecolors='k',linewidths=0.25, marker='v')\n",
    "ax.scatter(2.5, 2.2, s=arrow_marker_s, c='white',edgecolors='k',linewidths=0.25, marker='v')\n",
    "ax.scatter(3.5, 2.2, s=arrow_marker_s, c='k',edgecolors='k',linewidths=0.25, marker='v')\n",
    "ax.scatter(4.5, 2.2, s=arrow_marker_s, c='k',edgecolors='k',linewidths=0.25, marker='v')\n",
    "ax.scatter(5.5, 2.2, s=arrow_marker_s, c='k',edgecolors='k',linewidths=0.25, marker='v')\n",
    "pval_marker_s = 30\n",
    "for i in range(pval.shape[0]):\n",
    "    for j in range(pval.shape[1]):\n",
    "        _power = power[i,j]\n",
    "        _pval = pval[i,j]\n",
    "        c='white'\n",
    "        if _pval == -1:\n",
    "            continue\n",
    "        if np.isnan(_power):\n",
    "            ax.scatter(j+.5,i,s=25,marker='x',c='k',linewidths=0.25)\n",
    "            continue\n",
    "        if _pval > 1:\n",
    "            raise ValueError()\n",
    "        elif _pval==1.:\n",
    "            s=pval_marker_s\n",
    "            c='k'\n",
    "        elif _pval > .95:\n",
    "            s=pval_marker_s\n",
    "            c='grey'\n",
    "        elif _pval>.8:\n",
    "            s=pval_marker_s*.7\n",
    "        elif _pval>.6:\n",
    "            s=pval_marker_s*.4\n",
    "        else:\n",
    "            s=pval_marker_s*.1\n",
    "        ax.scatter(j+.5,i,s=s,c=c,edgecolors='k',linewidths=0.25)\n",
    "\n",
    "ax = ax_dict[\"Legend\"]\n",
    "plot_2_cohort_statistics(ax,cohort_pval_statistics,cohort_power_statistics)\n",
    "for i in (\"top\", \"right\", \"bottom\", \"left\"):\n",
    "    ax.spines[i].set_visible(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "ax.text(-2.3,3,f\"Frequency of the region\", fontsize=FONTSIZE)\n",
    "ax.scatter(-2,4,s=arrow_marker_s,c=roi_c_dict[\"f1\"],marker='s')\n",
    "ax.scatter(-1.5,4,s=arrow_marker_s,c=roi_c_dict[\"f1\"],marker='s')\n",
    "ax.scatter(-2,5,s=arrow_marker_s,c=roi_c_dict[\"f2\"],marker='s')\n",
    "ax.scatter(-1.5,5,s=arrow_marker_s,c=roi_c_dict[\"f2\"],marker='s')\n",
    "ax.scatter(-2,6,s=arrow_marker_s,c=roi_c_dict[\"f1f2\"],marker='s')\n",
    "ax.scatter(-1.5,6,s=arrow_marker_s,c=roi_c_dict[\"f1f2\"],marker='s')\n",
    "ax.text(-1.0,4.1,f\"$f_1$\",fontsize=FONTSIZE)\n",
    "ax.text(-1.0,5.1,f\"$f_2$\",fontsize=FONTSIZE)\n",
    "ax.text(-1.0,6.1,f\"Multiplex\",fontsize=FONTSIZE)\n",
    "\n",
    "ax.text(-2.3,9,f\"Tested frequency\\nmatches region\",fontsize=FONTSIZE)\n",
    "ax.scatter(-2,10,s=arrow_marker_s,c='k',marker='v',edgecolors='k',linewidths=.25)\n",
    "ax.scatter(-2,11,s=arrow_marker_s,c='white',marker='v',edgecolors='k',linewidths=.25)\n",
    "ax.text(-1.4,10.1,\"Match\",fontsize=FONTSIZE)\n",
    "ax.text(-1.4,11.1,\"No match\",fontsize=FONTSIZE)\n",
    "\n",
    "ax.text(-2.3,14,f\"$P$ value<.05\\n(% bootstraps)\",fontsize=FONTSIZE)\n",
    "ax.scatter(-2,15,s=pval_marker_s*.1,c='white',edgecolors='k',linewidths=.25)\n",
    "ax.scatter(-2,16,s=pval_marker_s*.4,c='white',edgecolors='k',linewidths=.25)\n",
    "ax.scatter(-2,17,s=pval_marker_s*.7,c='white',edgecolors='k',linewidths=.25)\n",
    "ax.scatter(-2,18,s=pval_marker_s,c='grey',edgecolors='k',linewidths=.25)\n",
    "ax.scatter(-2,19,s=pval_marker_s,c='k',edgecolors='k',linewidths=.25)\n",
    "ax.text(-1.4,15.1,\"<0.6\",fontsize=FONTSIZE)\n",
    "ax.text(-1.4,16.1,\"0.6-0.8\",fontsize=FONTSIZE)\n",
    "ax.text(-1.4,17.1,\"0.8-.95\",fontsize=FONTSIZE)\n",
    "ax.text(-1.4,18.1,\"0.95-1.0\",fontsize=FONTSIZE)\n",
    "ax.text(-1.4,19.1,\"1.0\",fontsize=FONTSIZE)\n",
    "\n",
    "ax=ax_dict[\"f1\"]\n",
    "ax.set_ylabel(\"Subjects\",fontsize=FONTSIZE,c='white')\n",
    "line = plt.Line2D([.0195,.0195],[.765,.935],transform=fig.transFigure,color='k',linestyle='-',lw=.4)\n",
    "fig.add_artist(line)\n",
    "line = plt.Line2D([.0195,.0195],[.765-.19,.935-.19],transform=fig.transFigure,color='k',linestyle='-',lw=.4)\n",
    "fig.add_artist(line)\n",
    "line = plt.Line2D([.0195,.0195],[.765-.19-(.19*5/10),.935-(.19*2)],transform=fig.transFigure,color='k',linestyle='-',lw=.4)\n",
    "fig.add_artist(line)\n",
    "line = plt.Line2D([.0195,.0195],[.765-.19-(.19*5/10)-(.19*12/10),.935-(.19*2)-(.19*5/10)],transform=fig.transFigure,color='k',linestyle='-',lw=.4)\n",
    "fig.add_artist(line)\n",
    "line = plt.Line2D([.0195,.0195],[.765-.19-(.19*5/10)-(.19*12/10)-(.19*12/10),.935-(.19*2)-(.19*5/10)-(.19*12/10)],transform=fig.transFigure,color='k',linestyle='-',lw=.4)\n",
    "fig.add_artist(line)\n",
    "\n",
    "fig.text(.0135, .515,\"7T\",fontsize=FONTSIZE+2,color='k',rotation=90,ha='center')\n",
    "fig.text(.0135, .515+(.19*7.5/10),\"3T\",fontsize=FONTSIZE+2,color='k',rotation=90,ha='center')\n",
    "fig.text(.0135, .515+(.19*15.5/10),\"3T Control\",fontsize=FONTSIZE+2,color='k',rotation=90,ha='center')\n",
    "fig.text(.0135, .515-(.19*9.5/10),\"3T Vary\",fontsize=FONTSIZE+2,color='k',rotation=90,ha='center')\n",
    "fig.text(.0135, .515-(.19*21.5/10),\"7T Vary\",fontsize=FONTSIZE+2,color='k',rotation=90,ha='center')\n",
    "\n",
    "fig.savefig(MAIN / \"Fig3_PSD_across_all_experiments.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "def calculate_im_frequency(row, im_expression):\n",
    "    if im == \"f2-f1\":\n",
    "        return row[\"f2\"]-row[\"f1\"]\n",
    "    elif im == \"2f1-f2\":\n",
    "        return 2*row[\"f1\"]-row[\"f2\"]\n",
    "    elif im == \"2f2-f1\":\n",
    "        return 2*row[\"f2\"]-row[\"f1\"]\n",
    "    elif im == \"2f1\":\n",
    "        return 2*row[\"f1\"]\n",
    "    elif im == \"2f2\":\n",
    "        return 2*row[\"f2\"]\n",
    "    elif im == \"f1+f2\":\n",
    "        return row[\"f1\"]+row[\"f2\"]\n",
    "    elif im == \"f1\":\n",
    "        return row[\"f1\"]\n",
    "    elif im == \"f2\":\n",
    "        return row[\"f2\"]\n",
    "    else:\n",
    "        raise ValueError(f\"Not Implemented: {im_expression}\")\n",
    "\n",
    "def find_closest_index(array, value):\n",
    "    \"\"\"Find the index in the array closest to the given value.\"\"\"\n",
    "    idx = np.abs(array - value).argmin()\n",
    "    return idx\n",
    "\n",
    "def calculate_fsnr(row, frequency_grid, foi, foi_range):\n",
    "\n",
    "    psd = row['power_spectrum']\n",
    "    im_idx = find_closest_index(frequency_grid, foi)\n",
    "    im_ub_idx = find_closest_index(frequency_grid,foi+foi_range)\n",
    "    im_lb_idx = find_closest_index(frequency_grid,foi-foi_range)\n",
    "    peak_power = psd[im_idx]\n",
    "    peripheral_power = np.concatenate((psd[im_lb_idx:im_idx], psd[im_idx+1:im_ub_idx+1]))\n",
    "\n",
    "    return peak_power / peripheral_power.mean()\n",
    "\n",
    "def get_im_pvalues(im,pval,roi_fractional_overlap,roi_f_type,rephase,rephase_with,frequency_grid,foi_range,total_control_datasets=9,total_datasets=9+4+6+6):\n",
    "    if rephase:\n",
    "        if roi_f_type in [\"f1\",\"f2\"]:\n",
    "            im_df = df[(df.roi_pval==pval) & (df.roi_fractional_overlap==roi_fractional_overlap) & (df.roi_f_type==roi_f_type) & (df.rephase==rephase)][[\"roi_f_type\",\"experiment_id\",\"sub_id\",\"roi_task_id\",\"f1\",\"f2\",f\"bootstrap_power_{im}\",f\"bootstrap_pval_{im}\",\"rephase_with\",\"power_spectrum\"]]\n",
    "        if roi_f_type == \"f1f2\":\n",
    "            im_df = df[(df.roi_pval==pval) & (df.roi_fractional_overlap==roi_fractional_overlap) & (df.roi_f_type==roi_f_type) & (df.rephase==rephase) & (df.rephase_with==rephase_with)][[\"roi_f_type\",\"experiment_id\",\"sub_id\",\"roi_task_id\",\"f1\",\"f2\",f\"bootstrap_power_{im}\",f\"bootstrap_pval_{im}\",\"rephase_with\",\"power_spectrum\"]]\n",
    "    else:\n",
    "        im_df = df[(df.roi_pval==pval) & (df.roi_fractional_overlap==roi_fractional_overlap) & (df.roi_f_type==roi_f_type) & (df.rephase==rephase)][[\"roi_f_type\",\"experiment_id\",\"sub_id\",\"roi_task_id\",\"f1\",\"f2\",f\"bootstrap_power_{im}\",f\"bootstrap_pval_{im}\",\"rephase_with\",\"power_spectrum\"]]\n",
    "        \n",
    "    im_df[\"im_frequency\"] = im_df.apply(lambda row: calculate_im_frequency(row, im), axis=1)\n",
    "    im_df[\"im_fsnr\"] = im_df.apply(lambda row: calculate_fsnr(row,frequency_grid,calculate_im_frequency(row,im),foi_range),axis=1)\n",
    "\n",
    "    control_im_df = im_df[(im_df.experiment_id.str.endswith(\"CONTROL\"))]\n",
    "    im_df = im_df[~(im_df.experiment_id.str.endswith(\"CONTROL\"))]\n",
    "    assert control_im_df.shape[0] == total_control_datasets\n",
    "    assert im_df.shape[0] <= total_datasets\n",
    "\n",
    "\n",
    "    #return control_im_df[f\"bootstrap_pval_{im}\"].values, im_df[f\"bootstrap_pval_{im}\"].values, control_im_df, im_df\n",
    "    return control_im_df[f\"im_fsnr\"].values, im_df[f\"im_fsnr\"].values, control_im_df, im_df\n",
    "\n",
    "\n",
    "\n",
    "pval = \"uncp\"\n",
    "roi_fractional_overlap = .8\n",
    "rephase = False\n",
    "rephase_with = None\n",
    "foi_range = .025\n",
    "\n",
    "if rephase:\n",
    "    if rephase_with not in [\"f1\",\"f2\"]:\n",
    "        raise ValueError(f\"{rephase_with} must be set to f1 or f2.\")\n",
    "\n",
    "roi_f_types = [\"f1\",\"f2\",\"f1f2\"]\n",
    "im_codes = [\"f1\",\"f2\",\"f2-f1\",\"f1+f2\",\"2f1\",\"2f2\",\"2f1-f2\",\"2f2-f1\"]\n",
    "\n",
    "fig, ax_dict = plt.subplot_mosaic(\n",
    "    mosaic=[roi_f_types,[f\"{i}C\" for i in roi_f_types]],\n",
    "    dpi=300,\n",
    "    figsize=(4,2),\n",
    "    layout=\"constrained\"\n",
    ")\n",
    "im_coords = {\n",
    "    \"f1\": 1,\n",
    "    \"f2\": 2,\n",
    "    \"f2-f1\": 4,\n",
    "    \"f1+f2\": 5,\n",
    "    \"2f1\": 6,\n",
    "    \"2f2\": 7,\n",
    "    \"2f1-f2\": 9,\n",
    "    \"2f2-f1\": 10,\n",
    "}\n",
    "\n",
    "store_im_data_across_rois = {}\n",
    "for roi_f_type in roi_f_types:\n",
    "    ax = ax_dict[roi_f_type]\n",
    "    for ax_key in [roi_f_type,f\"{roi_f_type}C\"]:\n",
    "        ax=ax_dict[ax_key]\n",
    "        ax.set_xticks([i for i in im_coords.values()])\n",
    "        ax.set_xticklabels([i for i in im_coords.keys()],fontsize=FONTSIZE,rotation=90)\n",
    "        ax.set_xlim(0,11)\n",
    "        if ax_key.endswith(\"C\"):\n",
    "            ax.set_yticks([-15,15])\n",
    "            ax.set_yticklabels([-15,15],fontsize=FONTSIZE)\n",
    "            ax.set_ylim(-15,15)\n",
    "            for _spine in [\"top\",\"bottom\",\"right\"]:\n",
    "                ax.spines[_spine].set_visible(False)\n",
    "        else:\n",
    "            ax.set_yticks([0,15])\n",
    "            ax.set_yticklabels([0,15],fontsize=FONTSIZE)\n",
    "            ax.set_ylim(-2,17)\n",
    "            for _spine in [\"top\",\"bottom\",\"right\"]:\n",
    "                ax.spines[_spine].set_visible(False)\n",
    "    for im in im_codes:\n",
    "        control_pvals,test_pvals,_,_ = get_im_pvalues(\n",
    "            im, pval, roi_fractional_overlap, roi_f_type, rephase, rephase_with,\n",
    "            data_dict['frequency_grid'],foi_range\n",
    "        )\n",
    "        \n",
    "        x_pos = np.zeros_like(test_pvals) + im_coords[im]\n",
    "        ax_dict[roi_f_type].scatter(x_pos, test_pvals, c=roi_c_dict[im],s=pval_marker_s,zorder=8)\n",
    "        x_pos = np.zeros_like(control_pvals) + im_coords[im]\n",
    "        ax_dict[roi_f_type].scatter(x_pos-.25, control_pvals, c='lightgrey',s=pval_marker_s/2,ec='k',lw=.25,zorder=10)\n",
    "        x_pos = np.zeros_like(control_pvals) + im_coords[im]\n",
    "        ax_dict[roi_f_type].scatter(x_pos+.25, test_pvals[:9], c='darkgrey',s=pval_marker_s/2,ec='k',lw=.25,zorder=10)\n",
    "\n",
    "        x_pos = np.zeros_like(control_pvals) + im_coords[im]\n",
    "        pval_test_vs_control = wilcoxon(test_pvals[:9],control_pvals,alternative=\"greater\")\n",
    "        c='grey'\n",
    "        if pval_test_vs_control.pvalue < .05:\n",
    "            c='red'\n",
    "        ax_dict[f\"{roi_f_type}C\"].scatter(x_pos, test_pvals[:9]-control_pvals, c=c,s=pval_marker_s)\n",
    "        store_im_data_across_rois[(roi_f_type,im)] = [\n",
    "            control_pvals,\n",
    "            test_pvals[:9],\n",
    "            pval_test_vs_control,\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "pvalues = [i[2].pvalue for i in store_im_data_across_rois.values()]\n",
    "_, p_values, _, _ = multipletests(pvalues,method=\"fdr_bh\")\n",
    "\n",
    "for pval, (k,v) in zip(p_values, store_im_data_across_rois.items()):\n",
    "    store_im_data_across_rois[k].append(pval)\n",
    "    print(k,store_im_data_across_rois[k][2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_f1_f2_equation(f1,f2):\n",
    "    if int(f1)==f1:\n",
    "        f1=int(f1)\n",
    "    if int(f2)==f2:\n",
    "        f2=int(f2)\n",
    "    if f1==f2:\n",
    "        if f1 == 1 or f1 == -1: f1 = \"\"\n",
    "        if f2 == 1 or f2 == -1: f2 = \"\"\n",
    "        return f\"{f1}$f_1$+{f2}$f_2$\"\n",
    "    elif f1<0 and f2>0:\n",
    "        if f1 == 1 or f1 == -1: f1 = \"\"\n",
    "        if f2 == 1 or f2 == -1: f2 = \"\"\n",
    "        try:\n",
    "            return f\"{f2}$f_2$-{-f1}$f_1$\"\n",
    "        except:\n",
    "            return f\"{f2}$f_2$-{f1}$f_1$\"\n",
    "    elif f2<0 and f1>0:\n",
    "        if f1 == 1 or f1 == -1: f1 = \"\"\n",
    "        if f2 == 1 or f2 == -1: f2 = \"\"\n",
    "        try:\n",
    "            return f\"{f1}$f_2$-{-f2}$f_1$\"\n",
    "        except:\n",
    "            return f\"{f1}$f_2$-{f2}$f_1$\"\n",
    "    elif f1>=0 and f2 >= 0:\n",
    "        if f1 == 1 or f1 == -1: f1 = \"\"\n",
    "        if f2 == 1 or f2 == -1: f2 = \"\"\n",
    "        if f1==0:\n",
    "            return f\"{f2}$f_2$\"\n",
    "        elif f2==0:\n",
    "            return f\"{f1}$f_1$\"\n",
    "        else:\n",
    "            return f\"{f1}$f_1$+{f2}$f_2$\"\n",
    "    else:\n",
    "        print(f1,f2)\n",
    "        raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pval = 'uncp'\n",
    "roi_fractional_overlap = .8\n",
    "rephase = False\n",
    "rephase_with = None\n",
    "\n",
    "LINEWIDTH=.5\n",
    "\n",
    "def get_pct_of_datasets_with_gt_max_fsnr(im_df, max_fsnr):\n",
    "    experiment_id_total_count = im_df.experiment_id.value_counts().to_dict()\n",
    "    n_gt_max_fsnr_all_datasets = 0\n",
    "    pct_of_datasets = {}\n",
    "    for experiment_id, n_experiments in experiment_id_total_count.items():\n",
    "        n_gt_max_fsnr = im_df[(im_df.im_fsnr>max_fsnr) & (im_df.experiment_id==experiment_id)].shape[0]\n",
    "        n_gt_max_fsnr_all_datasets += n_gt_max_fsnr\n",
    "        pct_of_datasets[experiment_id] = f\"{n_gt_max_fsnr}/{n_experiments}\"\n",
    "\n",
    "    total_datasets = np.sum([i for i in experiment_id_total_count.values()])\n",
    "    pct_of_datasets[\"ALL\"] = f\"{n_gt_max_fsnr_all_datasets}/{total_datasets}\"\n",
    "    \n",
    "    return pct_of_datasets\n",
    "\n",
    "mosaic = [[f\"im-{im}_roi-{i}\" for i in roi_f_types] for im in im_codes]\n",
    "fig, ax_dict = plt.subplot_mosaic(\n",
    "    mosaic,dpi=300,figsize=(6,7),layout=\"constrained\"\n",
    ")\n",
    "\n",
    "im_above_df = {}\n",
    "pct_of_datasets_across_all_frequencies = {}\n",
    "for im in im_codes:\n",
    "    im_c = roi_c_dict[im]\n",
    "    for roi_f_type in roi_f_types:\n",
    "        control_pvals, test_pvals, control_im_df, im_df = get_im_pvalues(im, pval, roi_fractional_overlap, roi_f_type, rephase, rephase_with, data_dict['frequency_grid'], foi_range)\n",
    "        ax = ax_dict[f\"im-{im}_roi-{roi_f_type}\"]\n",
    "        max_fsnr = control_im_df.im_fsnr.values.max()\n",
    "        pct_of_datasets = get_pct_of_datasets_with_gt_max_fsnr(im_df, max_fsnr)\n",
    "        ax.axvline(max_fsnr,c='k',lw=LINEWIDTH*4,zorder=5,linestyle='dotted')\n",
    "        im_above_df[f\"roi-{roi_f_type}_im-{im}\"] = im_df[(im_df.im_fsnr>max_fsnr)]\n",
    "        data = im_df.im_fsnr.values\n",
    "        below_threshold = data[data<max_fsnr]\n",
    "        above_threshold = data[data>=max_fsnr]\n",
    "        n_bins = 50\n",
    "        _xticks = [0,5,10]\n",
    "        if im in [\"f1\",\"f2\"]:\n",
    "            _xticks = [0,7,14]\n",
    "        _,_,patches = ax.hist(below_threshold,alpha=1.,bins=n_bins,zorder=2,color='grey',width=_xticks[-1]*.01)\n",
    "        _,_,patches = ax.hist(above_threshold,alpha=1.,bins=n_bins,zorder=2,color=im_c,width=_xticks[-1]*.01)\n",
    "        for _spine in [\"top\",\"right\"]:\n",
    "            ax.spines[_spine].set_visible(False)\n",
    "        for _spine in [\"left\",\"bottom\"]:\n",
    "            ax.spines[_spine].set_linewidth(LINEWIDTH)\n",
    "        ax.tick_params(axis=\"both\", length=2.,width=LINEWIDTH,pad=0)\n",
    "        if im==\"f1\":\n",
    "            if roi_f_type == \"f1\":\n",
    "                ax.set_title(f\"Region, {format_f1_f2_equation(1,0)}\", fontsize=FONTSIZE)\n",
    "            if roi_f_type == \"f2\":\n",
    "                ax.set_title(f\"Region, {format_f1_f2_equation(0,1)}\", fontsize=FONTSIZE)\n",
    "            if roi_f_type == \"f1f2\":\n",
    "                ax.set_title(f\"Region, Multiplex\", fontsize=FONTSIZE)\n",
    "        if im==\"2f2-f1\":\n",
    "            ax.set_xlabel(\"SNR\", fontsize=FONTSIZE)\n",
    "        if roi_f_type==\"f1\":\n",
    "            if im == \"f1\":\n",
    "                ax.set_ylabel(format_f1_f2_equation(1,0),fontsize=FONTSIZE,rotation=0)\n",
    "            if im == \"f2\":\n",
    "                ax.set_ylabel(format_f1_f2_equation(0,1),fontsize=FONTSIZE,rotation=0)\n",
    "            if im == \"f2-f1\":\n",
    "                ax.set_ylabel(format_f1_f2_equation(-1,1),fontsize=FONTSIZE,rotation=0)\n",
    "            if im == \"f1+f2\":\n",
    "                ax.set_ylabel(format_f1_f2_equation(1,1),fontsize=FONTSIZE,rotation=0)\n",
    "            if im == \"2f2-f1\":\n",
    "                ax.set_ylabel(format_f1_f2_equation(-1,2),fontsize=FONTSIZE,rotation=0)\n",
    "            if im == \"2f1-f2\":\n",
    "                ax.set_ylabel(format_f1_f2_equation(2,-1),fontsize=FONTSIZE,rotation=0)\n",
    "            if im == \"2f1\":\n",
    "                ax.set_ylabel(format_f1_f2_equation(2,0),fontsize=FONTSIZE,rotation=0)\n",
    "            if im == \"2f2\":\n",
    "                ax.set_ylabel(format_f1_f2_equation(0,2),fontsize=FONTSIZE,rotation=0)\n",
    "        ax.set_xlim(0,_xticks[-1])\n",
    "        ax.set_xticks(_xticks)\n",
    "        ax.set_xticklabels(_xticks,fontsize=FONTSIZE)\n",
    "        ax.set_ylim(0,3)\n",
    "        ax.set_yticks([0,3])\n",
    "        ax.set_yticklabels([0,3],fontsize=FONTSIZE)\n",
    "        texts = '\\n'.join([f\"{dataset_id}$=${pct_of_datasets[_key]}\" for _key, dataset_id in zip([\"NORMAL_3T\",\"NORMAL_7T\",\"VARY_3T\",\"VARY_7T\",\"ALL\"],[\"3T\",\"7T\",\"3T Vary\",\"7T Vary\",\"All\"])])\n",
    "        ax.text(ax.get_xlim()[-1]*1.02, ax.get_ylim()[-1]*.25, texts,fontsize=FONTSIZE-2,zorder=20,c='k')\n",
    "        # Store\n",
    "        pct_of_datasets_across_all_frequencies[(im,roi_f_type)] = pct_of_datasets\n",
    "\n",
    "fig.savefig(MAIN / \"Extended_Figure_X_fsnr_threshold.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in ['f2-f1','2f1',\"2f2\"]:\n",
    "    pval = \"uncp\"\n",
    "    roi_fractional_overlap = .8\n",
    "    rephase = False\n",
    "    rephase_with = None\n",
    "\n",
    "    control_pvals, test_pvals, control_im_df,im_df = get_im_pvalues(\n",
    "        im, pval, roi_fractional_overlap, roi_f_type, rephase, rephase_with, data_dict['frequency_grid'], foi_range\n",
    "    )\n",
    "\n",
    "    im_df = im_df[(im_df.experiment_id.str.startswith(\"VARY\"))]\n",
    "    im_df = im_df.dropna(subset=f\"bootstrap_power_{im}\")\n",
    "\n",
    "    fig,ax_dict = plt.subplot_mosaic([[\"power\",'snr',\"pval\"]],dpi=300,figsize=(4,1),layout=\"constrained\")\n",
    "    for k in [\"power\",\"pval\"]:\n",
    "        ax_dict[k].scatter(im_df.im_frequency,im_df[f\"bootstrap_{k}_{im}\"],s=5)\n",
    "        ax_dict[k].set_ylabel(k,fontsize=FONTSIZE)\n",
    "    ax_dict[\"snr\"].scatter(im_df.im_frequency,im_df.im_fsnr,s=5)\n",
    "    ax_dict[\"snr\"].set_ylabel(\"snr\",fontsize=FONTSIZE)\n",
    "    ax_dict[\"snr\"].set_xlabel(f\"frequency of {im}\",fontsize=FONTSIZE)\n",
    "    ax_dict[\"snr\"].set_title(im,fontsize=FONTSIZE)\n",
    "\n",
    "    for _k, ax in ax_dict.items():\n",
    "        ax.tick_params(axis=\"both\", length=2.,width=.4,pad=0,labelsize=FONTSIZE)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "cmap = plt.cm.get_cmap(\"YlGn\")\n",
    "n_colors = 4\n",
    "color_indices = np.linspace(0, 1, n_colors)\n",
    "colors = [cmap(index) for index in color_indices]\n",
    "custom_cmap = LinearSegmentedColormap.from_list('custom_YlGn', colors, N=n_colors)\n",
    "custom_cmap = [custom_cmap(i) for i in range(4)]\n",
    "custom_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "LINEWIDTH = .5\n",
    "FONTSIZE = 8\n",
    "x_axis = []\n",
    "\n",
    "for im in im_codes:\n",
    "    for roi_f_type in roi_f_types:\n",
    "        im_f_type_code = frequency_text_codes[im]\n",
    "        roi_f_type_code = frequency_text_codes[roi_f_type]\n",
    "        x_axis.append(f\"{im_f_type_code} [{roi_f_type_code}]\")\n",
    "\n",
    "weight_counts = {}\n",
    "for experiment_id in [\"NORMAL_3T\",\"NORMAL_7T\",\"VARY_3T\",\"VARY_7T\"]:\n",
    "    #weight_counts[experiment_id] = np.array([int(pct_of_datasets_across_all_frequencies[(im,roi_f_type)][experiment_id].split(\"/\")[0]) for roi_f_type in roi_f_types for im in im_codes])\n",
    "    weight_counts[experiment_id] = np.array([int(pct_of_datasets_across_all_frequencies[(im,roi_f_type)][experiment_id].split(\"/\")[0]) for im in im_codes for roi_f_type in roi_f_types])\n",
    "bottom = np.zeros_like(weight_counts[\"NORMAL_3T\"])\n",
    "width = 1\n",
    "\n",
    "xtick_pos = []\n",
    "_xtick_pos = 0\n",
    "for i in range(bottom.shape[0]):\n",
    "    _xtick_pos +=1\n",
    "    if i%3 == 0:\n",
    "        _xtick_pos+=.5\n",
    "    xtick_pos.append(_xtick_pos)\n",
    "\n",
    "\n",
    "mosaic = [\n",
    "    5*[\"1\"]+[\"legend\"],\n",
    "    5*[\"2\"]+[\"legend\"],\n",
    "    [\"3\",\"3a\",\"3b\",\"3c\",\"3d\",\"legend\"],\n",
    "]\n",
    "fig, ax_dict = plt.subplot_mosaic(\n",
    "    mosaic=mosaic,figsize=(7,3.6),dpi=300,layout=\"tight\",\n",
    "    gridspec_kw={\n",
    "        \"width_ratios\":[1,1,1,1,1,1],\n",
    "        \"height_ratios\":[1,1,1.2],\n",
    "    }\n",
    ")\n",
    "\n",
    "for ax_key, ax in ax_dict.items():\n",
    "    if ax_key == \"legend\" or ax_key.startswith(\"3\") or ax_key.startswith(\"4\") or ax_key == \"empty\":\n",
    "        continue\n",
    "    ax.set_xlim(xtick_pos[0]-width,xtick_pos[-1]+width)\n",
    "    LINEWIDTH = .4\n",
    "    for _spine in [\"top\",\"right\",\"bottom\"]:\n",
    "        ax.spines[_spine].set_visible(False)\n",
    "        ax.spines.left.set_linewidth(LINEWIDTH)\n",
    "        ax.spines.left.set_position(('outward',-1))\n",
    "    ax.tick_params(axis=\"x\", length=2.,width=LINEWIDTH,pad=.4)\n",
    "    ax.tick_params(axis=\"y\", length=4.,width=LINEWIDTH,pad=.4)\n",
    "\n",
    "\n",
    "ax = ax_dict[\"2\"]\n",
    "all_bars = []\n",
    "for (experiment_id, weight_count),bar_c in zip(weight_counts.items(),custom_cmap):\n",
    "    p = ax.bar(x_axis,weight_count,width,label=experiment_id,bottom=bottom,color=bar_c)\n",
    "    all_bars.append(p)\n",
    "    bottom+=weight_count\n",
    "\n",
    "for bars_per_experiment in all_bars:\n",
    "    for ix, (bar_per_im_and_roi_f_type, _xtick_pos) in enumerate(zip(bars_per_experiment,xtick_pos)):\n",
    "        bar_per_im_and_roi_f_type.set_edgecolor('k')\n",
    "        bar_per_im_and_roi_f_type.set_x(_xtick_pos-(width/2))\n",
    "        bar_per_im_and_roi_f_type.set_linewidth(LINEWIDTH)\n",
    "        if ix % 3 == 0:\n",
    "            x_label_c = roi_c_dict[\"f1\"]\n",
    "        if ix % 3 == 1:\n",
    "            x_label_c = roi_c_dict[\"f2\"]\n",
    "        if ix % 3 == 2:\n",
    "            x_label_c = roi_c_dict[\"f1f2\"]\n",
    "        ax.fill_between(\n",
    "            [_xtick_pos-(width/2),_xtick_pos+(width/2)],\n",
    "            [-3]*2, [-.5]*2,\n",
    "            color=x_label_c,linewidth=LINEWIDTH,edgecolor='k',zorder=1\n",
    "        )\n",
    "ax.set_ylabel(\"Peak count\\n(n=25)\", fontsize=FONTSIZE)\n",
    "ax.set_xlabel(\"Search frequency\", fontsize=FONTSIZE)\n",
    "ax.set_xticks([j for i,j in enumerate(xtick_pos) if i%3==1])\n",
    "ax.set_xticklabels([j.split(\"[\")[0] for i,j in enumerate(x_axis) if i%3==1],rotation=0, fontsize=FONTSIZE)\n",
    "ax.set_yticks([0,25])\n",
    "ax.set_yticklabels([0,25], fontsize=FONTSIZE)\n",
    "ax.set_ylim(-3,25.5)\n",
    "ax.spines.left.set_bounds(0,25)\n",
    "\n",
    "ordered_x_key=[]\n",
    "for im in im_codes:\n",
    "    for roi_f_type in roi_f_types:\n",
    "        ordered_x_key.append((roi_f_type,im))\n",
    "\n",
    "ax = ax_dict[\"1\"]\n",
    "for _xtick_pos, x_key in zip(xtick_pos,ordered_x_key):\n",
    "    offset = .2\n",
    "    control_x_pos = _xtick_pos - offset\n",
    "    test_x_pos = _xtick_pos + offset\n",
    "    stored_im_data = store_im_data_across_rois[x_key]\n",
    "    control_data = stored_im_data[0]\n",
    "    test_data = stored_im_data[1]\n",
    "    # Scatter\n",
    "    ax.scatter([control_x_pos]*control_data.shape[0],control_data,s=8,c='lightgrey',edgecolors='k',linewidths=0.25,zorder=10)\n",
    "    ax.scatter([test_x_pos]*test_data.shape[0],test_data,s=8,c='k',edgecolors='k',linewidths=0.25,zorder=10)\n",
    "    # P-value\n",
    "    _max = max(control_data.max(),test_data.max())+1\n",
    "    pvalue = stored_im_data[3]\n",
    "    if pvalue < .05:\n",
    "        ax.plot([control_x_pos,test_x_pos],[_max,_max],color='k',linewidth=.25,linestyle='-',zorder=20)\n",
    "        ax.text((control_x_pos+test_x_pos)/2,_max+.5,f\"$*$\",fontsize=FONTSIZE,horizontalalignment='center',verticalalignment='center')\n",
    "    # Line\n",
    "    for _control, _test in zip(control_data,test_data):\n",
    "        ax.plot([control_x_pos,test_x_pos],[_control,_test],color='k',linewidth=.25,linestyle=':',zorder=2)\n",
    "for bars_per_experiment in all_bars:\n",
    "    for ix, (bar_per_im_and_roi_f_type, _xtick_pos) in enumerate(zip(bars_per_experiment,xtick_pos)):\n",
    "        bar_per_im_and_roi_f_type.set_edgecolor('k')\n",
    "        bar_per_im_and_roi_f_type.set_x(_xtick_pos-(width/2))\n",
    "        bar_per_im_and_roi_f_type.set_linewidth(LINEWIDTH)\n",
    "        if ix % 3 == 0:\n",
    "            x_label_c = roi_c_dict[\"f1\"]\n",
    "        if ix % 3 == 1:\n",
    "            x_label_c = roi_c_dict[\"f2\"]\n",
    "        if ix % 3 == 2:\n",
    "            x_label_c = roi_c_dict[\"f1f2\"]\n",
    "        ax.fill_between(\n",
    "            [_xtick_pos-(width/2),_xtick_pos+(width/2)],\n",
    "            [-3]*2, [-.5]*2,\n",
    "            color=x_label_c,linewidth=LINEWIDTH,edgecolor='k',zorder=1\n",
    "        )\n",
    "ax.set_ylabel(\"\\nSNR\", fontsize=FONTSIZE)\n",
    "#ax.set_xlabel(\"Search frequency\", fontsize=FONTSIZE)\n",
    "ax.set_xticks([j for i,j in enumerate(xtick_pos) if i%3==1])\n",
    "ax.set_xticklabels([j.split(\"[\")[0] for i,j in enumerate(x_axis) if i%3==1],rotation=0, fontsize=FONTSIZE)\n",
    "max_y = int(ax.get_ylim()[-1])+1\n",
    "ax.set_ylim(-3,max_y+1)\n",
    "ax.spines.left.set_bounds(0,max_y)\n",
    "ax.set_yticks([0,max_y])\n",
    "ax.set_yticklabels([0,max_y],fontsize=FONTSIZE)\n",
    "\n",
    "for _k in [\"legend\"]:\n",
    "    ax = ax_dict[_k]\n",
    "    for i in (\"top\", \"right\", \"bottom\", \"left\"):\n",
    "        ax.spines[i].set_visible(False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    ax.set_ylim(0,1)\n",
    "    ax.set_xlim(0,1)\n",
    "\n",
    "\"\"\"ROW 3\"\"\"\n",
    "def calculate_fsnr(row,frequency_grid,f1_scalar,f2_scalar,foi_range):\n",
    "    foi = f1_scalar*row[\"f1\"] + f2_scalar*row[\"f2\"]\n",
    "    psd = row['power_spectrum']\n",
    "    im_idx = find_closest_index(frequency_grid, foi)\n",
    "    im_ub_idx = find_closest_index(frequency_grid,foi+foi_range)\n",
    "    im_lb_idx = find_closest_index(frequency_grid,foi-foi_range)\n",
    "    peak_power = psd[im_idx]\n",
    "    peripheral_power = np.concatenate((psd[im_lb_idx:im_idx], psd[im_idx+1:im_ub_idx+1]))\n",
    "\n",
    "    return peak_power / peripheral_power.mean()\n",
    "\n",
    "def get_im_pvalues(f1_scalar,f2_scalar,pval,roi_fractional_overlap,roi_f_type,rephase,rephase_with,frequency_grid,foi_range,total_control_datasets=9,total_datasets=9+4+6+6):\n",
    "    if rephase:\n",
    "        if roi_f_type in [\"f1\",\"f2\"]:\n",
    "            im_df = df[(df.roi_pval==pval) & (df.roi_fractional_overlap==roi_fractional_overlap) & (df.roi_f_type==roi_f_type) & (df.rephase==rephase)][[\"roi_f_type\",\"experiment_id\",\"sub_id\",\"roi_task_id\",\"f1\",\"f2\",\"rephase_with\",\"power_spectrum\"]]\n",
    "        if roi_f_type == \"f1f2\":\n",
    "            im_df = df[(df.roi_pval==pval) & (df.roi_fractional_overlap==roi_fractional_overlap) & (df.roi_f_type==roi_f_type) & (df.rephase==rephase) & (df.rephase_with==rephase_with)][[\"roi_f_type\",\"experiment_id\",\"sub_id\",\"roi_task_id\",\"f1\",\"f2\",\"rephase_with\",\"power_spectrum\"]]\n",
    "    else:\n",
    "        im_df = df[(df.roi_pval==pval) & (df.roi_fractional_overlap==roi_fractional_overlap) & (df.roi_f_type==roi_f_type) & (df.rephase==rephase)][[\"roi_f_type\",\"experiment_id\",\"sub_id\",\"roi_task_id\",\"f1\",\"f2\",\"rephase_with\",\"power_spectrum\"]]\n",
    "        \n",
    "    im_df[\"im_fsnr\"] = im_df.apply(lambda row: calculate_fsnr(row,frequency_grid,f1_scalar,f2_scalar,foi_range),axis=1)\n",
    "\n",
    "    control_im_df = im_df[(im_df.experiment_id.str.endswith(\"CONTROL\"))]\n",
    "    im_df = im_df[~(im_df.experiment_id.str.endswith(\"CONTROL\"))]\n",
    "    assert control_im_df.shape[0] == total_control_datasets\n",
    "    assert im_df.shape[0] <= total_datasets\n",
    "\n",
    "\n",
    "    #return control_im_df[f\"bootstrap_pval_{im}\"].values, im_df[f\"bootstrap_pval_{im}\"].values, control_im_df, im_df\n",
    "    return control_im_df[f\"im_fsnr\"].values, im_df[f\"im_fsnr\"].values, control_im_df, im_df\n",
    "\n",
    "def calculate_fraction_of_datasets(f1_scalar,f2_scalar,pval,roi_fractional_overlap,roi_f_type,rephase,rephase_with,foi_range):\n",
    "    control_pvals, test_pvals, control_im_df, im_df = get_im_pvalues(f1_scalar,f2_scalar, pval, roi_fractional_overlap, roi_f_type, rephase, rephase_with, data_dict['frequency_grid'], foi_range)\n",
    "    #im_df = im_df[(im_df.experiment_id.str.contains(\"NORMAL\"))]\n",
    "    max_fsnr = control_im_df.im_fsnr.values.max()\n",
    "    pct_of_datasets = get_pct_of_datasets_with_gt_max_fsnr(im_df, max_fsnr)\n",
    "    x,y = pct_of_datasets[\"ALL\"].split('/')\n",
    "    fraction_of_datasets = float(x)/float(y)\n",
    "    return fraction_of_datasets\n",
    "\n",
    "def calculate_im(f1,f2,f1_scalar,f2_scalar):\n",
    "    return round(f1*f1_scalar+f2*f2_scalar,10)\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "# Define the RGBA values for your 8 colors\n",
    "colors_rgba = [\n",
    "    (1,1,1,1),\n",
    "    (0,0,0,1),\n",
    "    tuple([i for i in roi_c_dict['f1'][0]]),\n",
    "    tuple([i for i in roi_c_dict['f2'][0]]),\n",
    "    tuple([i for i in roi_c_dict['f2-f1'][0]]),\n",
    "    tuple([i for i in roi_c_dict['2f1'][0]]),\n",
    "    tuple([i for i in roi_c_dict['2f2'][0]]),\n",
    "    tuple([i for i in roi_c_dict['f1+f2'][0]]),\n",
    "    tuple([i for i in roi_c_dict['2f1-f2'][0]]),\n",
    "    tuple([i for i in roi_c_dict['2f2-f1'][0]]),\n",
    "]\n",
    "\n",
    "# Create a colormap with the given RGBA values\n",
    "custom_cmap_3 = LinearSegmentedColormap.from_list(\"custom_cmap\", colors_rgba, N=len(colors_rgba))\n",
    "# setup\n",
    "all_test_frequencies = [\n",
    "    [.125,.2], # entrain/atendaway\n",
    "    [.125,.175], # entrainB\n",
    "    [.125,.15], # entrainC\n",
    "    [.15,.2], # entrainE\n",
    "    [.175,.2], # entrainF\n",
    "]\n",
    "scalars = np.arange(-2,2+.5,.5)\n",
    "n_scalars = scalars.shape[0]\n",
    "X_scaling = np.zeros((n_scalars,n_scalars,2))\n",
    "f1_fractions = np.zeros((n_scalars,n_scalars))\n",
    "f2_fractions = np.zeros((n_scalars,n_scalars))\n",
    "f1f2_fractions = np.zeros((n_scalars,n_scalars))\n",
    "xticks = []\n",
    "yticks = []\n",
    "xticklabels = []\n",
    "yticklabels = []\n",
    "for f1_ix,f1_scalar in enumerate(scalars[::-1]):\n",
    "    #f1_ix = len(scalars) - f1_ix - 1\n",
    "    for f2_ix,f2_scalar in enumerate(scalars):\n",
    "        f1_scalar = round(f1_scalar,2)\n",
    "        f2_scalar = round(f2_scalar,2)\n",
    "        if int(round(f1_scalar))==f1_scalar:\n",
    "            xticks.append(f1_ix)\n",
    "            xticklabels.append(int(f1_scalar))\n",
    "        if int(round(f2_scalar))==f2_scalar:\n",
    "            yticks.append(f2_ix)\n",
    "            yticklabels.append(int(f2_scalar))\n",
    "        #print(f1_ix, f2_ix, f1_scalar,f2_scalar)\n",
    "        f1_fractions[f1_ix,f2_ix] = calculate_fraction_of_datasets(f1_scalar,f2_scalar,pval,roi_fractional_overlap,\"f1\",rephase,rephase_with,foi_range)\n",
    "        f2_fractions[f1_ix,f2_ix] = calculate_fraction_of_datasets(f1_scalar,f2_scalar,pval,roi_fractional_overlap,\"f2\",rephase,rephase_with,foi_range)\n",
    "        f1f2_fractions[f1_ix,f2_ix] = calculate_fraction_of_datasets(f1_scalar,f2_scalar,pval,roi_fractional_overlap,\"f1f2\",rephase,rephase_with,foi_range)\n",
    "\n",
    "        X_scaling[f1_ix,f2_ix,0] = f1_scalar\n",
    "        X_scaling[f1_ix,f2_ix,1] = f2_scalar\n",
    "# Get mask\n",
    "X = np.zeros((n_scalars,n_scalars))\n",
    "im_frequencies_across_all_test_frequencies = {}\n",
    "for test_frequencies in all_test_frequencies:\n",
    "    _key = tuple([i for i in test_frequencies])\n",
    "    im_frequencies_across_all_test_frequencies[_key] = np.zeros((n_scalars,n_scalars))\n",
    "    for f1_ix,f1_scalar in enumerate(scalars):\n",
    "        for f2_ix,f2_scalar in enumerate(scalars):\n",
    "            f1_scalar = round(f1_scalar,2)\n",
    "            f2_scalar = round(f2_scalar,2)\n",
    "            im_frequency = f1_scalar*test_frequencies[0]+f2_scalar*test_frequencies[1]\n",
    "            if im_frequency <= 0:\n",
    "                X[9-f1_ix-1,f2_ix] += 1\n",
    "            else:\n",
    "                im_frequencies_across_all_test_frequencies[_key][f1_ix,f2_ix] = im_frequency\n",
    "\n",
    "X[X>0] = -1\n",
    "X+=1\n",
    "def get_idx_from_grid(scalars,val):\n",
    "    return np.where(scalars==val)[0][0]\n",
    "bw_scalars = scalars[::-1]\n",
    "X[get_idx_from_grid(bw_scalars,1),get_idx_from_grid(scalars,0)] = 2 # f1\n",
    "X[get_idx_from_grid(bw_scalars,0),get_idx_from_grid(scalars,1)] = 3 # f2\n",
    "X[get_idx_from_grid(bw_scalars,-1),get_idx_from_grid(scalars,1)] = 4 # f2-f1\n",
    "X[get_idx_from_grid(bw_scalars,2),get_idx_from_grid(scalars,0)] = 5 # 2f1\n",
    "X[get_idx_from_grid(bw_scalars,0),get_idx_from_grid(scalars,2)] = 6 # 2f2\n",
    "X[get_idx_from_grid(bw_scalars,1),get_idx_from_grid(scalars,1)] = 7 # f1+f2\n",
    "X[get_idx_from_grid(bw_scalars,2),get_idx_from_grid(scalars,-1)] = 8 # 2f1-f2\n",
    "X[get_idx_from_grid(bw_scalars,-1),get_idx_from_grid(scalars,2)] = 9 # 2f2-f1\n",
    "\n",
    "P = im_frequencies_across_all_test_frequencies[(.125,.2)][::-1,:]\n",
    "for ax_key, _X,_cmap,_title in zip(\n",
    "    [\"3\",\"3a\",\"3b\",\"3c\",\"3d\"],\n",
    "    [P,X,f1_fractions,f2_fractions,f1f2_fractions],\n",
    "    [\"viridis\",custom_cmap_3,\"magma\",\"magma\",\"magma\"],\n",
    "    [\"Power\",\"IM frequencies\",frequency_text_codes[\"f1\"],frequency_text_codes[\"f2\"],\"Multiplex\"],\n",
    "):\n",
    "    ax = ax_dict[ax_key]\n",
    "    ax.tick_params(axis='y',direction='out',right=True,left=False,length=2,width=LINEWIDTH,pad=.2,colors='k')\n",
    "    ax.tick_params(axis='x',direction='out',length=2,width=LINEWIDTH,pad=.2,colors='k')\n",
    "    xticks = list(set(xticks))\n",
    "    xticks.sort()\n",
    "    yticks = list(set(yticks))\n",
    "    yticks.sort()\n",
    "    xticklabels = list(set(xticklabels))\n",
    "    xticklabels.sort()\n",
    "    yticklabels = list(set(yticklabels))\n",
    "    yticklabels.sort()\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_xticklabels(xticklabels,fontsize=FONTSIZE)\n",
    "    ax.set_yticklabels(yticklabels[::-1],fontsize=FONTSIZE)\n",
    "    ax.set_xlabel(r\"$\\beta$\",fontsize=FONTSIZE)\n",
    "    ax.set_ylabel(r\"$\\alpha$\",rotation=0,fontsize=FONTSIZE)\n",
    "    if ax_key == \"3\":\n",
    "        _X = np.ma.masked_where((X==0),_X)\n",
    "        im = ax.imshow(_X,cmap=_cmap,vmax=np.nanmax(_X))\n",
    "        ax.set_title(r\"Frequency\",fontsize=FONTSIZE)\n",
    "    elif ax_key != \"3a\":\n",
    "        _X = np.ma.masked_where((X==0),_X)\n",
    "        im = ax.imshow(_X,cmap=_cmap,vmax=1.)\n",
    "        ax.set_title(f\"Region, {_title}\",fontsize=FONTSIZE)\n",
    "    else:\n",
    "        im = ax.imshow(_X,cmap=_cmap,vmax=9)\n",
    "        ax.set_title(r\"$f_{\\text{IM}}$\"+\"$=$\"+r\"$\\alpha$$f_1$+$\\beta$$f_2$\",fontsize=FONTSIZE)\n",
    "    for _spine in [\"top\",\"right\",\"bottom\",\"left\"]:\n",
    "        #ax.spines[_spine].set_visible(False)\n",
    "        ax.spines[_spine].set_linewidth(LINEWIDTH)\n",
    "    ax.yaxis.set_label_position(\"right\")\n",
    "    ax.yaxis.set_tick_params(labelleft=False, labelright=True, labelcolor='k')\n",
    "    ax.xaxis.set_label_position(\"bottom\")\n",
    "    ax.xaxis.set_tick_params(labelbottom=True, labelright=False, labelcolor='k')\n",
    "    ax.set_xlim(.5+1,8.5)\n",
    "    ax.set_ylim(8.5,.5-1)\n",
    "\n",
    "fig.savefig(MAIN / \"Fig4_IM_count_across_fundamental_frequency_encoded_populations.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "fontsize=8; linewidth=.5\n",
    "# Example data\n",
    "data = np.random.rand(10, 10)\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(2,2),dpi=300,layout=\"constrained\")\n",
    "\n",
    "# Plot the data using imshow\n",
    "im = ax.imshow(data, cmap='magma',vmin=0,vmax=1)\n",
    "\n",
    "# Add the colorbar\n",
    "#cbar = fig.colorbar(cax)\n",
    "\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "axins = inset_axes(\n",
    "    ax, width=\"5%\",height=\"25%\",loc=\"center right\",borderpad=-1\n",
    ")\n",
    "cbar = fig.colorbar(im, cax=axins)\n",
    "cbar.outline.set_linewidth(0)\n",
    "cbar.set_ticks([0,1])\n",
    "cbar.ax.tick_params(axis='y', pad=0.4, length=2, width=linewidth, direction=\"in\", which=\"both\",colors='white')\n",
    "cbar.set_ticklabels([f\"{i:.0f}\" for i in [0,1]], fontsize=fontsize,c='k')\n",
    "cbar.set_label(\"Fraction of\\nexperiments\",fontsize=fontsize)\n",
    "# Save the figure with the colorbar\n",
    "fig.savefig(MAIN / \"CBAR_f_im_count.png\",dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "# Show the plot (optional)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2,2),dpi=300,)\n",
    "ax.set_xlim(0,15)\n",
    "ax.set_ylim(0,35)\n",
    "\n",
    "counter = 0\n",
    "for ix, i in enumerate(roi_c_dict.keys()):\n",
    "    counter +=3\n",
    "    c = roi_c_dict[i]\n",
    "    txt = frequency_text_codes[i]\n",
    "    ax.scatter(1, counter, marker='s',c=c,s=20, linewidths=.5, edgecolors=\"k\")\n",
    "    ax.text(1.7, counter-.9, txt,c='k',fontsize=8)\n",
    "counter += 3\n",
    "ax.scatter(1, counter, marker='s',c=\"k\",s=20, linewidths=.5, edgecolors=\"k\")\n",
    "ax.text(1.7, counter-.9, \"Control IM\",c='k',fontsize=8)\n",
    "\n",
    "ax.text(8, 2.6, f\"$f_{2}$=0.2Hz\", fontsize=6)\n",
    "ax.text(8, 5, f\"$f_{1}$=0.125Hz\", fontsize=6)\n",
    "\n",
    "ax.scatter(7, 9, s=20, edgecolors=\"k\",linewidths=.5,c=\"lightgrey\")\n",
    "ax.text(7.5, 8.1, f\"Control\", fontsize=8)\n",
    "\n",
    "ax.scatter(7, 9+3, s=20, edgecolors=\"k\",linewidths=.5,c=\"k\")\n",
    "ax.text(7.5, 8.1+3, f\"Entrainment\", fontsize=8)\n",
    "\n",
    "custom_cmap = LinearSegmentedColormap.from_list('custom_YlGn', colors, N=n_colors)\n",
    "custom_cmap = [custom_cmap(i) for i in range(4)]\n",
    "counter = 13\n",
    "for i, (c, exp_id) in enumerate(zip(custom_cmap,[\"3T\",\"7T\",\"3T Vary\", \"7T Vary\"])):\n",
    "    counter += 3\n",
    "    ax.scatter(7, counter, marker='s',s=20, edgecolors=\"k\",linewidths=.5,c=c)\n",
    "    ax.text(7.5, counter-.8, exp_id, fontsize=8)\n",
    "\n",
    "fig.savefig(MAIN / \"LEGEND_3.png\",dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in im_codes:\n",
    "    for roi_f_type in roi_f_types:\n",
    "        print(f\"\\nroi-{roi_f_type} im-{im}\")\n",
    "        _df = im_above_df[f\"roi-{roi_f_type}_im-{im}\"]\n",
    "        for row_ix,row in _df.iterrows():\n",
    "            print(row.experiment_id,row.sub_id,row.roi_task_id,row.im_frequency, row.im_fsnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic = [[i for i in range(len(im_frequencies_across_all_test_frequencies))]]\n",
    "fig, ax_dict = plt.subplot_mosaic(mosaic=mosaic,figsize=(4,1),dpi=300,layout=\"constrained\")\n",
    "for (_, ax), k in zip(ax_dict.items(),im_frequencies_across_all_test_frequencies.keys()):\n",
    "    ax.imshow(im_frequencies_across_all_test_frequencies[k],cmap=\"magma\")\n",
    "    ax.set_title(f\"{k}\",fontsize=FONTSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_top = 2\n",
    "mosaic = [\"im_frequencies\",\"f1\",\"f2\",\"f1f2\"]\n",
    "fig, ax_dict = plt.subplot_mosaic(mosaic=[mosaic[1:]],figsize=(3,1.),dpi=300,layout=\"constrained\")\n",
    "for ax_ix, (ax_key, _X) in enumerate(zip([\"f1\",\"f2\",\"f1f2\"],[f1_fractions,f2_fractions,f1f2_fractions])):\n",
    "    ax = ax_dict[ax_key]\n",
    "    fractions = _X.copy()\n",
    "    _ = ax.hist(fractions[X!=0].flatten(),width=.02,bins=50,zorder=2)\n",
    "    # Add vertical lines\n",
    "    top_vals = fractions.flatten()\n",
    "    top_vals = list(set([i for i in top_vals]))\n",
    "    top_vals.sort()\n",
    "    top_vals = top_vals[-show_top:][::-1]\n",
    "    for rank_ix, _top_val in enumerate(top_vals):\n",
    "        coef = X_scaling[fractions==_top_val]\n",
    "        f1_coef = coef[:,0]\n",
    "        f2_coef = coef[:,1]\n",
    "        for _f1,_f2 in zip(f1_coef,f2_coef):\n",
    "            if ax_ix == 0 and _f1 == 1 and _f2 == 0:\n",
    "                ax.plot([_top_val,_top_val],[ax.get_ylim()[0],ax.get_ylim()[-1]*.3],color='r',linewidth=LINEWIDTH,zorder=1)\n",
    "                ax.text(_top_val,(ax.get_ylim()[-1]*.3)+1.4,format_f1_f2_equation(_f1,_f2),rotation=0,fontsize=FONTSIZE,ha=\"center\",va=\"center\")\n",
    "            elif ax_ix == 0 and _f1 == 2 and _f2 == 0:\n",
    "                ax.plot([_top_val,_top_val],[ax.get_ylim()[0],ax.get_ylim()[-1]*.6],color='r',linewidth=LINEWIDTH,zorder=1)\n",
    "                ax.text(_top_val,(ax.get_ylim()[-1]*.6)+1.4,format_f1_f2_equation(_f1,_f2),rotation=0,fontsize=FONTSIZE,ha=\"center\",va=\"center\")\n",
    "            elif ax_ix == 0 and _f1 == 0 and _f2 == 1:\n",
    "                ax.plot([_top_val,_top_val],[ax.get_ylim()[0],ax.get_ylim()[-1]*.6],color='r',linewidth=LINEWIDTH,zorder=1)\n",
    "                ax.text(_top_val,(ax.get_ylim()[-1]*.6)+1.4,format_f1_f2_equation(_f1,_f2),rotation=0,fontsize=FONTSIZE,ha=\"center\",va=\"center\")\n",
    "            elif ax_ix == 1 and _f1 == 0 and _f2 == 1:\n",
    "                ax.plot([_top_val,_top_val],[ax.get_ylim()[0],ax.get_ylim()[-1]*.6],color='r',linewidth=LINEWIDTH,zorder=1)\n",
    "                ax.text(_top_val,(ax.get_ylim()[-1]*.6)+1.4,format_f1_f2_equation(_f1,_f2),rotation=0,fontsize=FONTSIZE,ha=\"center\",va=\"center\")\n",
    "            elif ax_ix == 1 and _f1 == 0 and _f2 == .5:\n",
    "                ax.plot([_top_val,_top_val],[ax.get_ylim()[0],ax.get_ylim()[-1]*.6],color='darkgrey',linewidth=LINEWIDTH,zorder=1)\n",
    "                ax.text(_top_val,(ax.get_ylim()[-1]*.6)+1.4,format_f1_f2_equation(_f1,_f2),rotation=0,fontsize=FONTSIZE,ha=\"center\",va=\"center\")\n",
    "            elif ax_ix == 1 and _f1 == 0 and _f2 == 2:\n",
    "                ax.plot([_top_val,_top_val],[ax.get_ylim()[0],ax.get_ylim()[-1]*10.],color='r',linewidth=LINEWIDTH,zorder=1)\n",
    "                ax.text(_top_val,(ax.get_ylim()[-1]*.3)+1.4,format_f1_f2_equation(_f1,_f2),rotation=0,fontsize=FONTSIZE,ha=\"center\",va=\"center\",zorder=6)\n",
    "                \n",
    "            elif ax_ix == 2 and _f1 == 0 and _f2 == 1:\n",
    "                ax.plot([_top_val-.005,_top_val-.005],[ax.get_ylim()[0],ax.get_ylim()[-1]*.6],color='r',linewidth=LINEWIDTH,zorder=1)\n",
    "                ax.text(_top_val,(ax.get_ylim()[-1]*.6)+1.4,format_f1_f2_equation(_f1,_f2),rotation=0,fontsize=FONTSIZE,ha=\"center\",va=\"center\")\n",
    "            elif ax_ix == 2 and _f1 == -1 and _f2 == 1:\n",
    "                ax.plot([_top_val,_top_val],[ax.get_ylim()[0],ax.get_ylim()[-1]*.6],color='r',linewidth=LINEWIDTH,zorder=1)\n",
    "                ax.text(_top_val-.1,(ax.get_ylim()[-1]*.6)+1.4,format_f1_f2_equation(_f1,_f2),rotation=0,fontsize=FONTSIZE,ha=\"center\",va=\"center\")\n",
    "            elif ax_ix == 2 and _f1 == 1 and _f2 == 0:\n",
    "                ax.plot([_top_val,_top_val],[ax.get_ylim()[0],ax.get_ylim()[-1]*.3],color='r',linewidth=LINEWIDTH,zorder=1)\n",
    "                ax.text(_top_val-.05,(ax.get_ylim()[-1]*.3)+1.4,format_f1_f2_equation(_f1,_f2),rotation=0,fontsize=FONTSIZE,ha=\"center\",va=\"center\")\n",
    "            else:\n",
    "                ax.text(_top_val-.07,np.random.uniform(ax.get_ylim()[0],ax.get_ylim()[-1]*.5),format_f1_f2_equation(_f1,_f2),rotation=0,fontsize=FONTSIZE)\n",
    "    ax.tick_params(axis=\"both\", length=2.,width=LINEWIDTH,pad=0)\n",
    "    if ax_ix == 0:\n",
    "        ax.set_ylabel(r\"$f_{\\text{IM}}$\"+\" count (n=37)\", fontsize=FONTSIZE)\n",
    "    if ax_ix == 1:\n",
    "        ax.set_xlabel(\"Fraction of experiments\", fontsize=FONTSIZE)\n",
    "    for _spine in [\"top\",\"right\"]:\n",
    "        ax.spines[_spine].set_visible(False)\n",
    "    for _spine in [\"left\",\"bottom\"]:\n",
    "        ax.spines[_spine].set_linewidth(LINEWIDTH)\n",
    "    ax.set_xlim(0,1)\n",
    "    ax.set_xticks([0,1])\n",
    "    ax.set_xticklabels([0,1],fontsize=FONTSIZE)\n",
    "    ax.set_ylim(0,12)\n",
    "    ax.set_yticks([0,12])\n",
    "    ax.set_yticklabels([0,12],fontsize=FONTSIZE)\n",
    "\n",
    "fig.savefig(MAIN / \"Fig4_control_and_true_im_count_across_fundamental_frequency_encoded_populations.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
