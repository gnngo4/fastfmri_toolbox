{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2629b7bc-20df-456c-86c5-e272ff3fbdd1",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d321a-b9fe-4533-bb71-9d54144c6687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "def search(base_dir, wildcard):\n",
    "    search_path = Path(base_dir) / wildcard\n",
    "    files = glob.glob(str(search_path))\n",
    "\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No files were found in: {search_path}\")\n",
    "\n",
    "    return files\n",
    "\n",
    "def search_denoise_dir(\n",
    "    experiment_id, \n",
    "    mri_id, \n",
    "    proc_id, \n",
    "    denoise_id, \n",
    "    sub_id, \n",
    "    ses_id, \n",
    "    task_id, \n",
    "    run_id,\n",
    "):\n",
    "\n",
    "    nifti = {}\n",
    "    for descriptor in [\"windowed\", \"denoised\"]:\n",
    "        wildcard = f\"{experiment_id}/{mri_id}/derivatives/run_level_proc-{proc_id}_NIFTI/{denoise_id}/sub-{sub_id}/ses-{ses_id}/task-{task_id}/run-{run_id}/GLM/*desc-{descriptor}*bold.nii.gz\"\n",
    "        _nifti = search(\"/scratch\", wildcard)\n",
    "        assert len(_nifti) == 1\n",
    "        nifti[descriptor] = _nifti[0]\n",
    "    \n",
    "    return nifti\n",
    "\n",
    "def rename_nifti_to_metric(nifti_name, metric_name, search_frequency):\n",
    "\n",
    "    return Path(nifti_name.replace('bold.', f\"f-{search_frequency}_metric-{metric_name}.\"))\n",
    "\n",
    "def create_directory(directory_path):\n",
    "    path = Path(directory_path)\n",
    "    if not path.exists():\n",
    "        path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec6235f-a08c-48a8-bed5-d25f7dc8bfe6",
   "metadata": {},
   "source": [
    "Compute run average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5337743-8c30-447a-b44b-9ecb7ec32ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "proc_ids = [\"NONORDIC\"] # [\"NONORDIC\", \"NORDIC\"]\n",
    "dm_ids = ['00_experiment-min+motion24+wmcsfmean',]\n",
    "descs = ['denoised','windowed']\n",
    "\n",
    "for proc_id, dm_id, desc in itertools.product(proc_ids, dm_ids, descs):\n",
    "\n",
    "    print(proc_id, dm_id, desc)\n",
    "    # Get dtseries\n",
    "    inputs = {\n",
    "        \"experiment_id\": \"1_attention\",\n",
    "        \"mri_id\": \"7T\",\n",
    "        \"proc_id\": proc_id,\n",
    "        \"denoise_id\": dm_id,\n",
    "        \"sub_id\": \"000\",\n",
    "        \"ses_id\": \"20230801\", \n",
    "        \"task_id\": \"wbpilot\",\n",
    "        \"run_id\": '',\n",
    "    }\n",
    "\n",
    "\n",
    "    experiment_id = inputs[\"experiment_id\"]\n",
    "    mri_id = inputs[\"mri_id\"]\n",
    "    proc_id = inputs[\"proc_id\"]\n",
    "    denoise_id = inputs[\"denoise_id\"]\n",
    "    sub_id = inputs[\"sub_id\"]\n",
    "    ses_id = inputs[\"ses_id\"]\n",
    "    task_id = inputs[\"task_id\"]\n",
    "    \n",
    "    niftis = !ls /scratch/{experiment_id}/{mri_id}/derivatives/run_level_proc-{proc_id}_NIFTI/{denoise_id}/sub-{sub_id}/ses-{ses_id}/task-{task_id}/run-??/GLM/*desc-{desc}*bold.nii.gz\n",
    "    print(len(niftis), niftis[0], niftis[-1])\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in dtseries:\n",
    "        print(i)\n",
    "    \"\"\"\n",
    "\n",
    "    run_avg_dir = Path(f\"/scratch/{experiment_id}/{mri_id}/derivatives/run_level_proc-{proc_id}_NIFTI/{denoise_id}/sub-{sub_id}/ses-{ses_id}/task-{task_id}/run-avg/GLM\")\n",
    "    create_directory(run_avg_dir)\n",
    "    # Average all runs\n",
    "    bold_str_base = f\"sub-{sub_id}_ses-{ses_id}_task-{task_id}_run-avg_desc-{desc}\"\n",
    "    out_nifti = f\"{run_avg_dir}/{bold_str_base}_bold.nii.gz\"\n",
    "    for ix, nifti in enumerate(niftis):\n",
    "        if ix == 0:\n",
    "            !cp {nifti} {out_nifti}\n",
    "        else:\n",
    "            !fslmaths {out_nifti} -add {nifti} {out_nifti}\n",
    "    !fslmaths {out_nifti} -div {len(niftis)} {out_nifti}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6dff60-bdf6-4441-9573-fadbdfe0b34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "niftis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c435fb2-52c6-4fbd-93a9-dbe5f14a4493",
   "metadata": {},
   "source": [
    "Fit frequencies onto collapsed wholebrain data and compute R2 model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b479adf2-9593-43d9-af54-e8cef71bcf9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "METRIC_NAME = 'r2'\n",
    "TR = 3.024\n",
    "search_frequencies = [.2,.125]\n",
    "proc_ids = [\"NONORDIC\"] # [\"NONORDIC\", \"NORDIC\"]\n",
    "dm_ids = ['00_experiment-min+motion24+wmcsf_mean+scrub',]\n",
    "run_ids = ['avg'] # '01', '03', '04', '05', '06', '07', '08', '09'\n",
    "\n",
    "for proc_id, dm_id, run_id, search_frequency in itertools.product(proc_ids, dm_ids, run_ids, search_frequencies):\n",
    "\n",
    "    # Get dtseries\n",
    "    inputs = {\n",
    "        \"experiment_id\": \"1_attention\",\n",
    "        \"mri_id\": \"7T\",\n",
    "        \"proc_id\": proc_id,\n",
    "        \"denoise_id\": dm_id,\n",
    "        \"sub_id\": \"000\",\n",
    "        \"ses_id\": \"20230801\", \n",
    "        \"task_id\": \"wbpilot\",\n",
    "        \"run_id\": run_id,\n",
    "    }\n",
    "    niftis = search_denoise_dir(**inputs)\n",
    "\n",
    "    # Run on windowed and denoised data\n",
    "    for descriptor in [\"denoised\", \"windowed\"]:\n",
    "\n",
    "        _nifti = niftis[descriptor]\n",
    "        metric_out = rename_nifti_to_metric(_nifti, METRIC_NAME, search_frequency)\n",
    "        if metric_out.exists():\n",
    "            print(f\"{metric_out.stem} already generated.\\nSkipping.\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Generating metric: {metric_out.stem}\")\n",
    "        \n",
    "        # Load dtseries\n",
    "        img = nib.load(_nifti)\n",
    "        ts_data = img.get_fdata()\n",
    "        x, y, z, n_tps = ts_data.shape\n",
    "    \n",
    "        # Run GLM on each vertex\n",
    "        r2_data = np.zeros((x,y,z))\n",
    "        voxel_coordinates = itertools.product(range(x), range(y), range(z))\n",
    "\n",
    "        n_voxels = np.prod((x,y,z))\n",
    "        # Iterate over the voxel coordinates\n",
    "        for voxel_idx, coordinates in enumerate(voxel_coordinates):\n",
    "            # Process the voxel coordinates (x, y, z) here\n",
    "            _x, _y, _z = coordinates\n",
    "    \n",
    "            if voxel_idx % 50_000 == 0:\n",
    "                print(f\"[PROGRESS] {str(voxel_idx).zfill(7)}/{str(n_voxels).zfill(7)}\")\n",
    "            \n",
    "            # Get timeseries from a voxel, and associated timepoints\n",
    "            y = ts_data[_x, _y, _z, :]\n",
    "            # Skip if all values is zero\n",
    "            if np.all(y == 0):\n",
    "                continue\n",
    "                \n",
    "            t = np.linspace(0, TR*n_tps, n_tps+1)[:-1] # Non-phased timepoints\n",
    "            t = np.fmod(t, 1/search_frequency) # Phased timepoints\n",
    "            \n",
    "            # GLM - fit phased\n",
    "            X = np.vstack((np.sin(2*np.pi*t*search_frequency), np.cos(2*np.pi*t*search_frequency))).T\n",
    "            X = sm.add_constant(X)\n",
    "            model = sm.GLM(y, X, family=sm.families.Gaussian())\n",
    "            try:\n",
    "                result = model.fit()\n",
    "                # Calculate R2\n",
    "                y_pred = result.predict(X)\n",
    "                y_mean = np.mean(y)\n",
    "                ss_total = np.sum((y - y_mean) ** 2)  # Total sum of squares\n",
    "                ss_residual = np.sum((y - y_pred) ** 2)  # Residual sum of squares\n",
    "                r2 = 1 - (ss_residual / ss_total)  # R-squared\n",
    "                # store r2\n",
    "                r2_data[_x, _y, _z] = r2\n",
    "            except:\n",
    "                r2_data[_x, _y, _z] = -1\n",
    "    \n",
    "        # Save as dscalar\n",
    "        r2_img = nib.Nifti1Image(r2_data, header = img.header, affine = img.affine)\n",
    "        nib.save(r2_img, metric_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69ff265-853b-4d22-a3c6-f445c2824f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
