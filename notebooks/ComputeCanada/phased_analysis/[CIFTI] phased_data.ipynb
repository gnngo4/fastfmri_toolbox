{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2629b7bc-20df-456c-86c5-e272ff3fbdd1",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d321a-b9fe-4533-bb71-9d54144c6687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "def search(base_dir, wildcard):\n",
    "    search_path = Path(base_dir) / wildcard\n",
    "    files = glob.glob(str(search_path))\n",
    "\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No files were found in: {search_path}\")\n",
    "\n",
    "    return files\n",
    "\n",
    "def search_denoise_dir(\n",
    "    experiment_id, \n",
    "    mri_id, \n",
    "    smooth_id, \n",
    "    denoise_id, \n",
    "    sub_id, \n",
    "    ses_id, \n",
    "    task_id, \n",
    "    run_id\n",
    "):\n",
    "\n",
    "    dtseries = {}\n",
    "    for descriptor in [\"windowed\", \"denoised\"]:\n",
    "        wildcard = f\"{experiment_id}/{mri_id}/derivatives/run_level_s{smooth_id}/{denoise_id}/sub-{sub_id}/ses-{ses_id}/task-{task_id}/run-{run_id}/GLM/*desc-{descriptor}*bold.dtseries.nii\"\n",
    "        _dtseries = search(\"/scratch\", wildcard)\n",
    "        assert len(_dtseries) == 1\n",
    "        dtseries[descriptor] = _dtseries[0]\n",
    "    \n",
    "    return dtseries\n",
    "\n",
    "def rename_dtseries_to_metric(dtseries_name, metric_name):\n",
    "\n",
    "    return Path(dtseries_name.replace('bold.', f\"metric-{metric_name}.\"))\n",
    "\n",
    "def save_single_metric_as_dtseries(metric_data, base_dtseries, metric_name = 'r2'):\n",
    "    base_img = nib.load(base_dtseries)\n",
    "    # Save as dscalar\n",
    "    img = nib.Cifti2Image(\n",
    "        np.expand_dims(metric_data,axis=0), \n",
    "        header=base_img.header\n",
    "    )\n",
    "    # Rewrite number of datapoints\n",
    "    img.header.matrix[0].number_of_series_points = 1\n",
    "    # Save\n",
    "    dtseries_out = rename_dtseries_to_metric(base_dtseries, metric_name)\n",
    "    nib.save(img, dtseries_out)\n",
    "\n",
    "\n",
    "def create_directory(directory_path):\n",
    "    path = Path(directory_path)\n",
    "    if not path.exists():\n",
    "        path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec6235f-a08c-48a8-bed5-d25f7dc8bfe6",
   "metadata": {},
   "source": [
    "Compute run average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5337743-8c30-447a-b44b-9ecb7ec32ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "smooth_ids = [0, 4]\n",
    "dm_ids = [\n",
    "    '00_experiment-min+motion24+wmcsf_mean+scrub',\n",
    "    '01_experiment-min+motion24+wmcsf_compcor+scrub', \n",
    "]\n",
    "descs = ['denoised','windowed']\n",
    "\n",
    "for smooth_id, dm_id, desc in itertools.product(smooth_ids, dm_ids, descs):\n",
    "\n",
    "    print(smooth_id, dm_id, desc)\n",
    "    # Get dtseries\n",
    "    inputs = {\n",
    "        \"experiment_id\": \"1_attention\",\n",
    "        \"mri_id\": \"7T\",\n",
    "        \"smooth_id\": smooth_id,\n",
    "        \"denoise_id\": dm_id,\n",
    "        \"sub_id\": \"000\",\n",
    "        \"ses_id\": \"20230623d\", \n",
    "        \"task_id\": \"wbpilot\",\n",
    "        \"run_id\": '',\n",
    "    }\n",
    "\n",
    "    experiment_id = inputs[\"experiment_id\"]\n",
    "    mri_id = inputs[\"mri_id\"]\n",
    "    smooth_id = inputs[\"smooth_id\"]\n",
    "    denoise_id = inputs[\"denoise_id\"]\n",
    "    sub_id = inputs[\"sub_id\"]\n",
    "    ses_id = inputs[\"ses_id\"]\n",
    "    task_id = inputs[\"task_id\"]\n",
    "    \n",
    "    dtseries = !ls /scratch/{experiment_id}/{mri_id}/derivatives/run_level_s{smooth_id}/{denoise_id}/sub-{sub_id}/ses-{ses_id}/task-{task_id}/run-0?/GLM/*desc-{desc}*bold.dtseries.nii\n",
    "\n",
    "    \"\"\"\n",
    "    for i in dtseries:\n",
    "        print(i)\n",
    "    \"\"\"\n",
    "\n",
    "    run_avg_dir = Path(f\"/scratch/{experiment_id}/{mri_id}/derivatives/run_level_s{smooth_id}/{denoise_id}/sub-{sub_id}/ses-{ses_id}/task-{task_id}/run-avg/GLM\")\n",
    "    create_directory(run_avg_dir)    \n",
    "    # Average all runs\n",
    "    bold_str_base = f\"sub-{sub_id}_ses-{ses_id}_task-{task_id}_run-avg_desc-{desc}\"\n",
    "    out_dtseries = f\"{run_avg_dir}/{bold_str_base}_bold.dtseries.nii\"\n",
    "    !wb_command -cifti-average {out_dtseries} -cifti {' -cifti '.join(dtseries)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c435fb2-52c6-4fbd-93a9-dbe5f14a4493",
   "metadata": {},
   "source": [
    "Fit frequencies onto collapsed wholebrain data and compute R2 model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b479adf2-9593-43d9-af54-e8cef71bcf9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "METRIC_NAME = 'r2'\n",
    "TR = 1.64\n",
    "search_frequency = .2\n",
    "smooth_ids = [0, 4]\n",
    "dm_ids = [\n",
    "    '00_experiment-min+motion24+wmcsf_mean+scrub',\n",
    "    '01_experiment-min+motion24+wmcsf_compcor+scrub', \n",
    "]\n",
    "run_ids = ['02', '03', '04', '05', 'avg']\n",
    "\n",
    "for smooth_id, dm_id, run_id in itertools.product(smooth_ids, dm_ids, run_ids):\n",
    "\n",
    "    # Get dtseries\n",
    "    inputs = {\n",
    "        \"experiment_id\": \"1_attention\",\n",
    "        \"mri_id\": \"7T\",\n",
    "        \"smooth_id\": smooth_id,\n",
    "        \"denoise_id\": dm_id,\n",
    "        \"sub_id\": \"000\",\n",
    "        \"ses_id\": \"20230623d\", \n",
    "        \"task_id\": \"wbpilot\",\n",
    "        \"run_id\": run_id,\n",
    "    }\n",
    "    dtseries = search_denoise_dir(**inputs)\n",
    "\n",
    "    # Run on windowed and denoised data\n",
    "    for descriptor in [\"windowed\", \"denoised\"]:\n",
    "        _dtseries = dtseries[descriptor]\n",
    "        metric_out = rename_dtseries_to_metric(_dtseries, METRIC_NAME)\n",
    "        if metric_out.exists():\n",
    "            print(f\"{metric_out.stem} already generated.\\nSkipping.\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Generating metric: {metric_out.stem}\")\n",
    "        \n",
    "        # Load dtseries\n",
    "        img = nib.load(_dtseries)\n",
    "        ts_data = img.get_fdata()\n",
    "        n_tps, n_vertices = ts_data.shape\n",
    "    \n",
    "        # Run GLM on each vertex\n",
    "        r2_data = np.zeros((n_vertices,))\n",
    "        for voxel_idx in range(n_vertices):\n",
    "    \n",
    "            if voxel_idx % 50_000 == 0:\n",
    "                print(f\"[PROGRESS] {str(voxel_idx).zfill(6)}/{str(n_vertices).zfill(6)}\")\n",
    "            \n",
    "            # Get timeseries from a voxel, and associated timepoints\n",
    "            y = ts_data[:,voxel_idx]\n",
    "            t = np.linspace(0, TR*n_tps, n_tps+1)[:-1] # Non-phased timepoints\n",
    "            t = np.fmod(t, 1/search_frequency) # Phased timepoints\n",
    "            \n",
    "            # GLM - fit phased\n",
    "            X = np.vstack((np.sin(2*np.pi*t*search_frequency), np.cos(2*np.pi*t*search_frequency))).T\n",
    "            X = sm.add_constant(X)\n",
    "            model = sm.GLM(y, X, family=sm.families.Gaussian())\n",
    "            result = model.fit()\n",
    "            \n",
    "            # Calculate R2\n",
    "            y_pred = result.predict(X)\n",
    "            y_mean = np.mean(y)\n",
    "            ss_total = np.sum((y - y_mean) ** 2)  # Total sum of squares\n",
    "            ss_residual = np.sum((y - y_pred) ** 2)  # Residual sum of squares\n",
    "            r2 = 1 - (ss_residual / ss_total)  # R-squared\n",
    "        \n",
    "            # store r2\n",
    "            r2_data[voxel_idx] = r2\n",
    "    \n",
    "        # Save as dscalar\n",
    "        save_single_metric_as_dtseries(\n",
    "            r2_data, \n",
    "            _dtseries, \n",
    "            metric_name = METRIC_NAME\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e739a89-36af-4f13-bef2-73fb9ce1f688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
