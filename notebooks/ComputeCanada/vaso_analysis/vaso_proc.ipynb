{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e009bb7-d8ef-4cd1-9447-0a17c80ecc38",
   "metadata": {},
   "source": [
    "Input bids and subject info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27929a29",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- sub-000, ses-20231004OPCoil, 1_attention, 7T\n",
    "    - 14 off, 240 s stim-on\n",
    "    - TR=2.539s\n",
    "    - Q1: f1=0.1 / f2=0.125\n",
    "- sub-021, ses-VasoTest, 1_frequency_tagging, 7T\n",
    "    - 14 off, 240 s stim-on\n",
    "    - TR=3.106\n",
    "    - Q1: f1=0.1 / f2=0.125\n",
    "    - 31 runs, discard first run\n",
    "    - Stimulated frequencies: .14, .22, .1, .15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3105b09-8485-4b45-9be2-7a9072a81180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"ComputeCanada/vaso_preproc\")\n",
    "\n",
    "from pathlib import Path\n",
    "import nibabel as nib\n",
    "\n",
    "from vaso import sort_vaso_data\n",
    "\n",
    "project_id = '1_frequency_tagging'\n",
    "mri_id = '7T'\n",
    "sub_id = '021'\n",
    "ses_id = 'VasoTest'\n",
    "updated_TR = 3.106\n",
    "# Remove runs depending on volume count\n",
    "task_id = \"wbpilot\"\n",
    "expected_volumes = [82,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1052d70",
   "metadata": {},
   "source": [
    "Relabel and group bold and vaso counterparts together\n",
    " - vaso sequence produces 2 runs for each scan (blood-nulled and not-nulled contrast)\n",
    " - update TR to appropriate value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9aea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "vaso_niftis = !ls /data/{project_id}/{mri_id}/bids/sub-{sub_id}/ses-{ses_id}/func/*vaso.*\n",
    "vaso_niftis = [Path(i) for i in vaso_niftis]\n",
    "\n",
    "sort_vaso_data(vaso_niftis, updated_TR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e715278",
   "metadata": {},
   "source": [
    "Remove runs depending on volume count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e55d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "vaso_niftis = !ls /data/{project_id}/{mri_id}/bids/sub-{sub_id}/ses-{ses_id}/func/*task-{task_id}*.nii.gz\n",
    "vaso_niftis = [Path(i) for i in vaso_niftis]\n",
    "run_ids = []\n",
    "for f in vaso_niftis:\n",
    "    n_vols = nib.load(f).shape[-1]\n",
    "    if n_vols not in expected_volumes:\n",
    "        run_ids.append(f.stem.split(\"run-\")[1].split('_')[0])\n",
    "run_ids = list(set(run_ids))\n",
    "\n",
    "for run_id in run_ids:\n",
    "    print(f\"Removing run-{run_id}\")\n",
    "    !rm /data/{project_id}/{mri_id}/bids/sub-{sub_id}/ses-{ses_id}/func/*task-{task_id}*run-{run_id}*.nii.gz\n",
    "    !rm /data/{project_id}/{mri_id}/bids/sub-{sub_id}/ses-{ses_id}/func/*task-{task_id}*run-{run_id}*.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d7a2ff",
   "metadata": {},
   "source": [
    "Resample task-wholebrain to the same resolution as the vaso data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41f868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wholebrains = !ls  /data/{project_id}/{mri_id}/bids/sub-{sub_id}/ses-{ses_id}/func/*task-wholebrain*part-mag*sbref.nii.gz\n",
    "for i in wholebrains:\n",
    "    !echo flirt -in {i} -ref {i} -applyisoxfm 0.8 -out {i}\n",
    "    !flirt -in {i} -ref {i} -applyisoxfm 0.8 -out {i}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2d5f81-8eba-48b5-a26a-5443b9b05890",
   "metadata": {},
   "source": [
    "Motion correction stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f309c4-19ac-4578-9bd8-9c99903d9177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "TR = 3.106\n",
    "truncate = (14+25, 14+230)\n",
    "truncate_idx = [int(i/TR) + 1 for i in truncate]\n",
    "print(truncate_idx)\n",
    "n_vols = 82\n",
    "np.arange(0, TR*n_vols, TR)[truncate_idx[0]:truncate_idx[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f028bc3e-1458-46a7-afe4-0c9e45cd6ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_denoise(bold_path, n_components=10, outfile=\"mppca.nii.gz\"):\n",
    "    \n",
    "    import nibabel as nib\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    img = nib.load(bold_path)\n",
    "    data = img.get_fdata()\n",
    "    x, y, z, n_tps = data.shape\n",
    "    data_reshaped = data.reshape(-1, n_tps)\n",
    "    # standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data_reshaped)\n",
    "    # Apply MPPCA using PCA\n",
    "    num_components = n_components  # Number of principal components\n",
    "    pca = PCA(n_components=num_components)\n",
    "    data_mppca = pca.fit_transform(data_scaled)\n",
    "    # Inverse transform to reconstruct the data\n",
    "    data_reconstructed = pca.inverse_transform(data_mppca)\n",
    "    data_reconstructed = scaler.inverse_transform(data_reconstructed)\n",
    "    # Reshape the reconstructed data back to 4D\n",
    "    data_reconstructed = data_reconstructed.reshape(x, y, z, n_tps)\n",
    "\n",
    "    nib.save(\n",
    "        nib.Nifti1Image(data_reconstructed, affine=img.affine, header=img.header),\n",
    "        outfile,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feabae0c-6985-4932-94a3-494014e4f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = Path(\"./ComputeCanada/vaso_preproc/tmp\")\n",
    "if not outdir.exists():\n",
    "    outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "vaso_dump = Path(\"/scratch/fastfmri_playgrond/vaso_dump\")\n",
    "if not vaso_dump.exists():\n",
    "    vaso_dump.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b4c0b9-20bf-45c3-9aeb-6311129018d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOLDS = !ls  /data/{project_id}/{mri_id}/bids/sub-{sub_id}/ses-{ses_id}/func/*task-wbpilot*part-mag_bold.nii.gz\n",
    "n_runs = len(BOLDS)\n",
    "for i in BOLDS:\n",
    "    print(f\" - {Path(i).stem}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f85644-8529-4a4f-b242-5bc70db54264",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "no_nordic_bold_average = vaso_dump / \"average_bold.nii.gz\"\n",
    "nordic_bold_average = vaso_dump / \"nordic_average_bold.nii.gz\"\n",
    "no_nordic_vaso_average = vaso_dump / \"average_vaso.nii.gz\"\n",
    "nordic_vaso_average = vaso_dump / \"nordic_average_vaso.nii.gz\"\n",
    "\n",
    "for bold_ix, bold_orig in enumerate(BOLDS):\n",
    "\n",
    "    bold_base = Path(bold_orig).stem.replace('.nii','')\n",
    "    print(bold_ix, bold_base)\n",
    "    mppca = outdir / f\"{bold_base}.mppca.nii.gz\"\n",
    "    pca_denoise(bold_orig, outfile=mppca)\n",
    "\n",
    "    if bold_ix == 0:\n",
    "        split = outdir / \"split\"\n",
    "        !fslsplit {mppca} {split} -t\n",
    "        reference = outdir / \"split0001.nii.gz\"\n",
    "    \n",
    "    assert reference.exists(), f\"{reference} does not exist.\"\n",
    "\n",
    "    # Motion correction\n",
    "    bold_hmc = outdir / f\"{bold_base}.hmc.nii.gz\"\n",
    "    matrix_save = outdir / f\"{bold_base}.1dmatrix_save.aff12.1D\"\n",
    "    dfile = outdir / f\"{bold_base}.dfile\"\n",
    "    mot = outdir / f\"{bold_base}.1Dfile\"\n",
    "    # HMC on MPPCA denoised BOLD\n",
    "    !3dvolreg \\\n",
    "        -overwrite \\\n",
    "        -prefix {bold_hmc} \\\n",
    "        -base {reference} \\\n",
    "        -1Dmatrix_save {matrix_save} -dfile {dfile} -1Dfile {mot} \\\n",
    "        -quitic \\\n",
    "        {mppca}\n",
    "    # Apply HMC params to original BOLD data\n",
    "    !3dAllineate \\\n",
    "        -overwrite \\\n",
    "        -source {bold_orig} \\\n",
    "        -1Dmatrix_apply {matrix_save} \\\n",
    "        -prefix {bold_hmc} \n",
    "    # Apply HMC params to NORDIC BOLD data\n",
    "    bold_nordic = Path(bold_orig.replace('part-mag_', 'part-mag_proc-NORDIC_'))\n",
    "    assert bold_nordic.exists(), f\"{bold_nordic} does not exist.\"\n",
    "    bold_nordic_hmc = outdir / f\"{bold_base}.nordic.hmc.nii.gz\"\n",
    "    !3dAllineate \\\n",
    "        -overwrite \\\n",
    "        -source {bold_nordic} \\\n",
    "        -1Dmatrix_apply {matrix_save} \\\n",
    "        -prefix {bold_nordic_hmc}\n",
    "    # Apply HMC params to vaso data\n",
    "    vaso_orig = Path(bold_orig.replace(\"bold.nii.gz\", \"vaso.nii.gz\"))\n",
    "    assert vaso_orig.exists(), f\"{vaso_orig} does not exist.\"\n",
    "    vaso_hmc = outdir / f\"{bold_base}.vaso.hmc.nii.gz\"\n",
    "    !3dAllineate \\\n",
    "        -overwrite \\\n",
    "        -source {vaso_orig} \\\n",
    "        -1Dmatrix_apply {matrix_save} \\\n",
    "        -prefix {vaso_hmc}\n",
    "    # Apply HMC params to NORDIC vaso data\n",
    "    vaso_nordic = Path(bold_orig.replace(\"part-mag_bold\", \"part-mag_proc-NORDIC_vaso\"))\n",
    "    assert vaso_nordic.exists(), f\"{vaso_nordic} does not exist.\"\n",
    "    vaso_nordic_hmc = outdir / f\"{bold_base}.vaso.nordic.hmc.nii.gz\"\n",
    "    !3dAllineate \\\n",
    "        -overwrite \\\n",
    "        -source {vaso_nordic} \\\n",
    "        -1Dmatrix_apply {matrix_save} \\\n",
    "        -prefix {vaso_nordic_hmc}\n",
    "\n",
    "\n",
    "    # Highpass filter\n",
    "    bold_hmc_hpf = outdir / f\"{bold_base}.hmc.hpf.nii.gz\"\n",
    "    bold_nordic_hmc_hpf = outdir / f\"{bold_base}.nordic.hmc.hpf.nii.gz\"\n",
    "    vaso_hmc_hpf = outdir / f\"{bold_base}.vaso.hmc.hpf.nii.gz\"\n",
    "    vaso_nordic_hmc_hpf = outdir / f\"{bold_base}.vaso.nordic.hmc.hpf.nii.gz\"\n",
    "    tmean = outdir / \"tmean.nii.gz\"\n",
    "\n",
    "    for _hmc, _hmc_hpf in zip(\n",
    "        [bold_hmc, bold_nordic_hmc, vaso_hmc, vaso_nordic_hmc], \n",
    "        [bold_hmc_hpf, bold_nordic_hmc_hpf, vaso_hmc_hpf, vaso_nordic_hmc_hpf]\n",
    "    ):\n",
    "        !fslmaths {_hmc} -Tmean {tmean}\n",
    "        !3dBandpass -overwrite -prefix {_hmc_hpf} -dt {TR} .01 9999 {_hmc}\n",
    "        !fslmaths {_hmc_hpf} -add {tmean} {_hmc_hpf}\n",
    "        assert _hmc_hpf.exists()\n",
    "\n",
    "    if bold_ix == 0:\n",
    "        !cp {bold_hmc_hpf} {no_nordic_bold_average}\n",
    "        !cp {bold_nordic_hmc_hpf} {nordic_bold_average}\n",
    "        !cp {vaso_hmc_hpf} {no_nordic_vaso_average}\n",
    "        !cp {vaso_nordic_hmc_hpf} {nordic_vaso_average}\n",
    "    else:\n",
    "        !fslmaths {no_nordic_bold_average} -add {bold_hmc_hpf} {no_nordic_bold_average}\n",
    "        !fslmaths {nordic_bold_average} -add {bold_nordic_hmc_hpf} {nordic_bold_average}\n",
    "        !fslmaths {no_nordic_vaso_average} -add {vaso_hmc_hpf} {no_nordic_vaso_average}\n",
    "        !fslmaths {nordic_vaso_average} -add {vaso_nordic_hmc_hpf} {nordic_vaso_average}\n",
    "\n",
    "!fslmaths {no_nordic_bold_average} -div {n_runs} {no_nordic_bold_average}\n",
    "!fslmaths {nordic_bold_average} -div {n_runs} {nordic_bold_average}\n",
    "!fslmaths {no_nordic_vaso_average} -div {n_runs} {no_nordic_vaso_average}\n",
    "!fslmaths {nordic_vaso_average} -div {n_runs} {nordic_vaso_average}\n",
    "!fslmaths {no_nordic_vaso_average} -div {no_nordic_bold_average} {no_nordic_vaso_average}\n",
    "!fslmaths {nordic_vaso_average} -div {nordic_bold_average} {nordic_vaso_average}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f340fe-b696-4856-89e4-bc8189df93b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import itertools\n",
    "\n",
    "no_nordic_bold_average = vaso_dump / \"average_bold.nii.gz\"\n",
    "nordic_bold_average = vaso_dump / \"nordic_average_bold.nii.gz\"\n",
    "no_nordic_vaso_average = vaso_dump / \"average_vaso.nii.gz\"\n",
    "nordic_vaso_average = vaso_dump / \"nordic_average_vaso.nii.gz\"\n",
    "\n",
    "search_frequencies = [.14, .22, .1, .15, .08, .05, .12]\n",
    "for _nifti in [no_nordic_bold_average, no_nordic_vaso_average]:\n",
    "    for search_frequency in search_frequencies:\n",
    "        \n",
    "        metric_out = Path(str(_nifti).replace('.nii.gz',f'_f-{search_frequency}_r2.nii.gz'))\n",
    "        if metric_out.exists():\n",
    "            print(f\"{metric_out.stem} already generated.\\nSkipping.\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Generating metric: {metric_out.stem}\")\n",
    "        \n",
    "        # load nifti\n",
    "        img = nib.load(_nifti)\n",
    "        ts_data = img.get_fdata()[:,:,:,truncate_idx[0]:truncate_idx[1]]\n",
    "        x, y, z, n_tps = ts_data.shape\n",
    "        # Run GLM on each vertex\n",
    "        r2_data = np.zeros((x,y,z))\n",
    "        voxel_coordinates = itertools.product(range(x), range(y), range(z))\n",
    "    \n",
    "        n_voxels = np.prod((x,y,z))\n",
    "        # Iterate over the voxel coordinates\n",
    "        for voxel_idx, coordinates in enumerate(voxel_coordinates):\n",
    "            # Process the voxel coordinates (x, y, z) here\n",
    "            _x, _y, _z = coordinates\n",
    "    \n",
    "            if voxel_idx % 50_000 == 0:\n",
    "                print(f\"[PROGRESS] {str(voxel_idx).zfill(7)}/{str(n_voxels).zfill(7)}\")\n",
    "    \n",
    "            # Get timeseries from a voxel, and associated timepoints\n",
    "            y = ts_data[_x, _y, _z, :]\n",
    "            # Skip if all values is zero\n",
    "            if np.all(y == 0):\n",
    "                continue\n",
    "                \n",
    "            t = np.linspace(0, TR*n_tps, n_tps+1)[:-1] # Non-phased timepoints\n",
    "            t = np.fmod(t, 1/search_frequency) # Phased timepoints\n",
    "\n",
    "            # GLM - fit phased\n",
    "            X = np.vstack((np.sin(2*np.pi*t*search_frequency), np.cos(2*np.pi*t*search_frequency))).T\n",
    "            X = sm.add_constant(X)\n",
    "            model = sm.GLM(y, X, family=sm.families.Gaussian())\n",
    "            try:\n",
    "                result = model.fit()\n",
    "                # Calculate R2\n",
    "                y_pred = result.predict(X)\n",
    "                y_mean = np.mean(y)\n",
    "                ss_total = np.sum((y - y_mean) ** 2)  # Total sum of squares\n",
    "                ss_residual = np.sum((y - y_pred) ** 2)  # Residual sum of squares\n",
    "                r2 = 1 - (ss_residual / ss_total)  # R-squared\n",
    "                # store r2\n",
    "                r2_data[_x, _y, _z] = r2\n",
    "            except:\n",
    "                r2_data[_x, _y, _z] = -1\n",
    "    \n",
    "        # Save as dscalar\n",
    "        r2_img = nib.Nifti1Image(r2_data, header = img.header, affine = img.affine)\n",
    "        nib.save(r2_img, metric_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc76bac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
